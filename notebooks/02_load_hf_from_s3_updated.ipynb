{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMISQjvSREau61Z+3y+M/DZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b47cf842b49a42b38048e1050bf45d5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75f9840adeb74cd99f5660c9b1ceb3b5",
              "IPY_MODEL_0d7ae27d612b4cc7abf134189f8a09bf",
              "IPY_MODEL_daeb91c290504dce838bfa4eb46a2b1e"
            ],
            "layout": "IPY_MODEL_91644ae5917c4170b544214c76735244"
          }
        },
        "75f9840adeb74cd99f5660c9b1ceb3b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36172467967e4090bf84c29a16d21eca",
            "placeholder": "​",
            "style": "IPY_MODEL_56eaa1d5fd884bc2bc1036d07697b7e5",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "0d7ae27d612b4cc7abf134189f8a09bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08405cc0659946c1ad4529ea0b626401",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_216eb8fc28fa4b0b81e6ed3e943d7dbc",
            "value": 2
          }
        },
        "daeb91c290504dce838bfa4eb46a2b1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b6854ec5e5d49a7ba289bfd9737cccf",
            "placeholder": "​",
            "style": "IPY_MODEL_da88133d48604464b176c161fbc74555",
            "value": " 2/2 [00:01&lt;00:00,  1.45it/s]"
          }
        },
        "91644ae5917c4170b544214c76735244": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36172467967e4090bf84c29a16d21eca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56eaa1d5fd884bc2bc1036d07697b7e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08405cc0659946c1ad4529ea0b626401": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "216eb8fc28fa4b0b81e6ed3e943d7dbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b6854ec5e5d49a7ba289bfd9737cccf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da88133d48604464b176c161fbc74555": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wesslen/seamless_sacrebleu_evaluation/blob/main/notebooks/02_load_hf_from_s3_updated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install boto3 transformers torch"
      ],
      "metadata": {
        "id": "LvgUESk_Toc0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['AWS_ACCESS_KEY_ID'] = userdata.get('AWS_ACCESS_KEY_ID')\n",
        "os.environ['AWS_SECRET_ACCESS_KEY'] = userdata.get('AWS_SECRET_ACCESS_KEY')"
      ],
      "metadata": {
        "id": "Baj4H7tn1NpJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "from botocore.config import Config\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "from contextlib import contextmanager\n",
        "from io import BytesIO\n",
        "from tempfile import TemporaryDirectory\n",
        "from transformers import (\n",
        "    AutoModel,\n",
        "    AutoTokenizer,\n",
        "    PretrainedConfig,\n",
        "    AutoProcessor,\n",
        "    LlamaTokenizerFast,\n",
        "    LlamaForCausalLM,\n",
        "    SeamlessM4Tv2Model,\n",
        "    SeamlessM4TProcessor\n",
        ")\n",
        "from typing import Tuple, Optional, Union, List, Dict, Any\n",
        "from pathlib import Path\n",
        "import urllib3\n",
        "import warnings\n",
        "from IPython.display import display, HTML\n",
        "from datetime import datetime\n",
        "\n",
        "class NotebookLogger:\n",
        "    \"\"\"Custom logger for Jupyter notebooks with colored output\"\"\"\n",
        "\n",
        "    COLORS = {\n",
        "        'INFO': '#0066cc',\n",
        "        'DEBUG': '#666666',\n",
        "        'WARNING': '#ff9900',\n",
        "        'ERROR': '#cc0000',\n",
        "        'SUCCESS': '#009933'\n",
        "    }\n",
        "\n",
        "    def __init__(self, enable_debug=False):\n",
        "        self.enable_debug = enable_debug\n",
        "\n",
        "    def _log(self, level: str, message: str):\n",
        "        timestamp = datetime.now().strftime('%H:%M:%S')\n",
        "        color = self.COLORS.get(level, '#000000')\n",
        "        display(HTML(\n",
        "            f'<pre style=\"margin:0; padding:2px 0; color: {color}\">'\n",
        "            f'[{timestamp}] {level}: {message}'\n",
        "            '</pre>'\n",
        "        ))\n",
        "\n",
        "    def info(self, message: str): self._log('INFO', message)\n",
        "    def debug_log(self, message: str):\n",
        "        if self.enable_debug: self._log('DEBUG', message)\n",
        "    def warning(self, message: str): self._log('WARNING', message)\n",
        "    def error(self, message: str): self._log('ERROR', message)\n",
        "    def success(self, message: str): self._log('SUCCESS', message)\n",
        "\n",
        "def get_s3_client(endpoint_url: Optional[str] = None, verify_ssl: bool = True):\n",
        "    \"\"\"Create an S3 client with configurable SSL verification.\"\"\"\n",
        "    if not verify_ssl:\n",
        "        warnings.filterwarnings('ignore', category=urllib3.exceptions.InsecureRequestWarning)\n",
        "\n",
        "    config = Config(retries=dict(max_attempts=3))\n",
        "    return boto3.client(\n",
        "        's3',\n",
        "        endpoint_url=endpoint_url,\n",
        "        aws_access_key_id=os.environ.get('AWS_ACCESS_KEY_ID'),\n",
        "        aws_secret_access_key=os.environ.get('AWS_SECRET_ACCESS_KEY'),\n",
        "        verify=verify_ssl,\n",
        "        config=config\n",
        "    )\n",
        "\n",
        "def find_model_files(files: List[str], logger: NotebookLogger) -> Tuple[List[str], bool]:\n",
        "    \"\"\"Find model files and determine if they're sharded.\"\"\"\n",
        "    # Check for single safetensors file\n",
        "    single_file = [f for f in files if f.endswith('model.safetensors')]\n",
        "    if single_file:\n",
        "        logger.debug_log(\"Found single safetensors file\")\n",
        "        return single_file, False\n",
        "\n",
        "    # Check for sharded files\n",
        "    sharded_pattern = re.compile(r'model-\\d{5}-of-\\d{5}\\.safetensors$')\n",
        "    sharded_files = [f for f in files if sharded_pattern.search(os.path.basename(f))]\n",
        "\n",
        "    if sharded_files:\n",
        "        logger.debug_log(f\"Found {len(sharded_files)} sharded safetensors files\")\n",
        "        return sorted(sharded_files), True\n",
        "\n",
        "    logger.debug_log(\"No safetensors files found\")\n",
        "    return [], False\n",
        "\n",
        "def get_model_class(model_type: str, model_class: Optional[str], logger: NotebookLogger):\n",
        "    \"\"\"\n",
        "    Determine the appropriate model class based on model type and class name.\n",
        "    \"\"\"\n",
        "    if model_class:\n",
        "        if model_class == \"LlamaForCausalLM\":\n",
        "            return LlamaForCausalLM\n",
        "        elif model_class == \"SeamlessM4Tv2Model\":\n",
        "            return SeamlessM4Tv2Model\n",
        "        return AutoModel\n",
        "\n",
        "    MODEL_CLASS_MAPPING = {\n",
        "        \"llama\": LlamaForCausalLM,\n",
        "        \"seamless_m4t_v2\": SeamlessM4Tv2Model,\n",
        "    }\n",
        "\n",
        "    model_class = MODEL_CLASS_MAPPING.get(model_type)\n",
        "    if model_class:\n",
        "        logger.debug_log(f\"Using specific model class: {model_class.__name__}\")\n",
        "        return model_class\n",
        "\n",
        "    logger.debug_log(\"Using default AutoModel class\")\n",
        "    return AutoModel\n",
        "\n",
        "def download_file_from_s3(s3_client, bucket: str, key: str, target_path: Path, logger: NotebookLogger) -> bool:\n",
        "    \"\"\"Helper function to download a file from S3 and create parent directories.\n",
        "    Returns True if successful, False otherwise.\"\"\"\n",
        "    try:\n",
        "        target_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        logger.debug_log(f\"Downloading: {key} to {target_path}\")\n",
        "\n",
        "        # Verify the key exists in S3\n",
        "        try:\n",
        "            s3_client.head_object(Bucket=bucket, Key=key)\n",
        "        except:\n",
        "            logger.error(f\"File not found in S3: {key}\")\n",
        "            return False\n",
        "\n",
        "        with open(target_path, 'wb') as out:\n",
        "            obj = s3_client.get_object(Bucket=bucket, Key=key)\n",
        "            out.write(obj['Body'].read())\n",
        "\n",
        "        # Verify file was downloaded\n",
        "        if not target_path.exists():\n",
        "            logger.error(f\"File not created at: {target_path}\")\n",
        "            return False\n",
        "\n",
        "        logger.debug_log(f\"Successfully downloaded {key} ({target_path.stat().st_size} bytes)\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error downloading {key}: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "def verify_directory_contents(temp_path: Path, logger: NotebookLogger):\n",
        "    \"\"\"Debug helper to verify directory contents\"\"\"\n",
        "    logger.debug_log(\"\\nDirectory contents:\")\n",
        "    logger.debug_log(\"-\" * 50)\n",
        "    for path in temp_path.rglob(\"*\"):\n",
        "        if path.is_file():\n",
        "            logger.debug_log(f\"File: {path.relative_to(temp_path)} ({path.stat().st_size} bytes)\")\n",
        "    logger.debug_log(\"-\" * 50)\n",
        "\n",
        "def load_model_from_s3(\n",
        "    bucket: str,\n",
        "    path_to_model: str,\n",
        "    endpoint_url: Optional[str] = None,\n",
        "    verify_ssl: bool = True,\n",
        "    force_bin: bool = False,\n",
        "    enable_debug: bool = True,\n",
        "    model_class: Optional[str] = None\n",
        ") -> Tuple[Union[AutoModel, None], Union[Any, None]]:\n",
        "    \"\"\"\n",
        "    Load a model and its tokenizer/processor from S3 storage with enhanced debugging.\n",
        "    \"\"\"\n",
        "    logger = NotebookLogger(enable_debug=enable_debug)\n",
        "    logger.info(f\"Starting model load from bucket: {bucket}, path: {path_to_model}\")\n",
        "\n",
        "    s3_client = get_s3_client(endpoint_url, verify_ssl)\n",
        "\n",
        "    # List all files in the model directory\n",
        "    logger.info(\"Listing files in bucket...\")\n",
        "    try:\n",
        "        files = []\n",
        "        paginator = s3_client.get_paginator('list_objects_v2')\n",
        "        for page in paginator.paginate(Bucket=bucket, Prefix=path_to_model):\n",
        "            if 'Contents' in page:\n",
        "                files.extend(obj['Key'] for obj in page['Contents'])\n",
        "\n",
        "        if not files:\n",
        "            logger.error(f\"No files found in bucket {bucket} at path {path_to_model}\")\n",
        "            raise Exception(\"No files found in specified path\")\n",
        "\n",
        "        logger.debug_log(\"\\nFound files in S3:\")\n",
        "        for file in files:\n",
        "            logger.debug_log(f\"- {file}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error listing files: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "    with TemporaryDirectory() as temp_dir:\n",
        "        temp_path = Path(temp_dir)\n",
        "        logger.debug_log(f\"\\nCreated temporary directory: {temp_dir}\")\n",
        "\n",
        "        # First, download config.json\n",
        "        config_file = next((f for f in files if f.endswith('config.json')), None)\n",
        "        if not config_file:\n",
        "            logger.error(\"No config.json found!\")\n",
        "            raise Exception(\"No config.json found in model directory\")\n",
        "\n",
        "        config_path = temp_path / 'config.json'\n",
        "        if not download_file_from_s3(s3_client, bucket, config_file, config_path, logger):\n",
        "            raise Exception(\"Failed to download config.json\")\n",
        "\n",
        "        # Read config to determine model type\n",
        "        try:\n",
        "            with open(config_path) as f:\n",
        "                config_data = json.load(f)\n",
        "                model_type = config_data.get('model_type', '').lower()\n",
        "                logger.debug_log(f\"\\nDetected model type: {model_type}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error reading config.json: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "        # Define required files for Seamless model\n",
        "        seamless_required_files = [\n",
        "            'processor_config.json',\n",
        "            'tokenizer_config.json',\n",
        "            'special_tokens_map.json',\n",
        "            'tokenizer.model',\n",
        "            'preprocessor_config.json'\n",
        "        ]\n",
        "\n",
        "        # Download all auxiliary files first\n",
        "        aux_files = [f for f in files if any(f.endswith(ext) for ext in [\n",
        "            'tokenizer.json',\n",
        "            'tokenizer_config.json',\n",
        "            'special_tokens_map.json',\n",
        "            'vocab.json',\n",
        "            'merges.txt',\n",
        "            'tokenizer.model',\n",
        "            'processor_config.json',\n",
        "            'preprocessor_config.json',\n",
        "            'generation_config.json',\n",
        "            'config.json'\n",
        "        ])]\n",
        "\n",
        "        logger.debug_log(\"\\nDownloading auxiliary files:\")\n",
        "        downloaded_files = []\n",
        "        for file in aux_files:\n",
        "            relative_path = Path(file).relative_to(path_to_model)\n",
        "            target_path = temp_path / relative_path\n",
        "            success = download_file_from_s3(s3_client, bucket, file, target_path, logger)\n",
        "            if success:\n",
        "                downloaded_files.append(relative_path.name)\n",
        "            else:\n",
        "                logger.warning(f\"Failed to download auxiliary file: {file}\")\n",
        "\n",
        "        # Check for required files for Seamless model\n",
        "        if model_type == \"seamless_m4t_v2\":\n",
        "            missing_files = [f for f in seamless_required_files if f not in downloaded_files]\n",
        "            if missing_files:\n",
        "                logger.error(f\"Missing required files for Seamless model: {missing_files}\")\n",
        "                raise Exception(f\"Missing required files for Seamless model: {missing_files}\")\n",
        "\n",
        "        # Download model weights\n",
        "        safetensors_files, is_sharded = find_model_files(files, logger)\n",
        "        if safetensors_files and not force_bin:\n",
        "            logger.debug_log(\"\\nDownloading safetensors files:\")\n",
        "            for file in safetensors_files:\n",
        "                relative_path = Path(file).relative_to(path_to_model)\n",
        "                target_path = temp_path / relative_path\n",
        "                if not download_file_from_s3(s3_client, bucket, file, target_path, logger):\n",
        "                    raise Exception(f\"Failed to download model file: {file}\")\n",
        "\n",
        "            if is_sharded:\n",
        "                logger.debug_log(\"\\nCreating index file for sharded safetensors\")\n",
        "                num_shards = len(safetensors_files)\n",
        "                index_data = {\n",
        "                    \"metadata\": {\"total_size\": 0},\n",
        "                    \"weight_map\": {\n",
        "                        param: f\"model-{i+1:05d}-of-{num_shards:05d}.safetensors\"\n",
        "                        for i, param in enumerate([f\"layer_{i}\" for i in range(num_shards)])\n",
        "                    }\n",
        "                }\n",
        "                index_path = temp_path / \"model.safetensors.index.json\"\n",
        "                with open(index_path, \"w\") as f:\n",
        "                    json.dump(index_data, f)\n",
        "                logger.debug_log(f\"Created index file at {index_path}\")\n",
        "\n",
        "        # Verify directory contents before loading\n",
        "        verify_directory_contents(temp_path, logger)\n",
        "\n",
        "        # Try loading model\n",
        "        try:\n",
        "            logger.info(\"\\nLoading model...\")\n",
        "            model_path = str(temp_path.absolute())\n",
        "            logger.debug_log(f\"Loading model from path: {model_path}\")\n",
        "\n",
        "            ModelClass = get_model_class(model_type, model_class, logger)\n",
        "            model = ModelClass.from_pretrained(\n",
        "                model_path,\n",
        "                local_files_only=True,\n",
        "                use_safetensors=not force_bin,\n",
        "            )\n",
        "            logger.success(\"Model loaded successfully\")\n",
        "\n",
        "            # Load processor for Seamless model\n",
        "            if model_type == \"seamless_m4t_v2\":\n",
        "                try:\n",
        "                    logger.info(\"Loading Seamless processor...\")\n",
        "                    # Use the specific SeamlessM4TProcessor class\n",
        "                    processor = SeamlessM4TProcessor.from_pretrained(\n",
        "                        model_path,\n",
        "                        local_files_only=True,\n",
        "                        use_safetensors=not force_bin\n",
        "                    )\n",
        "                    logger.success(\"Seamless processor loaded successfully\")\n",
        "                    return model, processor\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"Failed to load Seamless processor: {str(e)}\")\n",
        "                    logger.debug_log(f\"Stack trace for processor error: {e.__class__.__name__}: {str(e)}\")\n",
        "                    raise\n",
        "\n",
        "            # Load tokenizer for other models\n",
        "            try:\n",
        "                if model_type == \"llama\":\n",
        "                    logger.info(\"Loading LlamaTokenizerFast...\")\n",
        "                    tokenizer = LlamaTokenizerFast.from_pretrained(\n",
        "                        model_path,\n",
        "                        local_files_only=True\n",
        "                    )\n",
        "                else:\n",
        "                    logger.info(\"Loading AutoTokenizer...\")\n",
        "                    tokenizer = AutoTokenizer.from_pretrained(\n",
        "                        model_path,\n",
        "                        local_files_only=True\n",
        "                    )\n",
        "                logger.success(\"Tokenizer loaded successfully\")\n",
        "                return model, tokenizer\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Failed to load tokenizer: {str(e)}\")\n",
        "                logger.debug_log(f\"Stack trace for tokenizer error: {e.__class__.__name__}: {str(e)}\")\n",
        "                raise\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to load model: {str(e)}\")\n",
        "            logger.debug_log(f\"Stack trace for model error: {e.__class__.__name__}: {str(e)}\")\n",
        "            raise"
      ],
      "metadata": {
        "id": "BS8xd74ST0VN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint = \"https://nyc3.digitaloceanspaces.com\""
      ],
      "metadata": {
        "id": "l4FIhCHX1EJi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# import boto3\n",
        "# from botocore.client import Config\n",
        "\n",
        "# # Initialize a session using DigitalOcean Spaces.\n",
        "# session = boto3.session.Session()\n",
        "# client = session.client('s3',\n",
        "#                         region_name='nyc3',\n",
        "#                         endpoint_url='https://nyc3.digitaloceanspaces.com',\n",
        "#                         aws_access_key_id=os.environ.get('AWS_ACCESS_KEY_ID'),\n",
        "#                         aws_secret_access_key=os.environ.get('AWS_SECRET_ACCESS_KEY')\n",
        "\n",
        "# # Create a new Space.\n",
        "# client.create_bucket(Bucket='seamless-model')\n",
        "\n",
        "# # List all buckets on your account.\n",
        "# response = client.list_buckets()"
      ],
      "metadata": {
        "id": "pKMKBIdN5GDL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # For Llama model\n",
        "# model, tokenizer = load_model_from_s3(\n",
        "#     bucket=\"my-bucket\",\n",
        "#     path_to_model=\"models/llama-3.1-8b-instruct\",\n",
        "#     endpoint_url=endpoint,\n",
        "#     verify_ssl=False,\n",
        "#     model_class=\"LlamaForCausalLM\",\n",
        "#     enable_debug=True\n",
        "# )"
      ],
      "metadata": {
        "id": "_ChlOgdWJ8ET"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load Seamless model\n",
        "# model, processor = load_model_from_s3(\n",
        "#     bucket=\"my-bucket\",\n",
        "#     path_to_model=\"models/seamless-m4t-v2-large\",\n",
        "#     endpoint_url=endpoint,\n",
        "#     verify_ssl=False,\n",
        "#     enable_debug=True\n",
        "# )"
      ],
      "metadata": {
        "id": "nr8pWY5DT1pd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    model, tokenizer = load_model_from_s3(\n",
        "        bucket=\"seamless-model\",\n",
        "        path_to_model=\"models/seamless-m4t-v2-large\",\n",
        "        endpoint_url=endpoint,\n",
        "        verify_ssl=True,\n",
        "        enable_debug=True\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(f\"Failed to load model: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b47cf842b49a42b38048e1050bf45d5d",
            "75f9840adeb74cd99f5660c9b1ceb3b5",
            "0d7ae27d612b4cc7abf134189f8a09bf",
            "daeb91c290504dce838bfa4eb46a2b1e",
            "91644ae5917c4170b544214c76735244",
            "36172467967e4090bf84c29a16d21eca",
            "56eaa1d5fd884bc2bc1036d07697b7e5",
            "08405cc0659946c1ad4529ea0b626401",
            "216eb8fc28fa4b0b81e6ed3e943d7dbc",
            "0b6854ec5e5d49a7ba289bfd9737cccf",
            "da88133d48604464b176c161fbc74555"
          ]
        },
        "id": "Ym10bHeIT30E",
        "outputId": "91c7ccd5-0cc7-4e5e-b9a0-d312e00e563d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #0066cc\">[04:02:29] INFO: Starting model load from bucket: seamless-model, path: models/seamless-m4t-v2-large</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #0066cc\">[04:02:29] INFO: Listing files in bucket...</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:30] DEBUG: \n",
              "Found files in S3:</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:30] DEBUG: - models/seamless-m4t-v2-large/README.md</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:30] DEBUG: - models/seamless-m4t-v2-large/added_tokens.json</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:30] DEBUG: - models/seamless-m4t-v2-large/config.json</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:30] DEBUG: - models/seamless-m4t-v2-large/generation_config.json</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:30] DEBUG: - models/seamless-m4t-v2-large/m4t_v2_multitask_unity2.pt</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:30] DEBUG: - models/seamless-m4t-v2-large/model-00001-of-00002.safetensors</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:30] DEBUG: - models/seamless-m4t-v2-large/model-00002-of-00002.safetensors</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:30] DEBUG: - models/seamless-m4t-v2-large/model.safetensors.index.json</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:30] DEBUG: - models/seamless-m4t-v2-large/preprocessor_config.json</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:30] DEBUG: - models/seamless-m4t-v2-large/seamlessM4T_v2_large.pt</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:30] DEBUG: - models/seamless-m4t-v2-large/seamlessm4t_arch.svg</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:30] DEBUG: - models/seamless-m4t-v2-large/sentencepiece.bpe.model</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:30] DEBUG: - models/seamless-m4t-v2-large/special_tokens_map.json</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:30] DEBUG: - models/seamless-m4t-v2-large/spm_char_lang38_tc.model</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:30] DEBUG: - models/seamless-m4t-v2-large/tokenizer.model</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:30] DEBUG: - models/seamless-m4t-v2-large/tokenizer_config.json</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:30] DEBUG: - models/seamless-m4t-v2-large/vocoder_v2.pt</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:30] DEBUG: \n",
              "Created temporary directory: /tmp/tmpk78mj4vs</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:30] DEBUG: Downloading: models/seamless-m4t-v2-large/config.json to /tmp/tmpk78mj4vs/config.json</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:31] DEBUG: Successfully downloaded models/seamless-m4t-v2-large/config.json (2716 bytes)</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:31] DEBUG: \n",
              "Detected model type: seamless_m4t_v2</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:31] DEBUG: \n",
              "Downloading auxiliary files:</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:31] DEBUG: Downloading: models/seamless-m4t-v2-large/config.json to /tmp/tmpk78mj4vs/config.json</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:31] DEBUG: Successfully downloaded models/seamless-m4t-v2-large/config.json (2716 bytes)</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:31] DEBUG: Downloading: models/seamless-m4t-v2-large/generation_config.json to /tmp/tmpk78mj4vs/generation_config.json</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:34] DEBUG: Successfully downloaded models/seamless-m4t-v2-large/generation_config.json (9906948 bytes)</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:34] DEBUG: Downloading: models/seamless-m4t-v2-large/preprocessor_config.json to /tmp/tmpk78mj4vs/preprocessor_config.json</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:34] DEBUG: Successfully downloaded models/seamless-m4t-v2-large/preprocessor_config.json (1776 bytes)</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:34] DEBUG: Downloading: models/seamless-m4t-v2-large/special_tokens_map.json to /tmp/tmpk78mj4vs/special_tokens_map.json</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:35] DEBUG: Successfully downloaded models/seamless-m4t-v2-large/special_tokens_map.json (2337 bytes)</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:35] DEBUG: Downloading: models/seamless-m4t-v2-large/tokenizer.model to /tmp/tmpk78mj4vs/tokenizer.model</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:35] DEBUG: Successfully downloaded models/seamless-m4t-v2-large/tokenizer.model (5165809 bytes)</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:35] DEBUG: Downloading: models/seamless-m4t-v2-large/tokenizer_config.json to /tmp/tmpk78mj4vs/tokenizer_config.json</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:36] DEBUG: Successfully downloaded models/seamless-m4t-v2-large/tokenizer_config.json (19667 bytes)</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:36] DEBUG: Found 2 sharded safetensors files</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:36] DEBUG: \n",
              "Downloading safetensors files:</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:02:36] DEBUG: Downloading: models/seamless-m4t-v2-large/model-00001-of-00002.safetensors to /tmp/tmpk78mj4vs/model-00001-of-00002.safetensors</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:08:30] DEBUG: Successfully downloaded models/seamless-m4t-v2-large/model-00001-of-00002.safetensors (4999163080 bytes)</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:08:30] DEBUG: Downloading: models/seamless-m4t-v2-large/model-00002-of-00002.safetensors to /tmp/tmpk78mj4vs/model-00002-of-00002.safetensors</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:14:19] DEBUG: Successfully downloaded models/seamless-m4t-v2-large/model-00002-of-00002.safetensors (4238114628 bytes)</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:14:19] DEBUG: \n",
              "Creating index file for sharded safetensors</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:14:19] DEBUG: Created index file at /tmp/tmpk78mj4vs/model.safetensors.index.json</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:14:19] DEBUG: \n",
              "Directory contents:</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:14:19] DEBUG: --------------------------------------------------</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:14:19] DEBUG: File: special_tokens_map.json (2337 bytes)</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:14:19] DEBUG: File: model-00002-of-00002.safetensors (4238114628 bytes)</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:14:19] DEBUG: File: model.safetensors.index.json (141 bytes)</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:14:19] DEBUG: File: tokenizer.model (5165809 bytes)</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:14:19] DEBUG: File: config.json (2716 bytes)</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:14:19] DEBUG: File: preprocessor_config.json (1776 bytes)</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:14:19] DEBUG: File: model-00001-of-00002.safetensors (4999163080 bytes)</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:14:19] DEBUG: File: generation_config.json (9906948 bytes)</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:14:19] DEBUG: File: tokenizer_config.json (19667 bytes)</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:14:19] DEBUG: --------------------------------------------------</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #0066cc\">[04:14:19] INFO: \n",
              "Loading model...</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:14:19] DEBUG: Loading model from path: /tmp/tmpk78mj4vs</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:14:19] DEBUG: Using specific model class: SeamlessM4Tv2Model</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b47cf842b49a42b38048e1050bf45d5d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at /tmp/tmpk78mj4vs were not used when initializing SeamlessM4Tv2Model: ['param_0', 'param_1']\n",
            "- This IS expected if you are initializing SeamlessM4Tv2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing SeamlessM4Tv2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of SeamlessM4Tv2Model were not initialized from the model checkpoint at /tmp/tmpk78mj4vs and are newly initialized: ['lm_head.weight', 'shared.weight', 'speech_encoder.adapter.layers.0.ffn.intermediate_dense.bias', 'speech_encoder.adapter.layers.0.ffn.intermediate_dense.weight', 'speech_encoder.adapter.layers.0.ffn.output_dense.bias', 'speech_encoder.adapter.layers.0.ffn.output_dense.weight', 'speech_encoder.adapter.layers.0.ffn_layer_norm.bias', 'speech_encoder.adapter.layers.0.ffn_layer_norm.weight', 'speech_encoder.adapter.layers.0.residual_conv.bias', 'speech_encoder.adapter.layers.0.residual_conv.weight', 'speech_encoder.adapter.layers.0.residual_layer_norm.bias', 'speech_encoder.adapter.layers.0.residual_layer_norm.weight', 'speech_encoder.adapter.layers.0.self_attn.linear_k.bias', 'speech_encoder.adapter.layers.0.self_attn.linear_k.weight', 'speech_encoder.adapter.layers.0.self_attn.linear_out.bias', 'speech_encoder.adapter.layers.0.self_attn.linear_out.weight', 'speech_encoder.adapter.layers.0.self_attn.linear_q.bias', 'speech_encoder.adapter.layers.0.self_attn.linear_q.weight', 'speech_encoder.adapter.layers.0.self_attn.linear_v.bias', 'speech_encoder.adapter.layers.0.self_attn.linear_v.weight', 'speech_encoder.adapter.layers.0.self_attn_conv.bias', 'speech_encoder.adapter.layers.0.self_attn_conv.weight', 'speech_encoder.adapter.layers.0.self_attn_layer_norm.bias', 'speech_encoder.adapter.layers.0.self_attn_layer_norm.weight', 'speech_encoder.encoder.layer_norm.bias', 'speech_encoder.encoder.layer_norm.weight', 'speech_encoder.encoder.layers.0.conv_module.depthwise_conv.weight', 'speech_encoder.encoder.layers.0.conv_module.depthwise_layer_norm.bias', 'speech_encoder.encoder.layers.0.conv_module.depthwise_layer_norm.weight', 'speech_encoder.encoder.layers.0.conv_module.layer_norm.bias', 'speech_encoder.encoder.layers.0.conv_module.layer_norm.weight', 'speech_encoder.encoder.layers.0.conv_module.pointwise_conv1.weight', 'speech_encoder.encoder.layers.0.conv_module.pointwise_conv2.weight', 'speech_encoder.encoder.layers.0.ffn1.intermediate_dense.bias', 'speech_encoder.encoder.layers.0.ffn1.intermediate_dense.weight', 'speech_encoder.encoder.layers.0.ffn1.output_dense.bias', 'speech_encoder.encoder.layers.0.ffn1.output_dense.weight', 'speech_encoder.encoder.layers.0.ffn1_layer_norm.bias', 'speech_encoder.encoder.layers.0.ffn1_layer_norm.weight', 'speech_encoder.encoder.layers.0.ffn2.intermediate_dense.bias', 'speech_encoder.encoder.layers.0.ffn2.intermediate_dense.weight', 'speech_encoder.encoder.layers.0.ffn2.output_dense.bias', 'speech_encoder.encoder.layers.0.ffn2.output_dense.weight', 'speech_encoder.encoder.layers.0.ffn2_layer_norm.bias', 'speech_encoder.encoder.layers.0.ffn2_layer_norm.weight', 'speech_encoder.encoder.layers.0.final_layer_norm.bias', 'speech_encoder.encoder.layers.0.final_layer_norm.weight', 'speech_encoder.encoder.layers.0.self_attn.distance_embedding.weight', 'speech_encoder.encoder.layers.0.self_attn.linear_k.bias', 'speech_encoder.encoder.layers.0.self_attn.linear_k.weight', 'speech_encoder.encoder.layers.0.self_attn.linear_out.bias', 'speech_encoder.encoder.layers.0.self_attn.linear_out.weight', 'speech_encoder.encoder.layers.0.self_attn.linear_q.bias', 'speech_encoder.encoder.layers.0.self_attn.linear_q.weight', 'speech_encoder.encoder.layers.0.self_attn.linear_v.bias', 'speech_encoder.encoder.layers.0.self_attn.linear_v.weight', 'speech_encoder.encoder.layers.0.self_attn_layer_norm.bias', 'speech_encoder.encoder.layers.0.self_attn_layer_norm.weight', 'speech_encoder.encoder.layers.1.conv_module.depthwise_conv.weight', 'speech_encoder.encoder.layers.1.conv_module.depthwise_layer_norm.bias', 'speech_encoder.encoder.layers.1.conv_module.depthwise_layer_norm.weight', 'speech_encoder.encoder.layers.1.conv_module.layer_norm.bias', 'speech_encoder.encoder.layers.1.conv_module.layer_norm.weight', 'speech_encoder.encoder.layers.1.conv_module.pointwise_conv1.weight', 'speech_encoder.encoder.layers.1.conv_module.pointwise_conv2.weight', 'speech_encoder.encoder.layers.1.ffn1.intermediate_dense.bias', 'speech_encoder.encoder.layers.1.ffn1.intermediate_dense.weight', 'speech_encoder.encoder.layers.1.ffn1.output_dense.bias', 'speech_encoder.encoder.layers.1.ffn1.output_dense.weight', 'speech_encoder.encoder.layers.1.ffn1_layer_norm.bias', 'speech_encoder.encoder.layers.1.ffn1_layer_norm.weight', 'speech_encoder.encoder.layers.1.ffn2.intermediate_dense.bias', 'speech_encoder.encoder.layers.1.ffn2.intermediate_dense.weight', 'speech_encoder.encoder.layers.1.ffn2.output_dense.bias', 'speech_encoder.encoder.layers.1.ffn2.output_dense.weight', 'speech_encoder.encoder.layers.1.ffn2_layer_norm.bias', 'speech_encoder.encoder.layers.1.ffn2_layer_norm.weight', 'speech_encoder.encoder.layers.1.final_layer_norm.bias', 'speech_encoder.encoder.layers.1.final_layer_norm.weight', 'speech_encoder.encoder.layers.1.self_attn.distance_embedding.weight', 'speech_encoder.encoder.layers.1.self_attn.linear_k.bias', 'speech_encoder.encoder.layers.1.self_attn.linear_k.weight', 'speech_encoder.encoder.layers.1.self_attn.linear_out.bias', 'speech_encoder.encoder.layers.1.self_attn.linear_out.weight', 'speech_encoder.encoder.layers.1.self_attn.linear_q.bias', 'speech_encoder.encoder.layers.1.self_attn.linear_q.weight', 'speech_encoder.encoder.layers.1.self_attn.linear_v.bias', 'speech_encoder.encoder.layers.1.self_attn.linear_v.weight', 'speech_encoder.encoder.layers.1.self_attn_layer_norm.bias', 'speech_encoder.encoder.layers.1.self_attn_layer_norm.weight', 'speech_encoder.encoder.layers.10.conv_module.depthwise_conv.weight', 'speech_encoder.encoder.layers.10.conv_module.depthwise_layer_norm.bias', 'speech_encoder.encoder.layers.10.conv_module.depthwise_layer_norm.weight', 'speech_encoder.encoder.layers.10.conv_module.layer_norm.bias', 'speech_encoder.encoder.layers.10.conv_module.layer_norm.weight', 'speech_encoder.encoder.layers.10.conv_module.pointwise_conv1.weight', 'speech_encoder.encoder.layers.10.conv_module.pointwise_conv2.weight', 'speech_encoder.encoder.layers.10.ffn1.intermediate_dense.bias', 'speech_encoder.encoder.layers.10.ffn1.intermediate_dense.weight', 'speech_encoder.encoder.layers.10.ffn1.output_dense.bias', 'speech_encoder.encoder.layers.10.ffn1.output_dense.weight', 'speech_encoder.encoder.layers.10.ffn1_layer_norm.bias', 'speech_encoder.encoder.layers.10.ffn1_layer_norm.weight', 'speech_encoder.encoder.layers.10.ffn2.intermediate_dense.bias', 'speech_encoder.encoder.layers.10.ffn2.intermediate_dense.weight', 'speech_encoder.encoder.layers.10.ffn2.output_dense.bias', 'speech_encoder.encoder.layers.10.ffn2.output_dense.weight', 'speech_encoder.encoder.layers.10.ffn2_layer_norm.bias', 'speech_encoder.encoder.layers.10.ffn2_layer_norm.weight', 'speech_encoder.encoder.layers.10.final_layer_norm.bias', 'speech_encoder.encoder.layers.10.final_layer_norm.weight', 'speech_encoder.encoder.layers.10.self_attn.distance_embedding.weight', 'speech_encoder.encoder.layers.10.self_attn.linear_k.bias', 'speech_encoder.encoder.layers.10.self_attn.linear_k.weight', 'speech_encoder.encoder.layers.10.self_attn.linear_out.bias', 'speech_encoder.encoder.layers.10.self_attn.linear_out.weight', 'speech_encoder.encoder.layers.10.self_attn.linear_q.bias', 'speech_encoder.encoder.layers.10.self_attn.linear_q.weight', 'speech_encoder.encoder.layers.10.self_attn.linear_v.bias', 'speech_encoder.encoder.layers.10.self_attn.linear_v.weight', 'speech_encoder.encoder.layers.10.self_attn_layer_norm.bias', 'speech_encoder.encoder.layers.10.self_attn_layer_norm.weight', 'speech_encoder.encoder.layers.11.conv_module.depthwise_conv.weight', 'speech_encoder.encoder.layers.11.conv_module.depthwise_layer_norm.bias', 'speech_encoder.encoder.layers.11.conv_module.depthwise_layer_norm.weight', 'speech_encoder.encoder.layers.11.conv_module.layer_norm.bias', 'speech_encoder.encoder.layers.11.conv_module.layer_norm.weight', 'speech_encoder.encoder.layers.11.conv_module.pointwise_conv1.weight', 'speech_encoder.encoder.layers.11.conv_module.pointwise_conv2.weight', 'speech_encoder.encoder.layers.11.ffn1.intermediate_dense.bias', 'speech_encoder.encoder.layers.11.ffn1.intermediate_dense.weight', 'speech_encoder.encoder.layers.11.ffn1.output_dense.bias', 'speech_encoder.encoder.layers.11.ffn1.output_dense.weight', 'speech_encoder.encoder.layers.11.ffn1_layer_norm.bias', 'speech_encoder.encoder.layers.11.ffn1_layer_norm.weight', 'speech_encoder.encoder.layers.11.ffn2.intermediate_dense.bias', 'speech_encoder.encoder.layers.11.ffn2.intermediate_dense.weight', 'speech_encoder.encoder.layers.11.ffn2.output_dense.bias', 'speech_encoder.encoder.layers.11.ffn2.output_dense.weight', 'speech_encoder.encoder.layers.11.ffn2_layer_norm.bias', 'speech_encoder.encoder.layers.11.ffn2_layer_norm.weight', 'speech_encoder.encoder.layers.11.final_layer_norm.bias', 'speech_encoder.encoder.layers.11.final_layer_norm.weight', 'speech_encoder.encoder.layers.11.self_attn.distance_embedding.weight', 'speech_encoder.encoder.layers.11.self_attn.linear_k.bias', 'speech_encoder.encoder.layers.11.self_attn.linear_k.weight', 'speech_encoder.encoder.layers.11.self_attn.linear_out.bias', 'speech_encoder.encoder.layers.11.self_attn.linear_out.weight', 'speech_encoder.encoder.layers.11.self_attn.linear_q.bias', 'speech_encoder.encoder.layers.11.self_attn.linear_q.weight', 'speech_encoder.encoder.layers.11.self_attn.linear_v.bias', 'speech_encoder.encoder.layers.11.self_attn.linear_v.weight', 'speech_encoder.encoder.layers.11.self_attn_layer_norm.bias', 'speech_encoder.encoder.layers.11.self_attn_layer_norm.weight', 'speech_encoder.encoder.layers.12.conv_module.depthwise_conv.weight', 'speech_encoder.encoder.layers.12.conv_module.depthwise_layer_norm.bias', 'speech_encoder.encoder.layers.12.conv_module.depthwise_layer_norm.weight', 'speech_encoder.encoder.layers.12.conv_module.layer_norm.bias', 'speech_encoder.encoder.layers.12.conv_module.layer_norm.weight', 'speech_encoder.encoder.layers.12.conv_module.pointwise_conv1.weight', 'speech_encoder.encoder.layers.12.conv_module.pointwise_conv2.weight', 'speech_encoder.encoder.layers.12.ffn1.intermediate_dense.bias', 'speech_encoder.encoder.layers.12.ffn1.intermediate_dense.weight', 'speech_encoder.encoder.layers.12.ffn1.output_dense.bias', 'speech_encoder.encoder.layers.12.ffn1.output_dense.weight', 'speech_encoder.encoder.layers.12.ffn1_layer_norm.bias', 'speech_encoder.encoder.layers.12.ffn1_layer_norm.weight', 'speech_encoder.encoder.layers.12.ffn2.intermediate_dense.bias', 'speech_encoder.encoder.layers.12.ffn2.intermediate_dense.weight', 'speech_encoder.encoder.layers.12.ffn2.output_dense.bias', 'speech_encoder.encoder.layers.12.ffn2.output_dense.weight', 'speech_encoder.encoder.layers.12.ffn2_layer_norm.bias', 'speech_encoder.encoder.layers.12.ffn2_layer_norm.weight', 'speech_encoder.encoder.layers.12.final_layer_norm.bias', 'speech_encoder.encoder.layers.12.final_layer_norm.weight', 'speech_encoder.encoder.layers.12.self_attn.distance_embedding.weight', 'speech_encoder.encoder.layers.12.self_attn.linear_k.bias', 'speech_encoder.encoder.layers.12.self_attn.linear_k.weight', 'speech_encoder.encoder.layers.12.self_attn.linear_out.bias', 'speech_encoder.encoder.layers.12.self_attn.linear_out.weight', 'speech_encoder.encoder.layers.12.self_attn.linear_q.bias', 'speech_encoder.encoder.layers.12.self_attn.linear_q.weight', 'speech_encoder.encoder.layers.12.self_attn.linear_v.bias', 'speech_encoder.encoder.layers.12.self_attn.linear_v.weight', 'speech_encoder.encoder.layers.12.self_attn_layer_norm.bias', 'speech_encoder.encoder.layers.12.self_attn_layer_norm.weight', 'speech_encoder.encoder.layers.13.conv_module.depthwise_conv.weight', 'speech_encoder.encoder.layers.13.conv_module.depthwise_layer_norm.bias', 'speech_encoder.encoder.layers.13.conv_module.depthwise_layer_norm.weight', 'speech_encoder.encoder.layers.13.conv_module.layer_norm.bias', 'speech_encoder.encoder.layers.13.conv_module.layer_norm.weight', 'speech_encoder.encoder.layers.13.conv_module.pointwise_conv1.weight', 'speech_encoder.encoder.layers.13.conv_module.pointwise_conv2.weight', 'speech_encoder.encoder.layers.13.ffn1.intermediate_dense.bias', 'speech_encoder.encoder.layers.13.ffn1.intermediate_dense.weight', 'speech_encoder.encoder.layers.13.ffn1.output_dense.bias', 'speech_encoder.encoder.layers.13.ffn1.output_dense.weight', 'speech_encoder.encoder.layers.13.ffn1_layer_norm.bias', 'speech_encoder.encoder.layers.13.ffn1_layer_norm.weight', 'speech_encoder.encoder.layers.13.ffn2.intermediate_dense.bias', 'speech_encoder.encoder.layers.13.ffn2.intermediate_dense.weight', 'speech_encoder.encoder.layers.13.ffn2.output_dense.bias', 'speech_encoder.encoder.layers.13.ffn2.output_dense.weight', 'speech_encoder.encoder.layers.13.ffn2_layer_norm.bias', 'speech_encoder.encoder.layers.13.ffn2_layer_norm.weight', 'speech_encoder.encoder.layers.13.final_layer_norm.bias', 'speech_encoder.encoder.layers.13.final_layer_norm.weight', 'speech_encoder.encoder.layers.13.self_attn.distance_embedding.weight', 'speech_encoder.encoder.layers.13.self_attn.linear_k.bias', 'speech_encoder.encoder.layers.13.self_attn.linear_k.weight', 'speech_encoder.encoder.layers.13.self_attn.linear_out.bias', 'speech_encoder.encoder.layers.13.self_attn.linear_out.weight', 'speech_encoder.encoder.layers.13.self_attn.linear_q.bias', 'speech_encoder.encoder.layers.13.self_attn.linear_q.weight', 'speech_encoder.encoder.layers.13.self_attn.linear_v.bias', 'speech_encoder.encoder.layers.13.self_attn.linear_v.weight', 'speech_encoder.encoder.layers.13.self_attn_layer_norm.bias', 'speech_encoder.encoder.layers.13.self_attn_layer_norm.weight', 'speech_encoder.encoder.layers.14.conv_module.depthwise_conv.weight', 'speech_encoder.encoder.layers.14.conv_module.depthwise_layer_norm.bias', 'speech_encoder.encoder.layers.14.conv_module.depthwise_layer_norm.weight', 'speech_encoder.encoder.layers.14.conv_module.layer_norm.bias', 'speech_encoder.encoder.layers.14.conv_module.layer_norm.weight', 'speech_encoder.encoder.layers.14.conv_module.pointwise_conv1.weight', 'speech_encoder.encoder.layers.14.conv_module.pointwise_conv2.weight', 'speech_encoder.encoder.layers.14.ffn1.intermediate_dense.bias', 'speech_encoder.encoder.layers.14.ffn1.intermediate_dense.weight', 'speech_encoder.encoder.layers.14.ffn1.output_dense.bias', 'speech_encoder.encoder.layers.14.ffn1.output_dense.weight', 'speech_encoder.encoder.layers.14.ffn1_layer_norm.bias', 'speech_encoder.encoder.layers.14.ffn1_layer_norm.weight', 'speech_encoder.encoder.layers.14.ffn2.intermediate_dense.bias', 'speech_encoder.encoder.layers.14.ffn2.intermediate_dense.weight', 'speech_encoder.encoder.layers.14.ffn2.output_dense.bias', 'speech_encoder.encoder.layers.14.ffn2.output_dense.weight', 'speech_encoder.encoder.layers.14.ffn2_layer_norm.bias', 'speech_encoder.encoder.layers.14.ffn2_layer_norm.weight', 'speech_encoder.encoder.layers.14.final_layer_norm.bias', 'speech_encoder.encoder.layers.14.final_layer_norm.weight', 'speech_encoder.encoder.layers.14.self_attn.distance_embedding.weight', 'speech_encoder.encoder.layers.14.self_attn.linear_k.bias', 'speech_encoder.encoder.layers.14.self_attn.linear_k.weight', 'speech_encoder.encoder.layers.14.self_attn.linear_out.bias', 'speech_encoder.encoder.layers.14.self_attn.linear_out.weight', 'speech_encoder.encoder.layers.14.self_attn.linear_q.bias', 'speech_encoder.encoder.layers.14.self_attn.linear_q.weight', 'speech_encoder.encoder.layers.14.self_attn.linear_v.bias', 'speech_encoder.encoder.layers.14.self_attn.linear_v.weight', 'speech_encoder.encoder.layers.14.self_attn_layer_norm.bias', 'speech_encoder.encoder.layers.14.self_attn_layer_norm.weight', 'speech_encoder.encoder.layers.15.conv_module.depthwise_conv.weight', 'speech_encoder.encoder.layers.15.conv_module.depthwise_layer_norm.bias', 'speech_encoder.encoder.layers.15.conv_module.depthwise_layer_norm.weight', 'speech_encoder.encoder.layers.15.conv_module.layer_norm.bias', 'speech_encoder.encoder.layers.15.conv_module.layer_norm.weight', 'speech_encoder.encoder.layers.15.conv_module.pointwise_conv1.weight', 'speech_encoder.encoder.layers.15.conv_module.pointwise_conv2.weight', 'speech_encoder.encoder.layers.15.ffn1.intermediate_dense.bias', 'speech_encoder.encoder.layers.15.ffn1.intermediate_dense.weight', 'speech_encoder.encoder.layers.15.ffn1.output_dense.bias', 'speech_encoder.encoder.layers.15.ffn1.output_dense.weight', 'speech_encoder.encoder.layers.15.ffn1_layer_norm.bias', 'speech_encoder.encoder.layers.15.ffn1_layer_norm.weight', 'speech_encoder.encoder.layers.15.ffn2.intermediate_dense.bias', 'speech_encoder.encoder.layers.15.ffn2.intermediate_dense.weight', 'speech_encoder.encoder.layers.15.ffn2.output_dense.bias', 'speech_encoder.encoder.layers.15.ffn2.output_dense.weight', 'speech_encoder.encoder.layers.15.ffn2_layer_norm.bias', 'speech_encoder.encoder.layers.15.ffn2_layer_norm.weight', 'speech_encoder.encoder.layers.15.final_layer_norm.bias', 'speech_encoder.encoder.layers.15.final_layer_norm.weight', 'speech_encoder.encoder.layers.15.self_attn.distance_embedding.weight', 'speech_encoder.encoder.layers.15.self_attn.linear_k.bias', 'speech_encoder.encoder.layers.15.self_attn.linear_k.weight', 'speech_encoder.encoder.layers.15.self_attn.linear_out.bias', 'speech_encoder.encoder.layers.15.self_attn.linear_out.weight', 'speech_encoder.encoder.layers.15.self_attn.linear_q.bias', 'speech_encoder.encoder.layers.15.self_attn.linear_q.weight', 'speech_encoder.encoder.layers.15.self_attn.linear_v.bias', 'speech_encoder.encoder.layers.15.self_attn.linear_v.weight', 'speech_encoder.encoder.layers.15.self_attn_layer_norm.bias', 'speech_encoder.encoder.layers.15.self_attn_layer_norm.weight', 'speech_encoder.encoder.layers.16.conv_module.depthwise_conv.weight', 'speech_encoder.encoder.layers.16.conv_module.depthwise_layer_norm.bias', 'speech_encoder.encoder.layers.16.conv_module.depthwise_layer_norm.weight', 'speech_encoder.encoder.layers.16.conv_module.layer_norm.bias', 'speech_encoder.encoder.layers.16.conv_module.layer_norm.weight', 'speech_encoder.encoder.layers.16.conv_module.pointwise_conv1.weight', 'speech_encoder.encoder.layers.16.conv_module.pointwise_conv2.weight', 'speech_encoder.encoder.layers.16.ffn1.intermediate_dense.bias', 'speech_encoder.encoder.layers.16.ffn1.intermediate_dense.weight', 'speech_encoder.encoder.layers.16.ffn1.output_dense.bias', 'speech_encoder.encoder.layers.16.ffn1.output_dense.weight', 'speech_encoder.encoder.layers.16.ffn1_layer_norm.bias', 'speech_encoder.encoder.layers.16.ffn1_layer_norm.weight', 'speech_encoder.encoder.layers.16.ffn2.intermediate_dense.bias', 'speech_encoder.encoder.layers.16.ffn2.intermediate_dense.weight', 'speech_encoder.encoder.layers.16.ffn2.output_dense.bias', 'speech_encoder.encoder.layers.16.ffn2.output_dense.weight', 'speech_encoder.encoder.layers.16.ffn2_layer_norm.bias', 'speech_encoder.encoder.layers.16.ffn2_layer_norm.weight', 'speech_encoder.encoder.layers.16.final_layer_norm.bias', 'speech_encoder.encoder.layers.16.final_layer_norm.weight', 'speech_encoder.encoder.layers.16.self_attn.distance_embedding.weight', 'speech_encoder.encoder.layers.16.self_attn.linear_k.bias', 'speech_encoder.encoder.layers.16.self_attn.linear_k.weight', 'speech_encoder.encoder.layers.16.self_attn.linear_out.bias', 'speech_encoder.encoder.layers.16.self_attn.linear_out.weight', 'speech_encoder.encoder.layers.16.self_attn.linear_q.bias', 'speech_encoder.encoder.layers.16.self_attn.linear_q.weight', 'speech_encoder.encoder.layers.16.self_attn.linear_v.bias', 'speech_encoder.encoder.layers.16.self_attn.linear_v.weight', 'speech_encoder.encoder.layers.16.self_attn_layer_norm.bias', 'speech_encoder.encoder.layers.16.self_attn_layer_norm.weight', 'speech_encoder.encoder.layers.17.conv_module.depthwise_conv.weight', 'speech_encoder.encoder.layers.17.conv_module.depthwise_layer_norm.bias', 'speech_encoder.encoder.layers.17.conv_module.depthwise_layer_norm.weight', 'speech_encoder.encoder.layers.17.conv_module.layer_norm.bias', 'speech_encoder.encoder.layers.17.conv_module.layer_norm.weight', 'speech_encoder.encoder.layers.17.conv_module.pointwise_conv1.weight', 'speech_encoder.encoder.layers.17.conv_module.pointwise_conv2.weight', 'speech_encoder.encoder.layers.17.ffn1.intermediate_dense.bias', 'speech_encoder.encoder.layers.17.ffn1.intermediate_dense.weight', 'speech_encoder.encoder.layers.17.ffn1.output_dense.bias', 'speech_encoder.encoder.layers.17.ffn1.output_dense.weight', 'speech_encoder.encoder.layers.17.ffn1_layer_norm.bias', 'speech_encoder.encoder.layers.17.ffn1_layer_norm.weight', 'speech_encoder.encoder.layers.17.ffn2.intermediate_dense.bias', 'speech_encoder.encoder.layers.17.ffn2.intermediate_dense.weight', 'speech_encoder.encoder.layers.17.ffn2.output_dense.bias', 'speech_encoder.encoder.layers.17.ffn2.output_dense.weight', 'speech_encoder.encoder.layers.17.ffn2_layer_norm.bias', 'speech_encoder.encoder.layers.17.ffn2_layer_norm.weight', 'speech_encoder.encoder.layers.17.final_layer_norm.bias', 'speech_encoder.encoder.layers.17.final_layer_norm.weight', 'speech_encoder.encoder.layers.17.self_attn.distance_embedding.weight', 'speech_encoder.encoder.layers.17.self_attn.linear_k.bias', 'speech_encoder.encoder.layers.17.self_attn.linear_k.weight', 'speech_encoder.encoder.layers.17.self_attn.linear_out.bias', 'speech_encoder.encoder.layers.17.self_attn.linear_out.weight', 'speech_encoder.encoder.layers.17.self_attn.linear_q.bias', 'speech_encoder.encoder.layers.17.self_attn.linear_q.weight', 'speech_encoder.encoder.layers.17.self_attn.linear_v.bias', 'speech_encoder.encoder.layers.17.self_attn.linear_v.weight', 'speech_encoder.encoder.layers.17.self_attn_layer_norm.bias', 'speech_encoder.encoder.layers.17.self_attn_layer_norm.weight', 'speech_encoder.encoder.layers.18.conv_module.depthwise_conv.weight', 'speech_encoder.encoder.layers.18.conv_module.depthwise_layer_norm.bias', 'speech_encoder.encoder.layers.18.conv_module.depthwise_layer_norm.weight', 'speech_encoder.encoder.layers.18.conv_module.layer_norm.bias', 'speech_encoder.encoder.layers.18.conv_module.layer_norm.weight', 'speech_encoder.encoder.layers.18.conv_module.pointwise_conv1.weight', 'speech_encoder.encoder.layers.18.conv_module.pointwise_conv2.weight', 'speech_encoder.encoder.layers.18.ffn1.intermediate_dense.bias', 'speech_encoder.encoder.layers.18.ffn1.intermediate_dense.weight', 'speech_encoder.encoder.layers.18.ffn1.output_dense.bias', 'speech_encoder.encoder.layers.18.ffn1.output_dense.weight', 'speech_encoder.encoder.layers.18.ffn1_layer_norm.bias', 'speech_encoder.encoder.layers.18.ffn1_layer_norm.weight', 'speech_encoder.encoder.layers.18.ffn2.intermediate_dense.bias', 'speech_encoder.encoder.layers.18.ffn2.intermediate_dense.weight', 'speech_encoder.encoder.layers.18.ffn2.output_dense.bias', 'speech_encoder.encoder.layers.18.ffn2.output_dense.weight', 'speech_encoder.encoder.layers.18.ffn2_layer_norm.bias', 'speech_encoder.encoder.layers.18.ffn2_layer_norm.weight', 'speech_encoder.encoder.layers.18.final_layer_norm.bias', 'speech_encoder.encoder.layers.18.final_layer_norm.weight', 'speech_encoder.encoder.layers.18.self_attn.distance_embedding.weight', 'speech_encoder.encoder.layers.18.self_attn.linear_k.bias', 'speech_encoder.encoder.layers.18.self_attn.linear_k.weight', 'speech_encoder.encoder.layers.18.self_attn.linear_out.bias', 'speech_encoder.encoder.layers.18.self_attn.linear_out.weight', 'speech_encoder.encoder.layers.18.self_attn.linear_q.bias', 'speech_encoder.encoder.layers.18.self_attn.linear_q.weight', 'speech_encoder.encoder.layers.18.self_attn.linear_v.bias', 'speech_encoder.encoder.layers.18.self_attn.linear_v.weight', 'speech_encoder.encoder.layers.18.self_attn_layer_norm.bias', 'speech_encoder.encoder.layers.18.self_attn_layer_norm.weight', 'speech_encoder.encoder.layers.19.conv_module.depthwise_conv.weight', 'speech_encoder.encoder.layers.19.conv_module.depthwise_layer_norm.bias', 'speech_encoder.encoder.layers.19.conv_module.depthwise_layer_norm.weight', 'speech_encoder.encoder.layers.19.conv_module.layer_norm.bias', 'speech_encoder.encoder.layers.19.conv_module.layer_norm.weight', 'speech_encoder.encoder.layers.19.conv_module.pointwise_conv1.weight', 'speech_encoder.encoder.layers.19.conv_module.pointwise_conv2.weight', 'speech_encoder.encoder.layers.19.ffn1.intermediate_dense.bias', 'speech_encoder.encoder.layers.19.ffn1.intermediate_dense.weight', 'speech_encoder.encoder.layers.19.ffn1.output_dense.bias', 'speech_encoder.encoder.layers.19.ffn1.output_dense.weight', 'speech_encoder.encoder.layers.19.ffn1_layer_norm.bias', 'speech_encoder.encoder.layers.19.ffn1_layer_norm.weight', 'speech_encoder.encoder.layers.19.ffn2.intermediate_dense.bias', 'speech_encoder.encoder.layers.19.ffn2.intermediate_dense.weight', 'speech_encoder.encoder.layers.19.ffn2.output_dense.bias', 'speech_encoder.encoder.layers.19.ffn2.output_dense.weight', 'speech_encoder.encoder.layers.19.ffn2_layer_norm.bias', 'speech_encoder.encoder.layers.19.ffn2_layer_norm.weight', 'speech_encoder.encoder.layers.19.final_layer_norm.bias', 'speech_encoder.encoder.layers.19.final_layer_norm.weight', 'speech_encoder.encoder.layers.19.self_attn.distance_embedding.weight', 'speech_encoder.encoder.layers.19.self_attn.linear_k.bias', 'speech_encoder.encoder.layers.19.self_attn.linear_k.weight', 'speech_encoder.encoder.layers.19.self_attn.linear_out.bias', 'speech_encoder.encoder.layers.19.self_attn.linear_out.weight', 'speech_encoder.encoder.layers.19.self_attn.linear_q.bias', 'speech_encoder.encoder.layers.19.self_attn.linear_q.weight', 'speech_encoder.encoder.layers.19.self_attn.linear_v.bias', 'speech_encoder.encoder.layers.19.self_attn.linear_v.weight', 'speech_encoder.encoder.layers.19.self_attn_layer_norm.bias', 'speech_encoder.encoder.layers.19.self_attn_layer_norm.weight', 'speech_encoder.encoder.layers.2.conv_module.depthwise_conv.weight', 'speech_encoder.encoder.layers.2.conv_module.depthwise_layer_norm.bias', 'speech_encoder.encoder.layers.2.conv_module.depthwise_layer_norm.weight', 'speech_encoder.encoder.layers.2.conv_module.layer_norm.bias', 'speech_encoder.encoder.layers.2.conv_module.layer_norm.weight', 'speech_encoder.encoder.layers.2.conv_module.pointwise_conv1.weight', 'speech_encoder.encoder.layers.2.conv_module.pointwise_conv2.weight', 'speech_encoder.encoder.layers.2.ffn1.intermediate_dense.bias', 'speech_encoder.encoder.layers.2.ffn1.intermediate_dense.weight', 'speech_encoder.encoder.layers.2.ffn1.output_dense.bias', 'speech_encoder.encoder.layers.2.ffn1.output_dense.weight', 'speech_encoder.encoder.layers.2.ffn1_layer_norm.bias', 'speech_encoder.encoder.layers.2.ffn1_layer_norm.weight', 'speech_encoder.encoder.layers.2.ffn2.intermediate_dense.bias', 'speech_encoder.encoder.layers.2.ffn2.intermediate_dense.weight', 'speech_encoder.encoder.layers.2.ffn2.output_dense.bias', 'speech_encoder.encoder.layers.2.ffn2.output_dense.weight', 'speech_encoder.encoder.layers.2.ffn2_layer_norm.bias', 'speech_encoder.encoder.layers.2.ffn2_layer_norm.weight', 'speech_encoder.encoder.layers.2.final_layer_norm.bias', 'speech_encoder.encoder.layers.2.final_layer_norm.weight', 'speech_encoder.encoder.layers.2.self_attn.distance_embedding.weight', 'speech_encoder.encoder.layers.2.self_attn.linear_k.bias', 'speech_encoder.encoder.layers.2.self_attn.linear_k.weight', 'speech_encoder.encoder.layers.2.self_attn.linear_out.bias', 'speech_encoder.encoder.layers.2.self_attn.linear_out.weight', 'speech_encoder.encoder.layers.2.self_attn.linear_q.bias', 'speech_encoder.encoder.layers.2.self_attn.linear_q.weight', 'speech_encoder.encoder.layers.2.self_attn.linear_v.bias', 'speech_encoder.encoder.layers.2.self_attn.linear_v.weight', 'speech_encoder.encoder.layers.2.self_attn_layer_norm.bias', 'speech_encoder.encoder.layers.2.self_attn_layer_norm.weight', 'speech_encoder.encoder.layers.20.conv_module.depthwise_conv.weight', 'speech_encoder.encoder.layers.20.conv_module.depthwise_layer_norm.bias', 'speech_encoder.encoder.layers.20.conv_module.depthwise_layer_norm.weight', 'speech_encoder.encoder.layers.20.conv_module.layer_norm.bias', 'speech_encoder.encoder.layers.20.conv_module.layer_norm.weight', 'speech_encoder.encoder.layers.20.conv_module.pointwise_conv1.weight', 'speech_encoder.encoder.layers.20.conv_module.pointwise_conv2.weight', 'speech_encoder.encoder.layers.20.ffn1.intermediate_dense.bias', 'speech_encoder.encoder.layers.20.ffn1.intermediate_dense.weight', 'speech_encoder.encoder.layers.20.ffn1.output_dense.bias', 'speech_encoder.encoder.layers.20.ffn1.output_dense.weight', 'speech_encoder.encoder.layers.20.ffn1_layer_norm.bias', 'speech_encoder.encoder.layers.20.ffn1_layer_norm.weight', 'speech_encoder.encoder.layers.20.ffn2.intermediate_dense.bias', 'speech_encoder.encoder.layers.20.ffn2.intermediate_dense.weight', 'speech_encoder.encoder.layers.20.ffn2.output_dense.bias', 'speech_encoder.encoder.layers.20.ffn2.output_dense.weight', 'speech_encoder.encoder.layers.20.ffn2_layer_norm.bias', 'speech_encoder.encoder.layers.20.ffn2_layer_norm.weight', 'speech_encoder.encoder.layers.20.final_layer_norm.bias', 'speech_encoder.encoder.layers.20.final_layer_norm.weight', 'speech_encoder.encoder.layers.20.self_attn.distance_embedding.weight', 'speech_encoder.encoder.layers.20.self_attn.linear_k.bias', 'speech_encoder.encoder.layers.20.self_attn.linear_k.weight', 'speech_encoder.encoder.layers.20.self_attn.linear_out.bias', 'speech_encoder.encoder.layers.20.self_attn.linear_out.weight', 'speech_encoder.encoder.layers.20.self_attn.linear_q.bias', 'speech_encoder.encoder.layers.20.self_attn.linear_q.weight', 'speech_encoder.encoder.layers.20.self_attn.linear_v.bias', 'speech_encoder.encoder.layers.20.self_attn.linear_v.weight', 'speech_encoder.encoder.layers.20.self_attn_layer_norm.bias', 'speech_encoder.encoder.layers.20.self_attn_layer_norm.weight', 'speech_encoder.encoder.layers.21.conv_module.depthwise_conv.weight', 'speech_encoder.encoder.layers.21.conv_module.depthwise_layer_norm.bias', 'speech_encoder.encoder.layers.21.conv_module.depthwise_layer_norm.weight', 'speech_encoder.encoder.layers.21.conv_module.layer_norm.bias', 'speech_encoder.encoder.layers.21.conv_module.layer_norm.weight', 'speech_encoder.encoder.layers.21.conv_module.pointwise_conv1.weight', 'speech_encoder.encoder.layers.21.conv_module.pointwise_conv2.weight', 'speech_encoder.encoder.layers.21.ffn1.intermediate_dense.bias', 'speech_encoder.encoder.layers.21.ffn1.intermediate_dense.weight', 'speech_encoder.encoder.layers.21.ffn1.output_dense.bias', 'speech_encoder.encoder.layers.21.ffn1.output_dense.weight', 'speech_encoder.encoder.layers.21.ffn1_layer_norm.bias', 'speech_encoder.encoder.layers.21.ffn1_layer_norm.weight', 'speech_encoder.encoder.layers.21.ffn2.intermediate_dense.bias', 'speech_encoder.encoder.layers.21.ffn2.intermediate_dense.weight', 'speech_encoder.encoder.layers.21.ffn2.output_dense.bias', 'speech_encoder.encoder.layers.21.ffn2.output_dense.weight', 'speech_encoder.encoder.layers.21.ffn2_layer_norm.bias', 'speech_encoder.encoder.layers.21.ffn2_layer_norm.weight', 'speech_encoder.encoder.layers.21.final_layer_norm.bias', 'speech_encoder.encoder.layers.21.final_layer_norm.weight', 'speech_encoder.encoder.layers.21.self_attn.distance_embedding.weight', 'speech_encoder.encoder.layers.21.self_attn.linear_k.bias', 'speech_encoder.encoder.layers.21.self_attn.linear_k.weight', 'speech_encoder.encoder.layers.21.self_attn.linear_out.bias', 'speech_encoder.encoder.layers.21.self_attn.linear_out.weight', 'speech_encoder.encoder.layers.21.self_attn.linear_q.bias', 'speech_encoder.encoder.layers.21.self_attn.linear_q.weight', 'speech_encoder.encoder.layers.21.self_attn.linear_v.bias', 'speech_encoder.encoder.layers.21.self_attn.linear_v.weight', 'speech_encoder.encoder.layers.21.self_attn_layer_norm.bias', 'speech_encoder.encoder.layers.21.self_attn_layer_norm.weight', 'speech_encoder.encoder.layers.22.conv_module.depthwise_conv.weight', 'speech_encoder.encoder.layers.22.conv_module.depthwise_layer_norm.bias', 'speech_encoder.encoder.layers.22.conv_module.depthwise_layer_norm.weight', 'speech_encoder.encoder.layers.22.conv_module.layer_norm.bias', 'speech_encoder.encoder.layers.22.conv_module.layer_norm.weight', 'speech_encoder.encoder.layers.22.conv_module.pointwise_conv1.weight', 'speech_encoder.encoder.layers.22.conv_module.pointwise_conv2.weight', 'speech_encoder.encoder.layers.22.ffn1.intermediate_dense.bias', 'speech_encoder.encoder.layers.22.ffn1.intermediate_dense.weight', 'speech_encoder.encoder.layers.22.ffn1.output_dense.bias', 'speech_encoder.encoder.layers.22.ffn1.output_dense.weight', 'speech_encoder.encoder.layers.22.ffn1_layer_norm.bias', 'speech_encoder.encoder.layers.22.ffn1_layer_norm.weight', 'speech_encoder.encoder.layers.22.ffn2.intermediate_dense.bias', 'speech_encoder.encoder.layers.22.ffn2.intermediate_dense.weight', 'speech_encoder.encoder.layers.22.ffn2.output_dense.bias', 'speech_encoder.encoder.layers.22.ffn2.output_dense.weight', 'speech_encoder.encoder.layers.22.ffn2_layer_norm.bias', 'speech_encoder.encoder.layers.22.ffn2_layer_norm.weight', 'speech_encoder.encoder.layers.22.final_layer_norm.bias', 'speech_encoder.encoder.layers.22.final_layer_norm.weight', 'speech_encoder.encoder.layers.22.self_attn.distance_embedding.weight', 'speech_encoder.encoder.layers.22.self_attn.linear_k.bias', 'speech_encoder.encoder.layers.22.self_attn.linear_k.weight', 'speech_encoder.encoder.layers.22.self_attn.linear_out.bias', 'speech_encoder.encoder.layers.22.self_attn.linear_out.weight', 'speech_encoder.encoder.layers.22.self_attn.linear_q.bias', 'speech_encoder.encoder.layers.22.self_attn.linear_q.weight', 'speech_encoder.encoder.layers.22.self_attn.linear_v.bias', 'speech_encoder.encoder.layers.22.self_attn.linear_v.weight', 'speech_encoder.encoder.layers.22.self_attn_layer_norm.bias', 'speech_encoder.encoder.layers.22.self_attn_layer_norm.weight', 'speech_encoder.encoder.layers.23.conv_module.depthwise_conv.weight', 'speech_encoder.encoder.layers.23.conv_module.depthwise_layer_norm.bias', 'speech_encoder.encoder.layers.23.conv_module.depthwise_layer_norm.weight', 'speech_encoder.encoder.layers.23.conv_module.layer_norm.bias', 'speech_encoder.encoder.layers.23.conv_module.layer_norm.weight', 'speech_encoder.encoder.layers.23.conv_module.pointwise_conv1.weight', 'speech_encoder.encoder.layers.23.conv_module.pointwise_conv2.weight', 'speech_encoder.encoder.layers.23.ffn1.intermediate_dense.bias', 'speech_encoder.encoder.layers.23.ffn1.intermediate_dense.weight', 'speech_encoder.encoder.layers.23.ffn1.output_dense.bias', 'speech_encoder.encoder.layers.23.ffn1.output_dense.weight', 'speech_encoder.encoder.layers.23.ffn1_layer_norm.bias', 'speech_encoder.encoder.layers.23.ffn1_layer_norm.weight', 'speech_encoder.encoder.layers.23.ffn2.intermediate_dense.bias', 'speech_encoder.encoder.layers.23.ffn2.intermediate_dense.weight', 'speech_encoder.encoder.layers.23.ffn2.output_dense.bias', 'speech_encoder.encoder.layers.23.ffn2.output_dense.weight', 'speech_encoder.encoder.layers.23.ffn2_layer_norm.bias', 'speech_encoder.encoder.layers.23.ffn2_layer_norm.weight', 'speech_encoder.encoder.layers.23.final_layer_norm.bias', 'speech_encoder.encoder.layers.23.final_layer_norm.weight', 'speech_encoder.encoder.layers.23.self_attn.distance_embedding.weight', 'speech_encoder.encoder.layers.23.self_attn.linear_k.bias', 'speech_encoder.encoder.layers.23.self_attn.linear_k.weight', 'speech_encoder.encoder.layers.23.self_attn.linear_out.bias', 'speech_encoder.encoder.layers.23.self_attn.linear_out.weight', 'speech_encoder.encoder.layers.23.self_attn.linear_q.bias', 'speech_encoder.encoder.layers.23.self_attn.linear_q.weight', 'speech_encoder.encoder.layers.23.self_attn.linear_v.bias', 'speech_encoder.encoder.layers.23.self_attn.linear_v.weight', 'speech_encoder.encoder.layers.23.self_attn_layer_norm.bias', 'speech_encoder.encoder.layers.23.self_attn_layer_norm.weight', 'speech_encoder.encoder.layers.3.conv_module.depthwise_conv.weight', 'speech_encoder.encoder.layers.3.conv_module.depthwise_layer_norm.bias', 'speech_encoder.encoder.layers.3.conv_module.depthwise_layer_norm.weight', 'speech_encoder.encoder.layers.3.conv_module.layer_norm.bias', 'speech_encoder.encoder.layers.3.conv_module.layer_norm.weight', 'speech_encoder.encoder.layers.3.conv_module.pointwise_conv1.weight', 'speech_encoder.encoder.layers.3.conv_module.pointwise_conv2.weight', 'speech_encoder.encoder.layers.3.ffn1.intermediate_dense.bias', 'speech_encoder.encoder.layers.3.ffn1.intermediate_dense.weight', 'speech_encoder.encoder.layers.3.ffn1.output_dense.bias', 'speech_encoder.encoder.layers.3.ffn1.output_dense.weight', 'speech_encoder.encoder.layers.3.ffn1_layer_norm.bias', 'speech_encoder.encoder.layers.3.ffn1_layer_norm.weight', 'speech_encoder.encoder.layers.3.ffn2.intermediate_dense.bias', 'speech_encoder.encoder.layers.3.ffn2.intermediate_dense.weight', 'speech_encoder.encoder.layers.3.ffn2.output_dense.bias', 'speech_encoder.encoder.layers.3.ffn2.output_dense.weight', 'speech_encoder.encoder.layers.3.ffn2_layer_norm.bias', 'speech_encoder.encoder.layers.3.ffn2_layer_norm.weight', 'speech_encoder.encoder.layers.3.final_layer_norm.bias', 'speech_encoder.encoder.layers.3.final_layer_norm.weight', 'speech_encoder.encoder.layers.3.self_attn.distance_embedding.weight', 'speech_encoder.encoder.layers.3.self_attn.linear_k.bias', 'speech_encoder.encoder.layers.3.self_attn.linear_k.weight', 'speech_encoder.encoder.layers.3.self_attn.linear_out.bias', 'speech_encoder.encoder.layers.3.self_attn.linear_out.weight', 'speech_encoder.encoder.layers.3.self_attn.linear_q.bias', 'speech_encoder.encoder.layers.3.self_attn.linear_q.weight', 'speech_encoder.encoder.layers.3.self_attn.linear_v.bias', 'speech_encoder.encoder.layers.3.self_attn.linear_v.weight', 'speech_encoder.encoder.layers.3.self_attn_layer_norm.bias', 'speech_encoder.encoder.layers.3.self_attn_layer_norm.weight', 'speech_encoder.encoder.layers.4.conv_module.depthwise_conv.weight', 'speech_encoder.encoder.layers.4.conv_module.depthwise_layer_norm.bias', 'speech_encoder.encoder.layers.4.conv_module.depthwise_layer_norm.weight', 'speech_encoder.encoder.layers.4.conv_module.layer_norm.bias', 'speech_encoder.encoder.layers.4.conv_module.layer_norm.weight', 'speech_encoder.encoder.layers.4.conv_module.pointwise_conv1.weight', 'speech_encoder.encoder.layers.4.conv_module.pointwise_conv2.weight', 'speech_encoder.encoder.layers.4.ffn1.intermediate_dense.bias', 'speech_encoder.encoder.layers.4.ffn1.intermediate_dense.weight', 'speech_encoder.encoder.layers.4.ffn1.output_dense.bias', 'speech_encoder.encoder.layers.4.ffn1.output_dense.weight', 'speech_encoder.encoder.layers.4.ffn1_layer_norm.bias', 'speech_encoder.encoder.layers.4.ffn1_layer_norm.weight', 'speech_encoder.encoder.layers.4.ffn2.intermediate_dense.bias', 'speech_encoder.encoder.layers.4.ffn2.intermediate_dense.weight', 'speech_encoder.encoder.layers.4.ffn2.output_dense.bias', 'speech_encoder.encoder.layers.4.ffn2.output_dense.weight', 'speech_encoder.encoder.layers.4.ffn2_layer_norm.bias', 'speech_encoder.encoder.layers.4.ffn2_layer_norm.weight', 'speech_encoder.encoder.layers.4.final_layer_norm.bias', 'speech_encoder.encoder.layers.4.final_layer_norm.weight', 'speech_encoder.encoder.layers.4.self_attn.distance_embedding.weight', 'speech_encoder.encoder.layers.4.self_attn.linear_k.bias', 'speech_encoder.encoder.layers.4.self_attn.linear_k.weight', 'speech_encoder.encoder.layers.4.self_attn.linear_out.bias', 'speech_encoder.encoder.layers.4.self_attn.linear_out.weight', 'speech_encoder.encoder.layers.4.self_attn.linear_q.bias', 'speech_encoder.encoder.layers.4.self_attn.linear_q.weight', 'speech_encoder.encoder.layers.4.self_attn.linear_v.bias', 'speech_encoder.encoder.layers.4.self_attn.linear_v.weight', 'speech_encoder.encoder.layers.4.self_attn_layer_norm.bias', 'speech_encoder.encoder.layers.4.self_attn_layer_norm.weight', 'speech_encoder.encoder.layers.5.conv_module.depthwise_conv.weight', 'speech_encoder.encoder.layers.5.conv_module.depthwise_layer_norm.bias', 'speech_encoder.encoder.layers.5.conv_module.depthwise_layer_norm.weight', 'speech_encoder.encoder.layers.5.conv_module.layer_norm.bias', 'speech_encoder.encoder.layers.5.conv_module.layer_norm.weight', 'speech_encoder.encoder.layers.5.conv_module.pointwise_conv1.weight', 'speech_encoder.encoder.layers.5.conv_module.pointwise_conv2.weight', 'speech_encoder.encoder.layers.5.ffn1.intermediate_dense.bias', 'speech_encoder.encoder.layers.5.ffn1.intermediate_dense.weight', 'speech_encoder.encoder.layers.5.ffn1.output_dense.bias', 'speech_encoder.encoder.layers.5.ffn1.output_dense.weight', 'speech_encoder.encoder.layers.5.ffn1_layer_norm.bias', 'speech_encoder.encoder.layers.5.ffn1_layer_norm.weight', 'speech_encoder.encoder.layers.5.ffn2.intermediate_dense.bias', 'speech_encoder.encoder.layers.5.ffn2.intermediate_dense.weight', 'speech_encoder.encoder.layers.5.ffn2.output_dense.bias', 'speech_encoder.encoder.layers.5.ffn2.output_dense.weight', 'speech_encoder.encoder.layers.5.ffn2_layer_norm.bias', 'speech_encoder.encoder.layers.5.ffn2_layer_norm.weight', 'speech_encoder.encoder.layers.5.final_layer_norm.bias', 'speech_encoder.encoder.layers.5.final_layer_norm.weight', 'speech_encoder.encoder.layers.5.self_attn.distance_embedding.weight', 'speech_encoder.encoder.layers.5.self_attn.linear_k.bias', 'speech_encoder.encoder.layers.5.self_attn.linear_k.weight', 'speech_encoder.encoder.layers.5.self_attn.linear_out.bias', 'speech_encoder.encoder.layers.5.self_attn.linear_out.weight', 'speech_encoder.encoder.layers.5.self_attn.linear_q.bias', 'speech_encoder.encoder.layers.5.self_attn.linear_q.weight', 'speech_encoder.encoder.layers.5.self_attn.linear_v.bias', 'speech_encoder.encoder.layers.5.self_attn.linear_v.weight', 'speech_encoder.encoder.layers.5.self_attn_layer_norm.bias', 'speech_encoder.encoder.layers.5.self_attn_layer_norm.weight', 'speech_encoder.encoder.layers.6.conv_module.depthwise_conv.weight', 'speech_encoder.encoder.layers.6.conv_module.depthwise_layer_norm.bias', 'speech_encoder.encoder.layers.6.conv_module.depthwise_layer_norm.weight', 'speech_encoder.encoder.layers.6.conv_module.layer_norm.bias', 'speech_encoder.encoder.layers.6.conv_module.layer_norm.weight', 'speech_encoder.encoder.layers.6.conv_module.pointwise_conv1.weight', 'speech_encoder.encoder.layers.6.conv_module.pointwise_conv2.weight', 'speech_encoder.encoder.layers.6.ffn1.intermediate_dense.bias', 'speech_encoder.encoder.layers.6.ffn1.intermediate_dense.weight', 'speech_encoder.encoder.layers.6.ffn1.output_dense.bias', 'speech_encoder.encoder.layers.6.ffn1.output_dense.weight', 'speech_encoder.encoder.layers.6.ffn1_layer_norm.bias', 'speech_encoder.encoder.layers.6.ffn1_layer_norm.weight', 'speech_encoder.encoder.layers.6.ffn2.intermediate_dense.bias', 'speech_encoder.encoder.layers.6.ffn2.intermediate_dense.weight', 'speech_encoder.encoder.layers.6.ffn2.output_dense.bias', 'speech_encoder.encoder.layers.6.ffn2.output_dense.weight', 'speech_encoder.encoder.layers.6.ffn2_layer_norm.bias', 'speech_encoder.encoder.layers.6.ffn2_layer_norm.weight', 'speech_encoder.encoder.layers.6.final_layer_norm.bias', 'speech_encoder.encoder.layers.6.final_layer_norm.weight', 'speech_encoder.encoder.layers.6.self_attn.distance_embedding.weight', 'speech_encoder.encoder.layers.6.self_attn.linear_k.bias', 'speech_encoder.encoder.layers.6.self_attn.linear_k.weight', 'speech_encoder.encoder.layers.6.self_attn.linear_out.bias', 'speech_encoder.encoder.layers.6.self_attn.linear_out.weight', 'speech_encoder.encoder.layers.6.self_attn.linear_q.bias', 'speech_encoder.encoder.layers.6.self_attn.linear_q.weight', 'speech_encoder.encoder.layers.6.self_attn.linear_v.bias', 'speech_encoder.encoder.layers.6.self_attn.linear_v.weight', 'speech_encoder.encoder.layers.6.self_attn_layer_norm.bias', 'speech_encoder.encoder.layers.6.self_attn_layer_norm.weight', 'speech_encoder.encoder.layers.7.conv_module.depthwise_conv.weight', 'speech_encoder.encoder.layers.7.conv_module.depthwise_layer_norm.bias', 'speech_encoder.encoder.layers.7.conv_module.depthwise_layer_norm.weight', 'speech_encoder.encoder.layers.7.conv_module.layer_norm.bias', 'speech_encoder.encoder.layers.7.conv_module.layer_norm.weight', 'speech_encoder.encoder.layers.7.conv_module.pointwise_conv1.weight', 'speech_encoder.encoder.layers.7.conv_module.pointwise_conv2.weight', 'speech_encoder.encoder.layers.7.ffn1.intermediate_dense.bias', 'speech_encoder.encoder.layers.7.ffn1.intermediate_dense.weight', 'speech_encoder.encoder.layers.7.ffn1.output_dense.bias', 'speech_encoder.encoder.layers.7.ffn1.output_dense.weight', 'speech_encoder.encoder.layers.7.ffn1_layer_norm.bias', 'speech_encoder.encoder.layers.7.ffn1_layer_norm.weight', 'speech_encoder.encoder.layers.7.ffn2.intermediate_dense.bias', 'speech_encoder.encoder.layers.7.ffn2.intermediate_dense.weight', 'speech_encoder.encoder.layers.7.ffn2.output_dense.bias', 'speech_encoder.encoder.layers.7.ffn2.output_dense.weight', 'speech_encoder.encoder.layers.7.ffn2_layer_norm.bias', 'speech_encoder.encoder.layers.7.ffn2_layer_norm.weight', 'speech_encoder.encoder.layers.7.final_layer_norm.bias', 'speech_encoder.encoder.layers.7.final_layer_norm.weight', 'speech_encoder.encoder.layers.7.self_attn.distance_embedding.weight', 'speech_encoder.encoder.layers.7.self_attn.linear_k.bias', 'speech_encoder.encoder.layers.7.self_attn.linear_k.weight', 'speech_encoder.encoder.layers.7.self_attn.linear_out.bias', 'speech_encoder.encoder.layers.7.self_attn.linear_out.weight', 'speech_encoder.encoder.layers.7.self_attn.linear_q.bias', 'speech_encoder.encoder.layers.7.self_attn.linear_q.weight', 'speech_encoder.encoder.layers.7.self_attn.linear_v.bias', 'speech_encoder.encoder.layers.7.self_attn.linear_v.weight', 'speech_encoder.encoder.layers.7.self_attn_layer_norm.bias', 'speech_encoder.encoder.layers.7.self_attn_layer_norm.weight', 'speech_encoder.encoder.layers.8.conv_module.depthwise_conv.weight', 'speech_encoder.encoder.layers.8.conv_module.depthwise_layer_norm.bias', 'speech_encoder.encoder.layers.8.conv_module.depthwise_layer_norm.weight', 'speech_encoder.encoder.layers.8.conv_module.layer_norm.bias', 'speech_encoder.encoder.layers.8.conv_module.layer_norm.weight', 'speech_encoder.encoder.layers.8.conv_module.pointwise_conv1.weight', 'speech_encoder.encoder.layers.8.conv_module.pointwise_conv2.weight', 'speech_encoder.encoder.layers.8.ffn1.intermediate_dense.bias', 'speech_encoder.encoder.layers.8.ffn1.intermediate_dense.weight', 'speech_encoder.encoder.layers.8.ffn1.output_dense.bias', 'speech_encoder.encoder.layers.8.ffn1.output_dense.weight', 'speech_encoder.encoder.layers.8.ffn1_layer_norm.bias', 'speech_encoder.encoder.layers.8.ffn1_layer_norm.weight', 'speech_encoder.encoder.layers.8.ffn2.intermediate_dense.bias', 'speech_encoder.encoder.layers.8.ffn2.intermediate_dense.weight', 'speech_encoder.encoder.layers.8.ffn2.output_dense.bias', 'speech_encoder.encoder.layers.8.ffn2.output_dense.weight', 'speech_encoder.encoder.layers.8.ffn2_layer_norm.bias', 'speech_encoder.encoder.layers.8.ffn2_layer_norm.weight', 'speech_encoder.encoder.layers.8.final_layer_norm.bias', 'speech_encoder.encoder.layers.8.final_layer_norm.weight', 'speech_encoder.encoder.layers.8.self_attn.distance_embedding.weight', 'speech_encoder.encoder.layers.8.self_attn.linear_k.bias', 'speech_encoder.encoder.layers.8.self_attn.linear_k.weight', 'speech_encoder.encoder.layers.8.self_attn.linear_out.bias', 'speech_encoder.encoder.layers.8.self_attn.linear_out.weight', 'speech_encoder.encoder.layers.8.self_attn.linear_q.bias', 'speech_encoder.encoder.layers.8.self_attn.linear_q.weight', 'speech_encoder.encoder.layers.8.self_attn.linear_v.bias', 'speech_encoder.encoder.layers.8.self_attn.linear_v.weight', 'speech_encoder.encoder.layers.8.self_attn_layer_norm.bias', 'speech_encoder.encoder.layers.8.self_attn_layer_norm.weight', 'speech_encoder.encoder.layers.9.conv_module.depthwise_conv.weight', 'speech_encoder.encoder.layers.9.conv_module.depthwise_layer_norm.bias', 'speech_encoder.encoder.layers.9.conv_module.depthwise_layer_norm.weight', 'speech_encoder.encoder.layers.9.conv_module.layer_norm.bias', 'speech_encoder.encoder.layers.9.conv_module.layer_norm.weight', 'speech_encoder.encoder.layers.9.conv_module.pointwise_conv1.weight', 'speech_encoder.encoder.layers.9.conv_module.pointwise_conv2.weight', 'speech_encoder.encoder.layers.9.ffn1.intermediate_dense.bias', 'speech_encoder.encoder.layers.9.ffn1.intermediate_dense.weight', 'speech_encoder.encoder.layers.9.ffn1.output_dense.bias', 'speech_encoder.encoder.layers.9.ffn1.output_dense.weight', 'speech_encoder.encoder.layers.9.ffn1_layer_norm.bias', 'speech_encoder.encoder.layers.9.ffn1_layer_norm.weight', 'speech_encoder.encoder.layers.9.ffn2.intermediate_dense.bias', 'speech_encoder.encoder.layers.9.ffn2.intermediate_dense.weight', 'speech_encoder.encoder.layers.9.ffn2.output_dense.bias', 'speech_encoder.encoder.layers.9.ffn2.output_dense.weight', 'speech_encoder.encoder.layers.9.ffn2_layer_norm.bias', 'speech_encoder.encoder.layers.9.ffn2_layer_norm.weight', 'speech_encoder.encoder.layers.9.final_layer_norm.bias', 'speech_encoder.encoder.layers.9.final_layer_norm.weight', 'speech_encoder.encoder.layers.9.self_attn.distance_embedding.weight', 'speech_encoder.encoder.layers.9.self_attn.linear_k.bias', 'speech_encoder.encoder.layers.9.self_attn.linear_k.weight', 'speech_encoder.encoder.layers.9.self_attn.linear_out.bias', 'speech_encoder.encoder.layers.9.self_attn.linear_out.weight', 'speech_encoder.encoder.layers.9.self_attn.linear_q.bias', 'speech_encoder.encoder.layers.9.self_attn.linear_q.weight', 'speech_encoder.encoder.layers.9.self_attn.linear_v.bias', 'speech_encoder.encoder.layers.9.self_attn.linear_v.weight', 'speech_encoder.encoder.layers.9.self_attn_layer_norm.bias', 'speech_encoder.encoder.layers.9.self_attn_layer_norm.weight', 'speech_encoder.feature_projection.layer_norm.bias', 'speech_encoder.feature_projection.layer_norm.weight', 'speech_encoder.feature_projection.projection.bias', 'speech_encoder.feature_projection.projection.weight', 'speech_encoder.inner_layer_norm.bias', 'speech_encoder.inner_layer_norm.weight', 'speech_encoder.intermediate_ffn.intermediate_dense.bias', 'speech_encoder.intermediate_ffn.intermediate_dense.weight', 'speech_encoder.intermediate_ffn.output_dense.bias', 'speech_encoder.intermediate_ffn.output_dense.weight', 't2u_model.lm_head.weight', 't2u_model.model.decoder.duration_predictor.conv1.bias', 't2u_model.model.decoder.duration_predictor.conv1.weight', 't2u_model.model.decoder.duration_predictor.conv2.bias', 't2u_model.model.decoder.duration_predictor.conv2.weight', 't2u_model.model.decoder.duration_predictor.ln1.bias', 't2u_model.model.decoder.duration_predictor.ln1.weight', 't2u_model.model.decoder.duration_predictor.ln2.bias', 't2u_model.model.decoder.duration_predictor.ln2.weight', 't2u_model.model.decoder.duration_predictor.proj.bias', 't2u_model.model.decoder.duration_predictor.proj.weight', 't2u_model.model.decoder.embed_char.weight', 't2u_model.model.decoder.embed_tokens.weight', 't2u_model.model.decoder.layer_norm.bias', 't2u_model.model.decoder.layer_norm.weight', 't2u_model.model.decoder.layers.0.conv1.bias', 't2u_model.model.decoder.layers.0.conv1.weight', 't2u_model.model.decoder.layers.0.conv2.bias', 't2u_model.model.decoder.layers.0.conv2.weight', 't2u_model.model.decoder.layers.0.conv_layer_norm.bias', 't2u_model.model.decoder.layers.0.conv_layer_norm.weight', 't2u_model.model.decoder.layers.0.self_attn.k_proj.bias', 't2u_model.model.decoder.layers.0.self_attn.k_proj.weight', 't2u_model.model.decoder.layers.0.self_attn.out_proj.bias', 't2u_model.model.decoder.layers.0.self_attn.out_proj.weight', 't2u_model.model.decoder.layers.0.self_attn.q_proj.bias', 't2u_model.model.decoder.layers.0.self_attn.q_proj.weight', 't2u_model.model.decoder.layers.0.self_attn.v_proj.bias', 't2u_model.model.decoder.layers.0.self_attn.v_proj.weight', 't2u_model.model.decoder.layers.0.self_attn_layer_norm.bias', 't2u_model.model.decoder.layers.0.self_attn_layer_norm.weight', 't2u_model.model.decoder.layers.1.conv1.bias', 't2u_model.model.decoder.layers.1.conv1.weight', 't2u_model.model.decoder.layers.1.conv2.bias', 't2u_model.model.decoder.layers.1.conv2.weight', 't2u_model.model.decoder.layers.1.conv_layer_norm.bias', 't2u_model.model.decoder.layers.1.conv_layer_norm.weight', 't2u_model.model.decoder.layers.1.self_attn.k_proj.bias', 't2u_model.model.decoder.layers.1.self_attn.k_proj.weight', 't2u_model.model.decoder.layers.1.self_attn.out_proj.bias', 't2u_model.model.decoder.layers.1.self_attn.out_proj.weight', 't2u_model.model.decoder.layers.1.self_attn.q_proj.bias', 't2u_model.model.decoder.layers.1.self_attn.q_proj.weight', 't2u_model.model.decoder.layers.1.self_attn.v_proj.bias', 't2u_model.model.decoder.layers.1.self_attn.v_proj.weight', 't2u_model.model.decoder.layers.1.self_attn_layer_norm.bias', 't2u_model.model.decoder.layers.1.self_attn_layer_norm.weight', 't2u_model.model.decoder.layers.2.conv1.bias', 't2u_model.model.decoder.layers.2.conv1.weight', 't2u_model.model.decoder.layers.2.conv2.bias', 't2u_model.model.decoder.layers.2.conv2.weight', 't2u_model.model.decoder.layers.2.conv_layer_norm.bias', 't2u_model.model.decoder.layers.2.conv_layer_norm.weight', 't2u_model.model.decoder.layers.2.self_attn.k_proj.bias', 't2u_model.model.decoder.layers.2.self_attn.k_proj.weight', 't2u_model.model.decoder.layers.2.self_attn.out_proj.bias', 't2u_model.model.decoder.layers.2.self_attn.out_proj.weight', 't2u_model.model.decoder.layers.2.self_attn.q_proj.bias', 't2u_model.model.decoder.layers.2.self_attn.q_proj.weight', 't2u_model.model.decoder.layers.2.self_attn.v_proj.bias', 't2u_model.model.decoder.layers.2.self_attn.v_proj.weight', 't2u_model.model.decoder.layers.2.self_attn_layer_norm.bias', 't2u_model.model.decoder.layers.2.self_attn_layer_norm.weight', 't2u_model.model.decoder.layers.3.conv1.bias', 't2u_model.model.decoder.layers.3.conv1.weight', 't2u_model.model.decoder.layers.3.conv2.bias', 't2u_model.model.decoder.layers.3.conv2.weight', 't2u_model.model.decoder.layers.3.conv_layer_norm.bias', 't2u_model.model.decoder.layers.3.conv_layer_norm.weight', 't2u_model.model.decoder.layers.3.self_attn.k_proj.bias', 't2u_model.model.decoder.layers.3.self_attn.k_proj.weight', 't2u_model.model.decoder.layers.3.self_attn.out_proj.bias', 't2u_model.model.decoder.layers.3.self_attn.out_proj.weight', 't2u_model.model.decoder.layers.3.self_attn.q_proj.bias', 't2u_model.model.decoder.layers.3.self_attn.q_proj.weight', 't2u_model.model.decoder.layers.3.self_attn.v_proj.bias', 't2u_model.model.decoder.layers.3.self_attn.v_proj.weight', 't2u_model.model.decoder.layers.3.self_attn_layer_norm.bias', 't2u_model.model.decoder.layers.3.self_attn_layer_norm.weight', 't2u_model.model.decoder.layers.4.conv1.bias', 't2u_model.model.decoder.layers.4.conv1.weight', 't2u_model.model.decoder.layers.4.conv2.bias', 't2u_model.model.decoder.layers.4.conv2.weight', 't2u_model.model.decoder.layers.4.conv_layer_norm.bias', 't2u_model.model.decoder.layers.4.conv_layer_norm.weight', 't2u_model.model.decoder.layers.4.self_attn.k_proj.bias', 't2u_model.model.decoder.layers.4.self_attn.k_proj.weight', 't2u_model.model.decoder.layers.4.self_attn.out_proj.bias', 't2u_model.model.decoder.layers.4.self_attn.out_proj.weight', 't2u_model.model.decoder.layers.4.self_attn.q_proj.bias', 't2u_model.model.decoder.layers.4.self_attn.q_proj.weight', 't2u_model.model.decoder.layers.4.self_attn.v_proj.bias', 't2u_model.model.decoder.layers.4.self_attn.v_proj.weight', 't2u_model.model.decoder.layers.4.self_attn_layer_norm.bias', 't2u_model.model.decoder.layers.4.self_attn_layer_norm.weight', 't2u_model.model.decoder.layers.5.conv1.bias', 't2u_model.model.decoder.layers.5.conv1.weight', 't2u_model.model.decoder.layers.5.conv2.bias', 't2u_model.model.decoder.layers.5.conv2.weight', 't2u_model.model.decoder.layers.5.conv_layer_norm.bias', 't2u_model.model.decoder.layers.5.conv_layer_norm.weight', 't2u_model.model.decoder.layers.5.self_attn.k_proj.bias', 't2u_model.model.decoder.layers.5.self_attn.k_proj.weight', 't2u_model.model.decoder.layers.5.self_attn.out_proj.bias', 't2u_model.model.decoder.layers.5.self_attn.out_proj.weight', 't2u_model.model.decoder.layers.5.self_attn.q_proj.bias', 't2u_model.model.decoder.layers.5.self_attn.q_proj.weight', 't2u_model.model.decoder.layers.5.self_attn.v_proj.bias', 't2u_model.model.decoder.layers.5.self_attn.v_proj.weight', 't2u_model.model.decoder.layers.5.self_attn_layer_norm.bias', 't2u_model.model.decoder.layers.5.self_attn_layer_norm.weight', 't2u_model.model.decoder.pos_emb_alpha', 't2u_model.model.decoder.pos_emb_alpha_char', 't2u_model.model.encoder.layer_norm.bias', 't2u_model.model.encoder.layer_norm.weight', 't2u_model.model.encoder.layers.0.ffn.fc1.bias', 't2u_model.model.encoder.layers.0.ffn.fc1.weight', 't2u_model.model.encoder.layers.0.ffn.fc2.bias', 't2u_model.model.encoder.layers.0.ffn.fc2.weight', 't2u_model.model.encoder.layers.0.ffn_layer_norm.bias', 't2u_model.model.encoder.layers.0.ffn_layer_norm.weight', 't2u_model.model.encoder.layers.0.self_attn.k_proj.bias', 't2u_model.model.encoder.layers.0.self_attn.k_proj.weight', 't2u_model.model.encoder.layers.0.self_attn.out_proj.bias', 't2u_model.model.encoder.layers.0.self_attn.out_proj.weight', 't2u_model.model.encoder.layers.0.self_attn.q_proj.bias', 't2u_model.model.encoder.layers.0.self_attn.q_proj.weight', 't2u_model.model.encoder.layers.0.self_attn.v_proj.bias', 't2u_model.model.encoder.layers.0.self_attn.v_proj.weight', 't2u_model.model.encoder.layers.0.self_attn_layer_norm.bias', 't2u_model.model.encoder.layers.0.self_attn_layer_norm.weight', 't2u_model.model.encoder.layers.1.ffn.fc1.bias', 't2u_model.model.encoder.layers.1.ffn.fc1.weight', 't2u_model.model.encoder.layers.1.ffn.fc2.bias', 't2u_model.model.encoder.layers.1.ffn.fc2.weight', 't2u_model.model.encoder.layers.1.ffn_layer_norm.bias', 't2u_model.model.encoder.layers.1.ffn_layer_norm.weight', 't2u_model.model.encoder.layers.1.self_attn.k_proj.bias', 't2u_model.model.encoder.layers.1.self_attn.k_proj.weight', 't2u_model.model.encoder.layers.1.self_attn.out_proj.bias', 't2u_model.model.encoder.layers.1.self_attn.out_proj.weight', 't2u_model.model.encoder.layers.1.self_attn.q_proj.bias', 't2u_model.model.encoder.layers.1.self_attn.q_proj.weight', 't2u_model.model.encoder.layers.1.self_attn.v_proj.bias', 't2u_model.model.encoder.layers.1.self_attn.v_proj.weight', 't2u_model.model.encoder.layers.1.self_attn_layer_norm.bias', 't2u_model.model.encoder.layers.1.self_attn_layer_norm.weight', 't2u_model.model.encoder.layers.2.ffn.fc1.bias', 't2u_model.model.encoder.layers.2.ffn.fc1.weight', 't2u_model.model.encoder.layers.2.ffn.fc2.bias', 't2u_model.model.encoder.layers.2.ffn.fc2.weight', 't2u_model.model.encoder.layers.2.ffn_layer_norm.bias', 't2u_model.model.encoder.layers.2.ffn_layer_norm.weight', 't2u_model.model.encoder.layers.2.self_attn.k_proj.bias', 't2u_model.model.encoder.layers.2.self_attn.k_proj.weight', 't2u_model.model.encoder.layers.2.self_attn.out_proj.bias', 't2u_model.model.encoder.layers.2.self_attn.out_proj.weight', 't2u_model.model.encoder.layers.2.self_attn.q_proj.bias', 't2u_model.model.encoder.layers.2.self_attn.q_proj.weight', 't2u_model.model.encoder.layers.2.self_attn.v_proj.bias', 't2u_model.model.encoder.layers.2.self_attn.v_proj.weight', 't2u_model.model.encoder.layers.2.self_attn_layer_norm.bias', 't2u_model.model.encoder.layers.2.self_attn_layer_norm.weight', 't2u_model.model.encoder.layers.3.ffn.fc1.bias', 't2u_model.model.encoder.layers.3.ffn.fc1.weight', 't2u_model.model.encoder.layers.3.ffn.fc2.bias', 't2u_model.model.encoder.layers.3.ffn.fc2.weight', 't2u_model.model.encoder.layers.3.ffn_layer_norm.bias', 't2u_model.model.encoder.layers.3.ffn_layer_norm.weight', 't2u_model.model.encoder.layers.3.self_attn.k_proj.bias', 't2u_model.model.encoder.layers.3.self_attn.k_proj.weight', 't2u_model.model.encoder.layers.3.self_attn.out_proj.bias', 't2u_model.model.encoder.layers.3.self_attn.out_proj.weight', 't2u_model.model.encoder.layers.3.self_attn.q_proj.bias', 't2u_model.model.encoder.layers.3.self_attn.q_proj.weight', 't2u_model.model.encoder.layers.3.self_attn.v_proj.bias', 't2u_model.model.encoder.layers.3.self_attn.v_proj.weight', 't2u_model.model.encoder.layers.3.self_attn_layer_norm.bias', 't2u_model.model.encoder.layers.3.self_attn_layer_norm.weight', 't2u_model.model.encoder.layers.4.ffn.fc1.bias', 't2u_model.model.encoder.layers.4.ffn.fc1.weight', 't2u_model.model.encoder.layers.4.ffn.fc2.bias', 't2u_model.model.encoder.layers.4.ffn.fc2.weight', 't2u_model.model.encoder.layers.4.ffn_layer_norm.bias', 't2u_model.model.encoder.layers.4.ffn_layer_norm.weight', 't2u_model.model.encoder.layers.4.self_attn.k_proj.bias', 't2u_model.model.encoder.layers.4.self_attn.k_proj.weight', 't2u_model.model.encoder.layers.4.self_attn.out_proj.bias', 't2u_model.model.encoder.layers.4.self_attn.out_proj.weight', 't2u_model.model.encoder.layers.4.self_attn.q_proj.bias', 't2u_model.model.encoder.layers.4.self_attn.q_proj.weight', 't2u_model.model.encoder.layers.4.self_attn.v_proj.bias', 't2u_model.model.encoder.layers.4.self_attn.v_proj.weight', 't2u_model.model.encoder.layers.4.self_attn_layer_norm.bias', 't2u_model.model.encoder.layers.4.self_attn_layer_norm.weight', 't2u_model.model.encoder.layers.5.ffn.fc1.bias', 't2u_model.model.encoder.layers.5.ffn.fc1.weight', 't2u_model.model.encoder.layers.5.ffn.fc2.bias', 't2u_model.model.encoder.layers.5.ffn.fc2.weight', 't2u_model.model.encoder.layers.5.ffn_layer_norm.bias', 't2u_model.model.encoder.layers.5.ffn_layer_norm.weight', 't2u_model.model.encoder.layers.5.self_attn.k_proj.bias', 't2u_model.model.encoder.layers.5.self_attn.k_proj.weight', 't2u_model.model.encoder.layers.5.self_attn.out_proj.bias', 't2u_model.model.encoder.layers.5.self_attn.out_proj.weight', 't2u_model.model.encoder.layers.5.self_attn.q_proj.bias', 't2u_model.model.encoder.layers.5.self_attn.q_proj.weight', 't2u_model.model.encoder.layers.5.self_attn.v_proj.bias', 't2u_model.model.encoder.layers.5.self_attn.v_proj.weight', 't2u_model.model.encoder.layers.5.self_attn_layer_norm.bias', 't2u_model.model.encoder.layers.5.self_attn_layer_norm.weight', 'text_decoder.embed_tokens.weight', 'text_decoder.layer_norm.bias', 'text_decoder.layer_norm.weight', 'text_decoder.layers.0.cross_attention.k_proj.bias', 'text_decoder.layers.0.cross_attention.k_proj.weight', 'text_decoder.layers.0.cross_attention.out_proj.bias', 'text_decoder.layers.0.cross_attention.out_proj.weight', 'text_decoder.layers.0.cross_attention.q_proj.bias', 'text_decoder.layers.0.cross_attention.q_proj.weight', 'text_decoder.layers.0.cross_attention.v_proj.bias', 'text_decoder.layers.0.cross_attention.v_proj.weight', 'text_decoder.layers.0.cross_attention_layer_norm.bias', 'text_decoder.layers.0.cross_attention_layer_norm.weight', 'text_decoder.layers.0.ffn.fc1.bias', 'text_decoder.layers.0.ffn.fc1.weight', 'text_decoder.layers.0.ffn.fc2.bias', 'text_decoder.layers.0.ffn.fc2.weight', 'text_decoder.layers.0.ffn_layer_norm.bias', 'text_decoder.layers.0.ffn_layer_norm.weight', 'text_decoder.layers.0.self_attn.k_proj.bias', 'text_decoder.layers.0.self_attn.k_proj.weight', 'text_decoder.layers.0.self_attn.out_proj.bias', 'text_decoder.layers.0.self_attn.out_proj.weight', 'text_decoder.layers.0.self_attn.q_proj.bias', 'text_decoder.layers.0.self_attn.q_proj.weight', 'text_decoder.layers.0.self_attn.v_proj.bias', 'text_decoder.layers.0.self_attn.v_proj.weight', 'text_decoder.layers.0.self_attn_layer_norm.bias', 'text_decoder.layers.0.self_attn_layer_norm.weight', 'text_decoder.layers.1.cross_attention.k_proj.bias', 'text_decoder.layers.1.cross_attention.k_proj.weight', 'text_decoder.layers.1.cross_attention.out_proj.bias', 'text_decoder.layers.1.cross_attention.out_proj.weight', 'text_decoder.layers.1.cross_attention.q_proj.bias', 'text_decoder.layers.1.cross_attention.q_proj.weight', 'text_decoder.layers.1.cross_attention.v_proj.bias', 'text_decoder.layers.1.cross_attention.v_proj.weight', 'text_decoder.layers.1.cross_attention_layer_norm.bias', 'text_decoder.layers.1.cross_attention_layer_norm.weight', 'text_decoder.layers.1.ffn.fc1.bias', 'text_decoder.layers.1.ffn.fc1.weight', 'text_decoder.layers.1.ffn.fc2.bias', 'text_decoder.layers.1.ffn.fc2.weight', 'text_decoder.layers.1.ffn_layer_norm.bias', 'text_decoder.layers.1.ffn_layer_norm.weight', 'text_decoder.layers.1.self_attn.k_proj.bias', 'text_decoder.layers.1.self_attn.k_proj.weight', 'text_decoder.layers.1.self_attn.out_proj.bias', 'text_decoder.layers.1.self_attn.out_proj.weight', 'text_decoder.layers.1.self_attn.q_proj.bias', 'text_decoder.layers.1.self_attn.q_proj.weight', 'text_decoder.layers.1.self_attn.v_proj.bias', 'text_decoder.layers.1.self_attn.v_proj.weight', 'text_decoder.layers.1.self_attn_layer_norm.bias', 'text_decoder.layers.1.self_attn_layer_norm.weight', 'text_decoder.layers.10.cross_attention.k_proj.bias', 'text_decoder.layers.10.cross_attention.k_proj.weight', 'text_decoder.layers.10.cross_attention.out_proj.bias', 'text_decoder.layers.10.cross_attention.out_proj.weight', 'text_decoder.layers.10.cross_attention.q_proj.bias', 'text_decoder.layers.10.cross_attention.q_proj.weight', 'text_decoder.layers.10.cross_attention.v_proj.bias', 'text_decoder.layers.10.cross_attention.v_proj.weight', 'text_decoder.layers.10.cross_attention_layer_norm.bias', 'text_decoder.layers.10.cross_attention_layer_norm.weight', 'text_decoder.layers.10.ffn.fc1.bias', 'text_decoder.layers.10.ffn.fc1.weight', 'text_decoder.layers.10.ffn.fc2.bias', 'text_decoder.layers.10.ffn.fc2.weight', 'text_decoder.layers.10.ffn_layer_norm.bias', 'text_decoder.layers.10.ffn_layer_norm.weight', 'text_decoder.layers.10.self_attn.k_proj.bias', 'text_decoder.layers.10.self_attn.k_proj.weight', 'text_decoder.layers.10.self_attn.out_proj.bias', 'text_decoder.layers.10.self_attn.out_proj.weight', 'text_decoder.layers.10.self_attn.q_proj.bias', 'text_decoder.layers.10.self_attn.q_proj.weight', 'text_decoder.layers.10.self_attn.v_proj.bias', 'text_decoder.layers.10.self_attn.v_proj.weight', 'text_decoder.layers.10.self_attn_layer_norm.bias', 'text_decoder.layers.10.self_attn_layer_norm.weight', 'text_decoder.layers.11.cross_attention.k_proj.bias', 'text_decoder.layers.11.cross_attention.k_proj.weight', 'text_decoder.layers.11.cross_attention.out_proj.bias', 'text_decoder.layers.11.cross_attention.out_proj.weight', 'text_decoder.layers.11.cross_attention.q_proj.bias', 'text_decoder.layers.11.cross_attention.q_proj.weight', 'text_decoder.layers.11.cross_attention.v_proj.bias', 'text_decoder.layers.11.cross_attention.v_proj.weight', 'text_decoder.layers.11.cross_attention_layer_norm.bias', 'text_decoder.layers.11.cross_attention_layer_norm.weight', 'text_decoder.layers.11.ffn.fc1.bias', 'text_decoder.layers.11.ffn.fc1.weight', 'text_decoder.layers.11.ffn.fc2.bias', 'text_decoder.layers.11.ffn.fc2.weight', 'text_decoder.layers.11.ffn_layer_norm.bias', 'text_decoder.layers.11.ffn_layer_norm.weight', 'text_decoder.layers.11.self_attn.k_proj.bias', 'text_decoder.layers.11.self_attn.k_proj.weight', 'text_decoder.layers.11.self_attn.out_proj.bias', 'text_decoder.layers.11.self_attn.out_proj.weight', 'text_decoder.layers.11.self_attn.q_proj.bias', 'text_decoder.layers.11.self_attn.q_proj.weight', 'text_decoder.layers.11.self_attn.v_proj.bias', 'text_decoder.layers.11.self_attn.v_proj.weight', 'text_decoder.layers.11.self_attn_layer_norm.bias', 'text_decoder.layers.11.self_attn_layer_norm.weight', 'text_decoder.layers.12.cross_attention.k_proj.bias', 'text_decoder.layers.12.cross_attention.k_proj.weight', 'text_decoder.layers.12.cross_attention.out_proj.bias', 'text_decoder.layers.12.cross_attention.out_proj.weight', 'text_decoder.layers.12.cross_attention.q_proj.bias', 'text_decoder.layers.12.cross_attention.q_proj.weight', 'text_decoder.layers.12.cross_attention.v_proj.bias', 'text_decoder.layers.12.cross_attention.v_proj.weight', 'text_decoder.layers.12.cross_attention_layer_norm.bias', 'text_decoder.layers.12.cross_attention_layer_norm.weight', 'text_decoder.layers.12.ffn.fc1.bias', 'text_decoder.layers.12.ffn.fc1.weight', 'text_decoder.layers.12.ffn.fc2.bias', 'text_decoder.layers.12.ffn.fc2.weight', 'text_decoder.layers.12.ffn_layer_norm.bias', 'text_decoder.layers.12.ffn_layer_norm.weight', 'text_decoder.layers.12.self_attn.k_proj.bias', 'text_decoder.layers.12.self_attn.k_proj.weight', 'text_decoder.layers.12.self_attn.out_proj.bias', 'text_decoder.layers.12.self_attn.out_proj.weight', 'text_decoder.layers.12.self_attn.q_proj.bias', 'text_decoder.layers.12.self_attn.q_proj.weight', 'text_decoder.layers.12.self_attn.v_proj.bias', 'text_decoder.layers.12.self_attn.v_proj.weight', 'text_decoder.layers.12.self_attn_layer_norm.bias', 'text_decoder.layers.12.self_attn_layer_norm.weight', 'text_decoder.layers.13.cross_attention.k_proj.bias', 'text_decoder.layers.13.cross_attention.k_proj.weight', 'text_decoder.layers.13.cross_attention.out_proj.bias', 'text_decoder.layers.13.cross_attention.out_proj.weight', 'text_decoder.layers.13.cross_attention.q_proj.bias', 'text_decoder.layers.13.cross_attention.q_proj.weight', 'text_decoder.layers.13.cross_attention.v_proj.bias', 'text_decoder.layers.13.cross_attention.v_proj.weight', 'text_decoder.layers.13.cross_attention_layer_norm.bias', 'text_decoder.layers.13.cross_attention_layer_norm.weight', 'text_decoder.layers.13.ffn.fc1.bias', 'text_decoder.layers.13.ffn.fc1.weight', 'text_decoder.layers.13.ffn.fc2.bias', 'text_decoder.layers.13.ffn.fc2.weight', 'text_decoder.layers.13.ffn_layer_norm.bias', 'text_decoder.layers.13.ffn_layer_norm.weight', 'text_decoder.layers.13.self_attn.k_proj.bias', 'text_decoder.layers.13.self_attn.k_proj.weight', 'text_decoder.layers.13.self_attn.out_proj.bias', 'text_decoder.layers.13.self_attn.out_proj.weight', 'text_decoder.layers.13.self_attn.q_proj.bias', 'text_decoder.layers.13.self_attn.q_proj.weight', 'text_decoder.layers.13.self_attn.v_proj.bias', 'text_decoder.layers.13.self_attn.v_proj.weight', 'text_decoder.layers.13.self_attn_layer_norm.bias', 'text_decoder.layers.13.self_attn_layer_norm.weight', 'text_decoder.layers.14.cross_attention.k_proj.bias', 'text_decoder.layers.14.cross_attention.k_proj.weight', 'text_decoder.layers.14.cross_attention.out_proj.bias', 'text_decoder.layers.14.cross_attention.out_proj.weight', 'text_decoder.layers.14.cross_attention.q_proj.bias', 'text_decoder.layers.14.cross_attention.q_proj.weight', 'text_decoder.layers.14.cross_attention.v_proj.bias', 'text_decoder.layers.14.cross_attention.v_proj.weight', 'text_decoder.layers.14.cross_attention_layer_norm.bias', 'text_decoder.layers.14.cross_attention_layer_norm.weight', 'text_decoder.layers.14.ffn.fc1.bias', 'text_decoder.layers.14.ffn.fc1.weight', 'text_decoder.layers.14.ffn.fc2.bias', 'text_decoder.layers.14.ffn.fc2.weight', 'text_decoder.layers.14.ffn_layer_norm.bias', 'text_decoder.layers.14.ffn_layer_norm.weight', 'text_decoder.layers.14.self_attn.k_proj.bias', 'text_decoder.layers.14.self_attn.k_proj.weight', 'text_decoder.layers.14.self_attn.out_proj.bias', 'text_decoder.layers.14.self_attn.out_proj.weight', 'text_decoder.layers.14.self_attn.q_proj.bias', 'text_decoder.layers.14.self_attn.q_proj.weight', 'text_decoder.layers.14.self_attn.v_proj.bias', 'text_decoder.layers.14.self_attn.v_proj.weight', 'text_decoder.layers.14.self_attn_layer_norm.bias', 'text_decoder.layers.14.self_attn_layer_norm.weight', 'text_decoder.layers.15.cross_attention.k_proj.bias', 'text_decoder.layers.15.cross_attention.k_proj.weight', 'text_decoder.layers.15.cross_attention.out_proj.bias', 'text_decoder.layers.15.cross_attention.out_proj.weight', 'text_decoder.layers.15.cross_attention.q_proj.bias', 'text_decoder.layers.15.cross_attention.q_proj.weight', 'text_decoder.layers.15.cross_attention.v_proj.bias', 'text_decoder.layers.15.cross_attention.v_proj.weight', 'text_decoder.layers.15.cross_attention_layer_norm.bias', 'text_decoder.layers.15.cross_attention_layer_norm.weight', 'text_decoder.layers.15.ffn.fc1.bias', 'text_decoder.layers.15.ffn.fc1.weight', 'text_decoder.layers.15.ffn.fc2.bias', 'text_decoder.layers.15.ffn.fc2.weight', 'text_decoder.layers.15.ffn_layer_norm.bias', 'text_decoder.layers.15.ffn_layer_norm.weight', 'text_decoder.layers.15.self_attn.k_proj.bias', 'text_decoder.layers.15.self_attn.k_proj.weight', 'text_decoder.layers.15.self_attn.out_proj.bias', 'text_decoder.layers.15.self_attn.out_proj.weight', 'text_decoder.layers.15.self_attn.q_proj.bias', 'text_decoder.layers.15.self_attn.q_proj.weight', 'text_decoder.layers.15.self_attn.v_proj.bias', 'text_decoder.layers.15.self_attn.v_proj.weight', 'text_decoder.layers.15.self_attn_layer_norm.bias', 'text_decoder.layers.15.self_attn_layer_norm.weight', 'text_decoder.layers.16.cross_attention.k_proj.bias', 'text_decoder.layers.16.cross_attention.k_proj.weight', 'text_decoder.layers.16.cross_attention.out_proj.bias', 'text_decoder.layers.16.cross_attention.out_proj.weight', 'text_decoder.layers.16.cross_attention.q_proj.bias', 'text_decoder.layers.16.cross_attention.q_proj.weight', 'text_decoder.layers.16.cross_attention.v_proj.bias', 'text_decoder.layers.16.cross_attention.v_proj.weight', 'text_decoder.layers.16.cross_attention_layer_norm.bias', 'text_decoder.layers.16.cross_attention_layer_norm.weight', 'text_decoder.layers.16.ffn.fc1.bias', 'text_decoder.layers.16.ffn.fc1.weight', 'text_decoder.layers.16.ffn.fc2.bias', 'text_decoder.layers.16.ffn.fc2.weight', 'text_decoder.layers.16.ffn_layer_norm.bias', 'text_decoder.layers.16.ffn_layer_norm.weight', 'text_decoder.layers.16.self_attn.k_proj.bias', 'text_decoder.layers.16.self_attn.k_proj.weight', 'text_decoder.layers.16.self_attn.out_proj.bias', 'text_decoder.layers.16.self_attn.out_proj.weight', 'text_decoder.layers.16.self_attn.q_proj.bias', 'text_decoder.layers.16.self_attn.q_proj.weight', 'text_decoder.layers.16.self_attn.v_proj.bias', 'text_decoder.layers.16.self_attn.v_proj.weight', 'text_decoder.layers.16.self_attn_layer_norm.bias', 'text_decoder.layers.16.self_attn_layer_norm.weight', 'text_decoder.layers.17.cross_attention.k_proj.bias', 'text_decoder.layers.17.cross_attention.k_proj.weight', 'text_decoder.layers.17.cross_attention.out_proj.bias', 'text_decoder.layers.17.cross_attention.out_proj.weight', 'text_decoder.layers.17.cross_attention.q_proj.bias', 'text_decoder.layers.17.cross_attention.q_proj.weight', 'text_decoder.layers.17.cross_attention.v_proj.bias', 'text_decoder.layers.17.cross_attention.v_proj.weight', 'text_decoder.layers.17.cross_attention_layer_norm.bias', 'text_decoder.layers.17.cross_attention_layer_norm.weight', 'text_decoder.layers.17.ffn.fc1.bias', 'text_decoder.layers.17.ffn.fc1.weight', 'text_decoder.layers.17.ffn.fc2.bias', 'text_decoder.layers.17.ffn.fc2.weight', 'text_decoder.layers.17.ffn_layer_norm.bias', 'text_decoder.layers.17.ffn_layer_norm.weight', 'text_decoder.layers.17.self_attn.k_proj.bias', 'text_decoder.layers.17.self_attn.k_proj.weight', 'text_decoder.layers.17.self_attn.out_proj.bias', 'text_decoder.layers.17.self_attn.out_proj.weight', 'text_decoder.layers.17.self_attn.q_proj.bias', 'text_decoder.layers.17.self_attn.q_proj.weight', 'text_decoder.layers.17.self_attn.v_proj.bias', 'text_decoder.layers.17.self_attn.v_proj.weight', 'text_decoder.layers.17.self_attn_layer_norm.bias', 'text_decoder.layers.17.self_attn_layer_norm.weight', 'text_decoder.layers.18.cross_attention.k_proj.bias', 'text_decoder.layers.18.cross_attention.k_proj.weight', 'text_decoder.layers.18.cross_attention.out_proj.bias', 'text_decoder.layers.18.cross_attention.out_proj.weight', 'text_decoder.layers.18.cross_attention.q_proj.bias', 'text_decoder.layers.18.cross_attention.q_proj.weight', 'text_decoder.layers.18.cross_attention.v_proj.bias', 'text_decoder.layers.18.cross_attention.v_proj.weight', 'text_decoder.layers.18.cross_attention_layer_norm.bias', 'text_decoder.layers.18.cross_attention_layer_norm.weight', 'text_decoder.layers.18.ffn.fc1.bias', 'text_decoder.layers.18.ffn.fc1.weight', 'text_decoder.layers.18.ffn.fc2.bias', 'text_decoder.layers.18.ffn.fc2.weight', 'text_decoder.layers.18.ffn_layer_norm.bias', 'text_decoder.layers.18.ffn_layer_norm.weight', 'text_decoder.layers.18.self_attn.k_proj.bias', 'text_decoder.layers.18.self_attn.k_proj.weight', 'text_decoder.layers.18.self_attn.out_proj.bias', 'text_decoder.layers.18.self_attn.out_proj.weight', 'text_decoder.layers.18.self_attn.q_proj.bias', 'text_decoder.layers.18.self_attn.q_proj.weight', 'text_decoder.layers.18.self_attn.v_proj.bias', 'text_decoder.layers.18.self_attn.v_proj.weight', 'text_decoder.layers.18.self_attn_layer_norm.bias', 'text_decoder.layers.18.self_attn_layer_norm.weight', 'text_decoder.layers.19.cross_attention.k_proj.bias', 'text_decoder.layers.19.cross_attention.k_proj.weight', 'text_decoder.layers.19.cross_attention.out_proj.bias', 'text_decoder.layers.19.cross_attention.out_proj.weight', 'text_decoder.layers.19.cross_attention.q_proj.bias', 'text_decoder.layers.19.cross_attention.q_proj.weight', 'text_decoder.layers.19.cross_attention.v_proj.bias', 'text_decoder.layers.19.cross_attention.v_proj.weight', 'text_decoder.layers.19.cross_attention_layer_norm.bias', 'text_decoder.layers.19.cross_attention_layer_norm.weight', 'text_decoder.layers.19.ffn.fc1.bias', 'text_decoder.layers.19.ffn.fc1.weight', 'text_decoder.layers.19.ffn.fc2.bias', 'text_decoder.layers.19.ffn.fc2.weight', 'text_decoder.layers.19.ffn_layer_norm.bias', 'text_decoder.layers.19.ffn_layer_norm.weight', 'text_decoder.layers.19.self_attn.k_proj.bias', 'text_decoder.layers.19.self_attn.k_proj.weight', 'text_decoder.layers.19.self_attn.out_proj.bias', 'text_decoder.layers.19.self_attn.out_proj.weight', 'text_decoder.layers.19.self_attn.q_proj.bias', 'text_decoder.layers.19.self_attn.q_proj.weight', 'text_decoder.layers.19.self_attn.v_proj.bias', 'text_decoder.layers.19.self_attn.v_proj.weight', 'text_decoder.layers.19.self_attn_layer_norm.bias', 'text_decoder.layers.19.self_attn_layer_norm.weight', 'text_decoder.layers.2.cross_attention.k_proj.bias', 'text_decoder.layers.2.cross_attention.k_proj.weight', 'text_decoder.layers.2.cross_attention.out_proj.bias', 'text_decoder.layers.2.cross_attention.out_proj.weight', 'text_decoder.layers.2.cross_attention.q_proj.bias', 'text_decoder.layers.2.cross_attention.q_proj.weight', 'text_decoder.layers.2.cross_attention.v_proj.bias', 'text_decoder.layers.2.cross_attention.v_proj.weight', 'text_decoder.layers.2.cross_attention_layer_norm.bias', 'text_decoder.layers.2.cross_attention_layer_norm.weight', 'text_decoder.layers.2.ffn.fc1.bias', 'text_decoder.layers.2.ffn.fc1.weight', 'text_decoder.layers.2.ffn.fc2.bias', 'text_decoder.layers.2.ffn.fc2.weight', 'text_decoder.layers.2.ffn_layer_norm.bias', 'text_decoder.layers.2.ffn_layer_norm.weight', 'text_decoder.layers.2.self_attn.k_proj.bias', 'text_decoder.layers.2.self_attn.k_proj.weight', 'text_decoder.layers.2.self_attn.out_proj.bias', 'text_decoder.layers.2.self_attn.out_proj.weight', 'text_decoder.layers.2.self_attn.q_proj.bias', 'text_decoder.layers.2.self_attn.q_proj.weight', 'text_decoder.layers.2.self_attn.v_proj.bias', 'text_decoder.layers.2.self_attn.v_proj.weight', 'text_decoder.layers.2.self_attn_layer_norm.bias', 'text_decoder.layers.2.self_attn_layer_norm.weight', 'text_decoder.layers.20.cross_attention.k_proj.bias', 'text_decoder.layers.20.cross_attention.k_proj.weight', 'text_decoder.layers.20.cross_attention.out_proj.bias', 'text_decoder.layers.20.cross_attention.out_proj.weight', 'text_decoder.layers.20.cross_attention.q_proj.bias', 'text_decoder.layers.20.cross_attention.q_proj.weight', 'text_decoder.layers.20.cross_attention.v_proj.bias', 'text_decoder.layers.20.cross_attention.v_proj.weight', 'text_decoder.layers.20.cross_attention_layer_norm.bias', 'text_decoder.layers.20.cross_attention_layer_norm.weight', 'text_decoder.layers.20.ffn.fc1.bias', 'text_decoder.layers.20.ffn.fc1.weight', 'text_decoder.layers.20.ffn.fc2.bias', 'text_decoder.layers.20.ffn.fc2.weight', 'text_decoder.layers.20.ffn_layer_norm.bias', 'text_decoder.layers.20.ffn_layer_norm.weight', 'text_decoder.layers.20.self_attn.k_proj.bias', 'text_decoder.layers.20.self_attn.k_proj.weight', 'text_decoder.layers.20.self_attn.out_proj.bias', 'text_decoder.layers.20.self_attn.out_proj.weight', 'text_decoder.layers.20.self_attn.q_proj.bias', 'text_decoder.layers.20.self_attn.q_proj.weight', 'text_decoder.layers.20.self_attn.v_proj.bias', 'text_decoder.layers.20.self_attn.v_proj.weight', 'text_decoder.layers.20.self_attn_layer_norm.bias', 'text_decoder.layers.20.self_attn_layer_norm.weight', 'text_decoder.layers.21.cross_attention.k_proj.bias', 'text_decoder.layers.21.cross_attention.k_proj.weight', 'text_decoder.layers.21.cross_attention.out_proj.bias', 'text_decoder.layers.21.cross_attention.out_proj.weight', 'text_decoder.layers.21.cross_attention.q_proj.bias', 'text_decoder.layers.21.cross_attention.q_proj.weight', 'text_decoder.layers.21.cross_attention.v_proj.bias', 'text_decoder.layers.21.cross_attention.v_proj.weight', 'text_decoder.layers.21.cross_attention_layer_norm.bias', 'text_decoder.layers.21.cross_attention_layer_norm.weight', 'text_decoder.layers.21.ffn.fc1.bias', 'text_decoder.layers.21.ffn.fc1.weight', 'text_decoder.layers.21.ffn.fc2.bias', 'text_decoder.layers.21.ffn.fc2.weight', 'text_decoder.layers.21.ffn_layer_norm.bias', 'text_decoder.layers.21.ffn_layer_norm.weight', 'text_decoder.layers.21.self_attn.k_proj.bias', 'text_decoder.layers.21.self_attn.k_proj.weight', 'text_decoder.layers.21.self_attn.out_proj.bias', 'text_decoder.layers.21.self_attn.out_proj.weight', 'text_decoder.layers.21.self_attn.q_proj.bias', 'text_decoder.layers.21.self_attn.q_proj.weight', 'text_decoder.layers.21.self_attn.v_proj.bias', 'text_decoder.layers.21.self_attn.v_proj.weight', 'text_decoder.layers.21.self_attn_layer_norm.bias', 'text_decoder.layers.21.self_attn_layer_norm.weight', 'text_decoder.layers.22.cross_attention.k_proj.bias', 'text_decoder.layers.22.cross_attention.k_proj.weight', 'text_decoder.layers.22.cross_attention.out_proj.bias', 'text_decoder.layers.22.cross_attention.out_proj.weight', 'text_decoder.layers.22.cross_attention.q_proj.bias', 'text_decoder.layers.22.cross_attention.q_proj.weight', 'text_decoder.layers.22.cross_attention.v_proj.bias', 'text_decoder.layers.22.cross_attention.v_proj.weight', 'text_decoder.layers.22.cross_attention_layer_norm.bias', 'text_decoder.layers.22.cross_attention_layer_norm.weight', 'text_decoder.layers.22.ffn.fc1.bias', 'text_decoder.layers.22.ffn.fc1.weight', 'text_decoder.layers.22.ffn.fc2.bias', 'text_decoder.layers.22.ffn.fc2.weight', 'text_decoder.layers.22.ffn_layer_norm.bias', 'text_decoder.layers.22.ffn_layer_norm.weight', 'text_decoder.layers.22.self_attn.k_proj.bias', 'text_decoder.layers.22.self_attn.k_proj.weight', 'text_decoder.layers.22.self_attn.out_proj.bias', 'text_decoder.layers.22.self_attn.out_proj.weight', 'text_decoder.layers.22.self_attn.q_proj.bias', 'text_decoder.layers.22.self_attn.q_proj.weight', 'text_decoder.layers.22.self_attn.v_proj.bias', 'text_decoder.layers.22.self_attn.v_proj.weight', 'text_decoder.layers.22.self_attn_layer_norm.bias', 'text_decoder.layers.22.self_attn_layer_norm.weight', 'text_decoder.layers.23.cross_attention.k_proj.bias', 'text_decoder.layers.23.cross_attention.k_proj.weight', 'text_decoder.layers.23.cross_attention.out_proj.bias', 'text_decoder.layers.23.cross_attention.out_proj.weight', 'text_decoder.layers.23.cross_attention.q_proj.bias', 'text_decoder.layers.23.cross_attention.q_proj.weight', 'text_decoder.layers.23.cross_attention.v_proj.bias', 'text_decoder.layers.23.cross_attention.v_proj.weight', 'text_decoder.layers.23.cross_attention_layer_norm.bias', 'text_decoder.layers.23.cross_attention_layer_norm.weight', 'text_decoder.layers.23.ffn.fc1.bias', 'text_decoder.layers.23.ffn.fc1.weight', 'text_decoder.layers.23.ffn.fc2.bias', 'text_decoder.layers.23.ffn.fc2.weight', 'text_decoder.layers.23.ffn_layer_norm.bias', 'text_decoder.layers.23.ffn_layer_norm.weight', 'text_decoder.layers.23.self_attn.k_proj.bias', 'text_decoder.layers.23.self_attn.k_proj.weight', 'text_decoder.layers.23.self_attn.out_proj.bias', 'text_decoder.layers.23.self_attn.out_proj.weight', 'text_decoder.layers.23.self_attn.q_proj.bias', 'text_decoder.layers.23.self_attn.q_proj.weight', 'text_decoder.layers.23.self_attn.v_proj.bias', 'text_decoder.layers.23.self_attn.v_proj.weight', 'text_decoder.layers.23.self_attn_layer_norm.bias', 'text_decoder.layers.23.self_attn_layer_norm.weight', 'text_decoder.layers.3.cross_attention.k_proj.bias', 'text_decoder.layers.3.cross_attention.k_proj.weight', 'text_decoder.layers.3.cross_attention.out_proj.bias', 'text_decoder.layers.3.cross_attention.out_proj.weight', 'text_decoder.layers.3.cross_attention.q_proj.bias', 'text_decoder.layers.3.cross_attention.q_proj.weight', 'text_decoder.layers.3.cross_attention.v_proj.bias', 'text_decoder.layers.3.cross_attention.v_proj.weight', 'text_decoder.layers.3.cross_attention_layer_norm.bias', 'text_decoder.layers.3.cross_attention_layer_norm.weight', 'text_decoder.layers.3.ffn.fc1.bias', 'text_decoder.layers.3.ffn.fc1.weight', 'text_decoder.layers.3.ffn.fc2.bias', 'text_decoder.layers.3.ffn.fc2.weight', 'text_decoder.layers.3.ffn_layer_norm.bias', 'text_decoder.layers.3.ffn_layer_norm.weight', 'text_decoder.layers.3.self_attn.k_proj.bias', 'text_decoder.layers.3.self_attn.k_proj.weight', 'text_decoder.layers.3.self_attn.out_proj.bias', 'text_decoder.layers.3.self_attn.out_proj.weight', 'text_decoder.layers.3.self_attn.q_proj.bias', 'text_decoder.layers.3.self_attn.q_proj.weight', 'text_decoder.layers.3.self_attn.v_proj.bias', 'text_decoder.layers.3.self_attn.v_proj.weight', 'text_decoder.layers.3.self_attn_layer_norm.bias', 'text_decoder.layers.3.self_attn_layer_norm.weight', 'text_decoder.layers.4.cross_attention.k_proj.bias', 'text_decoder.layers.4.cross_attention.k_proj.weight', 'text_decoder.layers.4.cross_attention.out_proj.bias', 'text_decoder.layers.4.cross_attention.out_proj.weight', 'text_decoder.layers.4.cross_attention.q_proj.bias', 'text_decoder.layers.4.cross_attention.q_proj.weight', 'text_decoder.layers.4.cross_attention.v_proj.bias', 'text_decoder.layers.4.cross_attention.v_proj.weight', 'text_decoder.layers.4.cross_attention_layer_norm.bias', 'text_decoder.layers.4.cross_attention_layer_norm.weight', 'text_decoder.layers.4.ffn.fc1.bias', 'text_decoder.layers.4.ffn.fc1.weight', 'text_decoder.layers.4.ffn.fc2.bias', 'text_decoder.layers.4.ffn.fc2.weight', 'text_decoder.layers.4.ffn_layer_norm.bias', 'text_decoder.layers.4.ffn_layer_norm.weight', 'text_decoder.layers.4.self_attn.k_proj.bias', 'text_decoder.layers.4.self_attn.k_proj.weight', 'text_decoder.layers.4.self_attn.out_proj.bias', 'text_decoder.layers.4.self_attn.out_proj.weight', 'text_decoder.layers.4.self_attn.q_proj.bias', 'text_decoder.layers.4.self_attn.q_proj.weight', 'text_decoder.layers.4.self_attn.v_proj.bias', 'text_decoder.layers.4.self_attn.v_proj.weight', 'text_decoder.layers.4.self_attn_layer_norm.bias', 'text_decoder.layers.4.self_attn_layer_norm.weight', 'text_decoder.layers.5.cross_attention.k_proj.bias', 'text_decoder.layers.5.cross_attention.k_proj.weight', 'text_decoder.layers.5.cross_attention.out_proj.bias', 'text_decoder.layers.5.cross_attention.out_proj.weight', 'text_decoder.layers.5.cross_attention.q_proj.bias', 'text_decoder.layers.5.cross_attention.q_proj.weight', 'text_decoder.layers.5.cross_attention.v_proj.bias', 'text_decoder.layers.5.cross_attention.v_proj.weight', 'text_decoder.layers.5.cross_attention_layer_norm.bias', 'text_decoder.layers.5.cross_attention_layer_norm.weight', 'text_decoder.layers.5.ffn.fc1.bias', 'text_decoder.layers.5.ffn.fc1.weight', 'text_decoder.layers.5.ffn.fc2.bias', 'text_decoder.layers.5.ffn.fc2.weight', 'text_decoder.layers.5.ffn_layer_norm.bias', 'text_decoder.layers.5.ffn_layer_norm.weight', 'text_decoder.layers.5.self_attn.k_proj.bias', 'text_decoder.layers.5.self_attn.k_proj.weight', 'text_decoder.layers.5.self_attn.out_proj.bias', 'text_decoder.layers.5.self_attn.out_proj.weight', 'text_decoder.layers.5.self_attn.q_proj.bias', 'text_decoder.layers.5.self_attn.q_proj.weight', 'text_decoder.layers.5.self_attn.v_proj.bias', 'text_decoder.layers.5.self_attn.v_proj.weight', 'text_decoder.layers.5.self_attn_layer_norm.bias', 'text_decoder.layers.5.self_attn_layer_norm.weight', 'text_decoder.layers.6.cross_attention.k_proj.bias', 'text_decoder.layers.6.cross_attention.k_proj.weight', 'text_decoder.layers.6.cross_attention.out_proj.bias', 'text_decoder.layers.6.cross_attention.out_proj.weight', 'text_decoder.layers.6.cross_attention.q_proj.bias', 'text_decoder.layers.6.cross_attention.q_proj.weight', 'text_decoder.layers.6.cross_attention.v_proj.bias', 'text_decoder.layers.6.cross_attention.v_proj.weight', 'text_decoder.layers.6.cross_attention_layer_norm.bias', 'text_decoder.layers.6.cross_attention_layer_norm.weight', 'text_decoder.layers.6.ffn.fc1.bias', 'text_decoder.layers.6.ffn.fc1.weight', 'text_decoder.layers.6.ffn.fc2.bias', 'text_decoder.layers.6.ffn.fc2.weight', 'text_decoder.layers.6.ffn_layer_norm.bias', 'text_decoder.layers.6.ffn_layer_norm.weight', 'text_decoder.layers.6.self_attn.k_proj.bias', 'text_decoder.layers.6.self_attn.k_proj.weight', 'text_decoder.layers.6.self_attn.out_proj.bias', 'text_decoder.layers.6.self_attn.out_proj.weight', 'text_decoder.layers.6.self_attn.q_proj.bias', 'text_decoder.layers.6.self_attn.q_proj.weight', 'text_decoder.layers.6.self_attn.v_proj.bias', 'text_decoder.layers.6.self_attn.v_proj.weight', 'text_decoder.layers.6.self_attn_layer_norm.bias', 'text_decoder.layers.6.self_attn_layer_norm.weight', 'text_decoder.layers.7.cross_attention.k_proj.bias', 'text_decoder.layers.7.cross_attention.k_proj.weight', 'text_decoder.layers.7.cross_attention.out_proj.bias', 'text_decoder.layers.7.cross_attention.out_proj.weight', 'text_decoder.layers.7.cross_attention.q_proj.bias', 'text_decoder.layers.7.cross_attention.q_proj.weight', 'text_decoder.layers.7.cross_attention.v_proj.bias', 'text_decoder.layers.7.cross_attention.v_proj.weight', 'text_decoder.layers.7.cross_attention_layer_norm.bias', 'text_decoder.layers.7.cross_attention_layer_norm.weight', 'text_decoder.layers.7.ffn.fc1.bias', 'text_decoder.layers.7.ffn.fc1.weight', 'text_decoder.layers.7.ffn.fc2.bias', 'text_decoder.layers.7.ffn.fc2.weight', 'text_decoder.layers.7.ffn_layer_norm.bias', 'text_decoder.layers.7.ffn_layer_norm.weight', 'text_decoder.layers.7.self_attn.k_proj.bias', 'text_decoder.layers.7.self_attn.k_proj.weight', 'text_decoder.layers.7.self_attn.out_proj.bias', 'text_decoder.layers.7.self_attn.out_proj.weight', 'text_decoder.layers.7.self_attn.q_proj.bias', 'text_decoder.layers.7.self_attn.q_proj.weight', 'text_decoder.layers.7.self_attn.v_proj.bias', 'text_decoder.layers.7.self_attn.v_proj.weight', 'text_decoder.layers.7.self_attn_layer_norm.bias', 'text_decoder.layers.7.self_attn_layer_norm.weight', 'text_decoder.layers.8.cross_attention.k_proj.bias', 'text_decoder.layers.8.cross_attention.k_proj.weight', 'text_decoder.layers.8.cross_attention.out_proj.bias', 'text_decoder.layers.8.cross_attention.out_proj.weight', 'text_decoder.layers.8.cross_attention.q_proj.bias', 'text_decoder.layers.8.cross_attention.q_proj.weight', 'text_decoder.layers.8.cross_attention.v_proj.bias', 'text_decoder.layers.8.cross_attention.v_proj.weight', 'text_decoder.layers.8.cross_attention_layer_norm.bias', 'text_decoder.layers.8.cross_attention_layer_norm.weight', 'text_decoder.layers.8.ffn.fc1.bias', 'text_decoder.layers.8.ffn.fc1.weight', 'text_decoder.layers.8.ffn.fc2.bias', 'text_decoder.layers.8.ffn.fc2.weight', 'text_decoder.layers.8.ffn_layer_norm.bias', 'text_decoder.layers.8.ffn_layer_norm.weight', 'text_decoder.layers.8.self_attn.k_proj.bias', 'text_decoder.layers.8.self_attn.k_proj.weight', 'text_decoder.layers.8.self_attn.out_proj.bias', 'text_decoder.layers.8.self_attn.out_proj.weight', 'text_decoder.layers.8.self_attn.q_proj.bias', 'text_decoder.layers.8.self_attn.q_proj.weight', 'text_decoder.layers.8.self_attn.v_proj.bias', 'text_decoder.layers.8.self_attn.v_proj.weight', 'text_decoder.layers.8.self_attn_layer_norm.bias', 'text_decoder.layers.8.self_attn_layer_norm.weight', 'text_decoder.layers.9.cross_attention.k_proj.bias', 'text_decoder.layers.9.cross_attention.k_proj.weight', 'text_decoder.layers.9.cross_attention.out_proj.bias', 'text_decoder.layers.9.cross_attention.out_proj.weight', 'text_decoder.layers.9.cross_attention.q_proj.bias', 'text_decoder.layers.9.cross_attention.q_proj.weight', 'text_decoder.layers.9.cross_attention.v_proj.bias', 'text_decoder.layers.9.cross_attention.v_proj.weight', 'text_decoder.layers.9.cross_attention_layer_norm.bias', 'text_decoder.layers.9.cross_attention_layer_norm.weight', 'text_decoder.layers.9.ffn.fc1.bias', 'text_decoder.layers.9.ffn.fc1.weight', 'text_decoder.layers.9.ffn.fc2.bias', 'text_decoder.layers.9.ffn.fc2.weight', 'text_decoder.layers.9.ffn_layer_norm.bias', 'text_decoder.layers.9.ffn_layer_norm.weight', 'text_decoder.layers.9.self_attn.k_proj.bias', 'text_decoder.layers.9.self_attn.k_proj.weight', 'text_decoder.layers.9.self_attn.out_proj.bias', 'text_decoder.layers.9.self_attn.out_proj.weight', 'text_decoder.layers.9.self_attn.q_proj.bias', 'text_decoder.layers.9.self_attn.q_proj.weight', 'text_decoder.layers.9.self_attn.v_proj.bias', 'text_decoder.layers.9.self_attn.v_proj.weight', 'text_decoder.layers.9.self_attn_layer_norm.bias', 'text_decoder.layers.9.self_attn_layer_norm.weight', 'text_encoder.embed_tokens.weight', 'text_encoder.layer_norm.bias', 'text_encoder.layer_norm.weight', 'text_encoder.layers.0.ffn.fc1.bias', 'text_encoder.layers.0.ffn.fc1.weight', 'text_encoder.layers.0.ffn.fc2.bias', 'text_encoder.layers.0.ffn.fc2.weight', 'text_encoder.layers.0.ffn_layer_norm.bias', 'text_encoder.layers.0.ffn_layer_norm.weight', 'text_encoder.layers.0.self_attn.k_proj.bias', 'text_encoder.layers.0.self_attn.k_proj.weight', 'text_encoder.layers.0.self_attn.out_proj.bias', 'text_encoder.layers.0.self_attn.out_proj.weight', 'text_encoder.layers.0.self_attn.q_proj.bias', 'text_encoder.layers.0.self_attn.q_proj.weight', 'text_encoder.layers.0.self_attn.v_proj.bias', 'text_encoder.layers.0.self_attn.v_proj.weight', 'text_encoder.layers.0.self_attn_layer_norm.bias', 'text_encoder.layers.0.self_attn_layer_norm.weight', 'text_encoder.layers.1.ffn.fc1.bias', 'text_encoder.layers.1.ffn.fc1.weight', 'text_encoder.layers.1.ffn.fc2.bias', 'text_encoder.layers.1.ffn.fc2.weight', 'text_encoder.layers.1.ffn_layer_norm.bias', 'text_encoder.layers.1.ffn_layer_norm.weight', 'text_encoder.layers.1.self_attn.k_proj.bias', 'text_encoder.layers.1.self_attn.k_proj.weight', 'text_encoder.layers.1.self_attn.out_proj.bias', 'text_encoder.layers.1.self_attn.out_proj.weight', 'text_encoder.layers.1.self_attn.q_proj.bias', 'text_encoder.layers.1.self_attn.q_proj.weight', 'text_encoder.layers.1.self_attn.v_proj.bias', 'text_encoder.layers.1.self_attn.v_proj.weight', 'text_encoder.layers.1.self_attn_layer_norm.bias', 'text_encoder.layers.1.self_attn_layer_norm.weight', 'text_encoder.layers.10.ffn.fc1.bias', 'text_encoder.layers.10.ffn.fc1.weight', 'text_encoder.layers.10.ffn.fc2.bias', 'text_encoder.layers.10.ffn.fc2.weight', 'text_encoder.layers.10.ffn_layer_norm.bias', 'text_encoder.layers.10.ffn_layer_norm.weight', 'text_encoder.layers.10.self_attn.k_proj.bias', 'text_encoder.layers.10.self_attn.k_proj.weight', 'text_encoder.layers.10.self_attn.out_proj.bias', 'text_encoder.layers.10.self_attn.out_proj.weight', 'text_encoder.layers.10.self_attn.q_proj.bias', 'text_encoder.layers.10.self_attn.q_proj.weight', 'text_encoder.layers.10.self_attn.v_proj.bias', 'text_encoder.layers.10.self_attn.v_proj.weight', 'text_encoder.layers.10.self_attn_layer_norm.bias', 'text_encoder.layers.10.self_attn_layer_norm.weight', 'text_encoder.layers.11.ffn.fc1.bias', 'text_encoder.layers.11.ffn.fc1.weight', 'text_encoder.layers.11.ffn.fc2.bias', 'text_encoder.layers.11.ffn.fc2.weight', 'text_encoder.layers.11.ffn_layer_norm.bias', 'text_encoder.layers.11.ffn_layer_norm.weight', 'text_encoder.layers.11.self_attn.k_proj.bias', 'text_encoder.layers.11.self_attn.k_proj.weight', 'text_encoder.layers.11.self_attn.out_proj.bias', 'text_encoder.layers.11.self_attn.out_proj.weight', 'text_encoder.layers.11.self_attn.q_proj.bias', 'text_encoder.layers.11.self_attn.q_proj.weight', 'text_encoder.layers.11.self_attn.v_proj.bias', 'text_encoder.layers.11.self_attn.v_proj.weight', 'text_encoder.layers.11.self_attn_layer_norm.bias', 'text_encoder.layers.11.self_attn_layer_norm.weight', 'text_encoder.layers.12.ffn.fc1.bias', 'text_encoder.layers.12.ffn.fc1.weight', 'text_encoder.layers.12.ffn.fc2.bias', 'text_encoder.layers.12.ffn.fc2.weight', 'text_encoder.layers.12.ffn_layer_norm.bias', 'text_encoder.layers.12.ffn_layer_norm.weight', 'text_encoder.layers.12.self_attn.k_proj.bias', 'text_encoder.layers.12.self_attn.k_proj.weight', 'text_encoder.layers.12.self_attn.out_proj.bias', 'text_encoder.layers.12.self_attn.out_proj.weight', 'text_encoder.layers.12.self_attn.q_proj.bias', 'text_encoder.layers.12.self_attn.q_proj.weight', 'text_encoder.layers.12.self_attn.v_proj.bias', 'text_encoder.layers.12.self_attn.v_proj.weight', 'text_encoder.layers.12.self_attn_layer_norm.bias', 'text_encoder.layers.12.self_attn_layer_norm.weight', 'text_encoder.layers.13.ffn.fc1.bias', 'text_encoder.layers.13.ffn.fc1.weight', 'text_encoder.layers.13.ffn.fc2.bias', 'text_encoder.layers.13.ffn.fc2.weight', 'text_encoder.layers.13.ffn_layer_norm.bias', 'text_encoder.layers.13.ffn_layer_norm.weight', 'text_encoder.layers.13.self_attn.k_proj.bias', 'text_encoder.layers.13.self_attn.k_proj.weight', 'text_encoder.layers.13.self_attn.out_proj.bias', 'text_encoder.layers.13.self_attn.out_proj.weight', 'text_encoder.layers.13.self_attn.q_proj.bias', 'text_encoder.layers.13.self_attn.q_proj.weight', 'text_encoder.layers.13.self_attn.v_proj.bias', 'text_encoder.layers.13.self_attn.v_proj.weight', 'text_encoder.layers.13.self_attn_layer_norm.bias', 'text_encoder.layers.13.self_attn_layer_norm.weight', 'text_encoder.layers.14.ffn.fc1.bias', 'text_encoder.layers.14.ffn.fc1.weight', 'text_encoder.layers.14.ffn.fc2.bias', 'text_encoder.layers.14.ffn.fc2.weight', 'text_encoder.layers.14.ffn_layer_norm.bias', 'text_encoder.layers.14.ffn_layer_norm.weight', 'text_encoder.layers.14.self_attn.k_proj.bias', 'text_encoder.layers.14.self_attn.k_proj.weight', 'text_encoder.layers.14.self_attn.out_proj.bias', 'text_encoder.layers.14.self_attn.out_proj.weight', 'text_encoder.layers.14.self_attn.q_proj.bias', 'text_encoder.layers.14.self_attn.q_proj.weight', 'text_encoder.layers.14.self_attn.v_proj.bias', 'text_encoder.layers.14.self_attn.v_proj.weight', 'text_encoder.layers.14.self_attn_layer_norm.bias', 'text_encoder.layers.14.self_attn_layer_norm.weight', 'text_encoder.layers.15.ffn.fc1.bias', 'text_encoder.layers.15.ffn.fc1.weight', 'text_encoder.layers.15.ffn.fc2.bias', 'text_encoder.layers.15.ffn.fc2.weight', 'text_encoder.layers.15.ffn_layer_norm.bias', 'text_encoder.layers.15.ffn_layer_norm.weight', 'text_encoder.layers.15.self_attn.k_proj.bias', 'text_encoder.layers.15.self_attn.k_proj.weight', 'text_encoder.layers.15.self_attn.out_proj.bias', 'text_encoder.layers.15.self_attn.out_proj.weight', 'text_encoder.layers.15.self_attn.q_proj.bias', 'text_encoder.layers.15.self_attn.q_proj.weight', 'text_encoder.layers.15.self_attn.v_proj.bias', 'text_encoder.layers.15.self_attn.v_proj.weight', 'text_encoder.layers.15.self_attn_layer_norm.bias', 'text_encoder.layers.15.self_attn_layer_norm.weight', 'text_encoder.layers.16.ffn.fc1.bias', 'text_encoder.layers.16.ffn.fc1.weight', 'text_encoder.layers.16.ffn.fc2.bias', 'text_encoder.layers.16.ffn.fc2.weight', 'text_encoder.layers.16.ffn_layer_norm.bias', 'text_encoder.layers.16.ffn_layer_norm.weight', 'text_encoder.layers.16.self_attn.k_proj.bias', 'text_encoder.layers.16.self_attn.k_proj.weight', 'text_encoder.layers.16.self_attn.out_proj.bias', 'text_encoder.layers.16.self_attn.out_proj.weight', 'text_encoder.layers.16.self_attn.q_proj.bias', 'text_encoder.layers.16.self_attn.q_proj.weight', 'text_encoder.layers.16.self_attn.v_proj.bias', 'text_encoder.layers.16.self_attn.v_proj.weight', 'text_encoder.layers.16.self_attn_layer_norm.bias', 'text_encoder.layers.16.self_attn_layer_norm.weight', 'text_encoder.layers.17.ffn.fc1.bias', 'text_encoder.layers.17.ffn.fc1.weight', 'text_encoder.layers.17.ffn.fc2.bias', 'text_encoder.layers.17.ffn.fc2.weight', 'text_encoder.layers.17.ffn_layer_norm.bias', 'text_encoder.layers.17.ffn_layer_norm.weight', 'text_encoder.layers.17.self_attn.k_proj.bias', 'text_encoder.layers.17.self_attn.k_proj.weight', 'text_encoder.layers.17.self_attn.out_proj.bias', 'text_encoder.layers.17.self_attn.out_proj.weight', 'text_encoder.layers.17.self_attn.q_proj.bias', 'text_encoder.layers.17.self_attn.q_proj.weight', 'text_encoder.layers.17.self_attn.v_proj.bias', 'text_encoder.layers.17.self_attn.v_proj.weight', 'text_encoder.layers.17.self_attn_layer_norm.bias', 'text_encoder.layers.17.self_attn_layer_norm.weight', 'text_encoder.layers.18.ffn.fc1.bias', 'text_encoder.layers.18.ffn.fc1.weight', 'text_encoder.layers.18.ffn.fc2.bias', 'text_encoder.layers.18.ffn.fc2.weight', 'text_encoder.layers.18.ffn_layer_norm.bias', 'text_encoder.layers.18.ffn_layer_norm.weight', 'text_encoder.layers.18.self_attn.k_proj.bias', 'text_encoder.layers.18.self_attn.k_proj.weight', 'text_encoder.layers.18.self_attn.out_proj.bias', 'text_encoder.layers.18.self_attn.out_proj.weight', 'text_encoder.layers.18.self_attn.q_proj.bias', 'text_encoder.layers.18.self_attn.q_proj.weight', 'text_encoder.layers.18.self_attn.v_proj.bias', 'text_encoder.layers.18.self_attn.v_proj.weight', 'text_encoder.layers.18.self_attn_layer_norm.bias', 'text_encoder.layers.18.self_attn_layer_norm.weight', 'text_encoder.layers.19.ffn.fc1.bias', 'text_encoder.layers.19.ffn.fc1.weight', 'text_encoder.layers.19.ffn.fc2.bias', 'text_encoder.layers.19.ffn.fc2.weight', 'text_encoder.layers.19.ffn_layer_norm.bias', 'text_encoder.layers.19.ffn_layer_norm.weight', 'text_encoder.layers.19.self_attn.k_proj.bias', 'text_encoder.layers.19.self_attn.k_proj.weight', 'text_encoder.layers.19.self_attn.out_proj.bias', 'text_encoder.layers.19.self_attn.out_proj.weight', 'text_encoder.layers.19.self_attn.q_proj.bias', 'text_encoder.layers.19.self_attn.q_proj.weight', 'text_encoder.layers.19.self_attn.v_proj.bias', 'text_encoder.layers.19.self_attn.v_proj.weight', 'text_encoder.layers.19.self_attn_layer_norm.bias', 'text_encoder.layers.19.self_attn_layer_norm.weight', 'text_encoder.layers.2.ffn.fc1.bias', 'text_encoder.layers.2.ffn.fc1.weight', 'text_encoder.layers.2.ffn.fc2.bias', 'text_encoder.layers.2.ffn.fc2.weight', 'text_encoder.layers.2.ffn_layer_norm.bias', 'text_encoder.layers.2.ffn_layer_norm.weight', 'text_encoder.layers.2.self_attn.k_proj.bias', 'text_encoder.layers.2.self_attn.k_proj.weight', 'text_encoder.layers.2.self_attn.out_proj.bias', 'text_encoder.layers.2.self_attn.out_proj.weight', 'text_encoder.layers.2.self_attn.q_proj.bias', 'text_encoder.layers.2.self_attn.q_proj.weight', 'text_encoder.layers.2.self_attn.v_proj.bias', 'text_encoder.layers.2.self_attn.v_proj.weight', 'text_encoder.layers.2.self_attn_layer_norm.bias', 'text_encoder.layers.2.self_attn_layer_norm.weight', 'text_encoder.layers.20.ffn.fc1.bias', 'text_encoder.layers.20.ffn.fc1.weight', 'text_encoder.layers.20.ffn.fc2.bias', 'text_encoder.layers.20.ffn.fc2.weight', 'text_encoder.layers.20.ffn_layer_norm.bias', 'text_encoder.layers.20.ffn_layer_norm.weight', 'text_encoder.layers.20.self_attn.k_proj.bias', 'text_encoder.layers.20.self_attn.k_proj.weight', 'text_encoder.layers.20.self_attn.out_proj.bias', 'text_encoder.layers.20.self_attn.out_proj.weight', 'text_encoder.layers.20.self_attn.q_proj.bias', 'text_encoder.layers.20.self_attn.q_proj.weight', 'text_encoder.layers.20.self_attn.v_proj.bias', 'text_encoder.layers.20.self_attn.v_proj.weight', 'text_encoder.layers.20.self_attn_layer_norm.bias', 'text_encoder.layers.20.self_attn_layer_norm.weight', 'text_encoder.layers.21.ffn.fc1.bias', 'text_encoder.layers.21.ffn.fc1.weight', 'text_encoder.layers.21.ffn.fc2.bias', 'text_encoder.layers.21.ffn.fc2.weight', 'text_encoder.layers.21.ffn_layer_norm.bias', 'text_encoder.layers.21.ffn_layer_norm.weight', 'text_encoder.layers.21.self_attn.k_proj.bias', 'text_encoder.layers.21.self_attn.k_proj.weight', 'text_encoder.layers.21.self_attn.out_proj.bias', 'text_encoder.layers.21.self_attn.out_proj.weight', 'text_encoder.layers.21.self_attn.q_proj.bias', 'text_encoder.layers.21.self_attn.q_proj.weight', 'text_encoder.layers.21.self_attn.v_proj.bias', 'text_encoder.layers.21.self_attn.v_proj.weight', 'text_encoder.layers.21.self_attn_layer_norm.bias', 'text_encoder.layers.21.self_attn_layer_norm.weight', 'text_encoder.layers.22.ffn.fc1.bias', 'text_encoder.layers.22.ffn.fc1.weight', 'text_encoder.layers.22.ffn.fc2.bias', 'text_encoder.layers.22.ffn.fc2.weight', 'text_encoder.layers.22.ffn_layer_norm.bias', 'text_encoder.layers.22.ffn_layer_norm.weight', 'text_encoder.layers.22.self_attn.k_proj.bias', 'text_encoder.layers.22.self_attn.k_proj.weight', 'text_encoder.layers.22.self_attn.out_proj.bias', 'text_encoder.layers.22.self_attn.out_proj.weight', 'text_encoder.layers.22.self_attn.q_proj.bias', 'text_encoder.layers.22.self_attn.q_proj.weight', 'text_encoder.layers.22.self_attn.v_proj.bias', 'text_encoder.layers.22.self_attn.v_proj.weight', 'text_encoder.layers.22.self_attn_layer_norm.bias', 'text_encoder.layers.22.self_attn_layer_norm.weight', 'text_encoder.layers.23.ffn.fc1.bias', 'text_encoder.layers.23.ffn.fc1.weight', 'text_encoder.layers.23.ffn.fc2.bias', 'text_encoder.layers.23.ffn.fc2.weight', 'text_encoder.layers.23.ffn_layer_norm.bias', 'text_encoder.layers.23.ffn_layer_norm.weight', 'text_encoder.layers.23.self_attn.k_proj.bias', 'text_encoder.layers.23.self_attn.k_proj.weight', 'text_encoder.layers.23.self_attn.out_proj.bias', 'text_encoder.layers.23.self_attn.out_proj.weight', 'text_encoder.layers.23.self_attn.q_proj.bias', 'text_encoder.layers.23.self_attn.q_proj.weight', 'text_encoder.layers.23.self_attn.v_proj.bias', 'text_encoder.layers.23.self_attn.v_proj.weight', 'text_encoder.layers.23.self_attn_layer_norm.bias', 'text_encoder.layers.23.self_attn_layer_norm.weight', 'text_encoder.layers.3.ffn.fc1.bias', 'text_encoder.layers.3.ffn.fc1.weight', 'text_encoder.layers.3.ffn.fc2.bias', 'text_encoder.layers.3.ffn.fc2.weight', 'text_encoder.layers.3.ffn_layer_norm.bias', 'text_encoder.layers.3.ffn_layer_norm.weight', 'text_encoder.layers.3.self_attn.k_proj.bias', 'text_encoder.layers.3.self_attn.k_proj.weight', 'text_encoder.layers.3.self_attn.out_proj.bias', 'text_encoder.layers.3.self_attn.out_proj.weight', 'text_encoder.layers.3.self_attn.q_proj.bias', 'text_encoder.layers.3.self_attn.q_proj.weight', 'text_encoder.layers.3.self_attn.v_proj.bias', 'text_encoder.layers.3.self_attn.v_proj.weight', 'text_encoder.layers.3.self_attn_layer_norm.bias', 'text_encoder.layers.3.self_attn_layer_norm.weight', 'text_encoder.layers.4.ffn.fc1.bias', 'text_encoder.layers.4.ffn.fc1.weight', 'text_encoder.layers.4.ffn.fc2.bias', 'text_encoder.layers.4.ffn.fc2.weight', 'text_encoder.layers.4.ffn_layer_norm.bias', 'text_encoder.layers.4.ffn_layer_norm.weight', 'text_encoder.layers.4.self_attn.k_proj.bias', 'text_encoder.layers.4.self_attn.k_proj.weight', 'text_encoder.layers.4.self_attn.out_proj.bias', 'text_encoder.layers.4.self_attn.out_proj.weight', 'text_encoder.layers.4.self_attn.q_proj.bias', 'text_encoder.layers.4.self_attn.q_proj.weight', 'text_encoder.layers.4.self_attn.v_proj.bias', 'text_encoder.layers.4.self_attn.v_proj.weight', 'text_encoder.layers.4.self_attn_layer_norm.bias', 'text_encoder.layers.4.self_attn_layer_norm.weight', 'text_encoder.layers.5.ffn.fc1.bias', 'text_encoder.layers.5.ffn.fc1.weight', 'text_encoder.layers.5.ffn.fc2.bias', 'text_encoder.layers.5.ffn.fc2.weight', 'text_encoder.layers.5.ffn_layer_norm.bias', 'text_encoder.layers.5.ffn_layer_norm.weight', 'text_encoder.layers.5.self_attn.k_proj.bias', 'text_encoder.layers.5.self_attn.k_proj.weight', 'text_encoder.layers.5.self_attn.out_proj.bias', 'text_encoder.layers.5.self_attn.out_proj.weight', 'text_encoder.layers.5.self_attn.q_proj.bias', 'text_encoder.layers.5.self_attn.q_proj.weight', 'text_encoder.layers.5.self_attn.v_proj.bias', 'text_encoder.layers.5.self_attn.v_proj.weight', 'text_encoder.layers.5.self_attn_layer_norm.bias', 'text_encoder.layers.5.self_attn_layer_norm.weight', 'text_encoder.layers.6.ffn.fc1.bias', 'text_encoder.layers.6.ffn.fc1.weight', 'text_encoder.layers.6.ffn.fc2.bias', 'text_encoder.layers.6.ffn.fc2.weight', 'text_encoder.layers.6.ffn_layer_norm.bias', 'text_encoder.layers.6.ffn_layer_norm.weight', 'text_encoder.layers.6.self_attn.k_proj.bias', 'text_encoder.layers.6.self_attn.k_proj.weight', 'text_encoder.layers.6.self_attn.out_proj.bias', 'text_encoder.layers.6.self_attn.out_proj.weight', 'text_encoder.layers.6.self_attn.q_proj.bias', 'text_encoder.layers.6.self_attn.q_proj.weight', 'text_encoder.layers.6.self_attn.v_proj.bias', 'text_encoder.layers.6.self_attn.v_proj.weight', 'text_encoder.layers.6.self_attn_layer_norm.bias', 'text_encoder.layers.6.self_attn_layer_norm.weight', 'text_encoder.layers.7.ffn.fc1.bias', 'text_encoder.layers.7.ffn.fc1.weight', 'text_encoder.layers.7.ffn.fc2.bias', 'text_encoder.layers.7.ffn.fc2.weight', 'text_encoder.layers.7.ffn_layer_norm.bias', 'text_encoder.layers.7.ffn_layer_norm.weight', 'text_encoder.layers.7.self_attn.k_proj.bias', 'text_encoder.layers.7.self_attn.k_proj.weight', 'text_encoder.layers.7.self_attn.out_proj.bias', 'text_encoder.layers.7.self_attn.out_proj.weight', 'text_encoder.layers.7.self_attn.q_proj.bias', 'text_encoder.layers.7.self_attn.q_proj.weight', 'text_encoder.layers.7.self_attn.v_proj.bias', 'text_encoder.layers.7.self_attn.v_proj.weight', 'text_encoder.layers.7.self_attn_layer_norm.bias', 'text_encoder.layers.7.self_attn_layer_norm.weight', 'text_encoder.layers.8.ffn.fc1.bias', 'text_encoder.layers.8.ffn.fc1.weight', 'text_encoder.layers.8.ffn.fc2.bias', 'text_encoder.layers.8.ffn.fc2.weight', 'text_encoder.layers.8.ffn_layer_norm.bias', 'text_encoder.layers.8.ffn_layer_norm.weight', 'text_encoder.layers.8.self_attn.k_proj.bias', 'text_encoder.layers.8.self_attn.k_proj.weight', 'text_encoder.layers.8.self_attn.out_proj.bias', 'text_encoder.layers.8.self_attn.out_proj.weight', 'text_encoder.layers.8.self_attn.q_proj.bias', 'text_encoder.layers.8.self_attn.q_proj.weight', 'text_encoder.layers.8.self_attn.v_proj.bias', 'text_encoder.layers.8.self_attn.v_proj.weight', 'text_encoder.layers.8.self_attn_layer_norm.bias', 'text_encoder.layers.8.self_attn_layer_norm.weight', 'text_encoder.layers.9.ffn.fc1.bias', 'text_encoder.layers.9.ffn.fc1.weight', 'text_encoder.layers.9.ffn.fc2.bias', 'text_encoder.layers.9.ffn.fc2.weight', 'text_encoder.layers.9.ffn_layer_norm.bias', 'text_encoder.layers.9.ffn_layer_norm.weight', 'text_encoder.layers.9.self_attn.k_proj.bias', 'text_encoder.layers.9.self_attn.k_proj.weight', 'text_encoder.layers.9.self_attn.out_proj.bias', 'text_encoder.layers.9.self_attn.out_proj.weight', 'text_encoder.layers.9.self_attn.q_proj.bias', 'text_encoder.layers.9.self_attn.q_proj.weight', 'text_encoder.layers.9.self_attn.v_proj.bias', 'text_encoder.layers.9.self_attn.v_proj.weight', 'text_encoder.layers.9.self_attn_layer_norm.bias', 'text_encoder.layers.9.self_attn_layer_norm.weight', 'vocoder.dur_predictor.conv1.bias', 'vocoder.dur_predictor.conv1.weight', 'vocoder.dur_predictor.conv2.bias', 'vocoder.dur_predictor.conv2.weight', 'vocoder.dur_predictor.ln1.bias', 'vocoder.dur_predictor.ln1.weight', 'vocoder.dur_predictor.ln2.bias', 'vocoder.dur_predictor.ln2.weight', 'vocoder.dur_predictor.proj.bias', 'vocoder.dur_predictor.proj.weight', 'vocoder.hifi_gan.conv_post.bias', 'vocoder.hifi_gan.conv_post.weight', 'vocoder.hifi_gan.conv_pre.bias', 'vocoder.hifi_gan.conv_pre.weight', 'vocoder.hifi_gan.resblocks.0.convs1.0.bias', 'vocoder.hifi_gan.resblocks.0.convs1.0.weight', 'vocoder.hifi_gan.resblocks.0.convs1.1.bias', 'vocoder.hifi_gan.resblocks.0.convs1.1.weight', 'vocoder.hifi_gan.resblocks.0.convs1.2.bias', 'vocoder.hifi_gan.resblocks.0.convs1.2.weight', 'vocoder.hifi_gan.resblocks.0.convs2.0.bias', 'vocoder.hifi_gan.resblocks.0.convs2.0.weight', 'vocoder.hifi_gan.resblocks.0.convs2.1.bias', 'vocoder.hifi_gan.resblocks.0.convs2.1.weight', 'vocoder.hifi_gan.resblocks.0.convs2.2.bias', 'vocoder.hifi_gan.resblocks.0.convs2.2.weight', 'vocoder.hifi_gan.resblocks.1.convs1.0.bias', 'vocoder.hifi_gan.resblocks.1.convs1.0.weight', 'vocoder.hifi_gan.resblocks.1.convs1.1.bias', 'vocoder.hifi_gan.resblocks.1.convs1.1.weight', 'vocoder.hifi_gan.resblocks.1.convs1.2.bias', 'vocoder.hifi_gan.resblocks.1.convs1.2.weight', 'vocoder.hifi_gan.resblocks.1.convs2.0.bias', 'vocoder.hifi_gan.resblocks.1.convs2.0.weight', 'vocoder.hifi_gan.resblocks.1.convs2.1.bias', 'vocoder.hifi_gan.resblocks.1.convs2.1.weight', 'vocoder.hifi_gan.resblocks.1.convs2.2.bias', 'vocoder.hifi_gan.resblocks.1.convs2.2.weight', 'vocoder.hifi_gan.resblocks.10.convs1.0.bias', 'vocoder.hifi_gan.resblocks.10.convs1.0.weight', 'vocoder.hifi_gan.resblocks.10.convs1.1.bias', 'vocoder.hifi_gan.resblocks.10.convs1.1.weight', 'vocoder.hifi_gan.resblocks.10.convs1.2.bias', 'vocoder.hifi_gan.resblocks.10.convs1.2.weight', 'vocoder.hifi_gan.resblocks.10.convs2.0.bias', 'vocoder.hifi_gan.resblocks.10.convs2.0.weight', 'vocoder.hifi_gan.resblocks.10.convs2.1.bias', 'vocoder.hifi_gan.resblocks.10.convs2.1.weight', 'vocoder.hifi_gan.resblocks.10.convs2.2.bias', 'vocoder.hifi_gan.resblocks.10.convs2.2.weight', 'vocoder.hifi_gan.resblocks.11.convs1.0.bias', 'vocoder.hifi_gan.resblocks.11.convs1.0.weight', 'vocoder.hifi_gan.resblocks.11.convs1.1.bias', 'vocoder.hifi_gan.resblocks.11.convs1.1.weight', 'vocoder.hifi_gan.resblocks.11.convs1.2.bias', 'vocoder.hifi_gan.resblocks.11.convs1.2.weight', 'vocoder.hifi_gan.resblocks.11.convs2.0.bias', 'vocoder.hifi_gan.resblocks.11.convs2.0.weight', 'vocoder.hifi_gan.resblocks.11.convs2.1.bias', 'vocoder.hifi_gan.resblocks.11.convs2.1.weight', 'vocoder.hifi_gan.resblocks.11.convs2.2.bias', 'vocoder.hifi_gan.resblocks.11.convs2.2.weight', 'vocoder.hifi_gan.resblocks.12.convs1.0.bias', 'vocoder.hifi_gan.resblocks.12.convs1.0.weight', 'vocoder.hifi_gan.resblocks.12.convs1.1.bias', 'vocoder.hifi_gan.resblocks.12.convs1.1.weight', 'vocoder.hifi_gan.resblocks.12.convs1.2.bias', 'vocoder.hifi_gan.resblocks.12.convs1.2.weight', 'vocoder.hifi_gan.resblocks.12.convs2.0.bias', 'vocoder.hifi_gan.resblocks.12.convs2.0.weight', 'vocoder.hifi_gan.resblocks.12.convs2.1.bias', 'vocoder.hifi_gan.resblocks.12.convs2.1.weight', 'vocoder.hifi_gan.resblocks.12.convs2.2.bias', 'vocoder.hifi_gan.resblocks.12.convs2.2.weight', 'vocoder.hifi_gan.resblocks.13.convs1.0.bias', 'vocoder.hifi_gan.resblocks.13.convs1.0.weight', 'vocoder.hifi_gan.resblocks.13.convs1.1.bias', 'vocoder.hifi_gan.resblocks.13.convs1.1.weight', 'vocoder.hifi_gan.resblocks.13.convs1.2.bias', 'vocoder.hifi_gan.resblocks.13.convs1.2.weight', 'vocoder.hifi_gan.resblocks.13.convs2.0.bias', 'vocoder.hifi_gan.resblocks.13.convs2.0.weight', 'vocoder.hifi_gan.resblocks.13.convs2.1.bias', 'vocoder.hifi_gan.resblocks.13.convs2.1.weight', 'vocoder.hifi_gan.resblocks.13.convs2.2.bias', 'vocoder.hifi_gan.resblocks.13.convs2.2.weight', 'vocoder.hifi_gan.resblocks.14.convs1.0.bias', 'vocoder.hifi_gan.resblocks.14.convs1.0.weight', 'vocoder.hifi_gan.resblocks.14.convs1.1.bias', 'vocoder.hifi_gan.resblocks.14.convs1.1.weight', 'vocoder.hifi_gan.resblocks.14.convs1.2.bias', 'vocoder.hifi_gan.resblocks.14.convs1.2.weight', 'vocoder.hifi_gan.resblocks.14.convs2.0.bias', 'vocoder.hifi_gan.resblocks.14.convs2.0.weight', 'vocoder.hifi_gan.resblocks.14.convs2.1.bias', 'vocoder.hifi_gan.resblocks.14.convs2.1.weight', 'vocoder.hifi_gan.resblocks.14.convs2.2.bias', 'vocoder.hifi_gan.resblocks.14.convs2.2.weight', 'vocoder.hifi_gan.resblocks.2.convs1.0.bias', 'vocoder.hifi_gan.resblocks.2.convs1.0.weight', 'vocoder.hifi_gan.resblocks.2.convs1.1.bias', 'vocoder.hifi_gan.resblocks.2.convs1.1.weight', 'vocoder.hifi_gan.resblocks.2.convs1.2.bias', 'vocoder.hifi_gan.resblocks.2.convs1.2.weight', 'vocoder.hifi_gan.resblocks.2.convs2.0.bias', 'vocoder.hifi_gan.resblocks.2.convs2.0.weight', 'vocoder.hifi_gan.resblocks.2.convs2.1.bias', 'vocoder.hifi_gan.resblocks.2.convs2.1.weight', 'vocoder.hifi_gan.resblocks.2.convs2.2.bias', 'vocoder.hifi_gan.resblocks.2.convs2.2.weight', 'vocoder.hifi_gan.resblocks.3.convs1.0.bias', 'vocoder.hifi_gan.resblocks.3.convs1.0.weight', 'vocoder.hifi_gan.resblocks.3.convs1.1.bias', 'vocoder.hifi_gan.resblocks.3.convs1.1.weight', 'vocoder.hifi_gan.resblocks.3.convs1.2.bias', 'vocoder.hifi_gan.resblocks.3.convs1.2.weight', 'vocoder.hifi_gan.resblocks.3.convs2.0.bias', 'vocoder.hifi_gan.resblocks.3.convs2.0.weight', 'vocoder.hifi_gan.resblocks.3.convs2.1.bias', 'vocoder.hifi_gan.resblocks.3.convs2.1.weight', 'vocoder.hifi_gan.resblocks.3.convs2.2.bias', 'vocoder.hifi_gan.resblocks.3.convs2.2.weight', 'vocoder.hifi_gan.resblocks.4.convs1.0.bias', 'vocoder.hifi_gan.resblocks.4.convs1.0.weight', 'vocoder.hifi_gan.resblocks.4.convs1.1.bias', 'vocoder.hifi_gan.resblocks.4.convs1.1.weight', 'vocoder.hifi_gan.resblocks.4.convs1.2.bias', 'vocoder.hifi_gan.resblocks.4.convs1.2.weight', 'vocoder.hifi_gan.resblocks.4.convs2.0.bias', 'vocoder.hifi_gan.resblocks.4.convs2.0.weight', 'vocoder.hifi_gan.resblocks.4.convs2.1.bias', 'vocoder.hifi_gan.resblocks.4.convs2.1.weight', 'vocoder.hifi_gan.resblocks.4.convs2.2.bias', 'vocoder.hifi_gan.resblocks.4.convs2.2.weight', 'vocoder.hifi_gan.resblocks.5.convs1.0.bias', 'vocoder.hifi_gan.resblocks.5.convs1.0.weight', 'vocoder.hifi_gan.resblocks.5.convs1.1.bias', 'vocoder.hifi_gan.resblocks.5.convs1.1.weight', 'vocoder.hifi_gan.resblocks.5.convs1.2.bias', 'vocoder.hifi_gan.resblocks.5.convs1.2.weight', 'vocoder.hifi_gan.resblocks.5.convs2.0.bias', 'vocoder.hifi_gan.resblocks.5.convs2.0.weight', 'vocoder.hifi_gan.resblocks.5.convs2.1.bias', 'vocoder.hifi_gan.resblocks.5.convs2.1.weight', 'vocoder.hifi_gan.resblocks.5.convs2.2.bias', 'vocoder.hifi_gan.resblocks.5.convs2.2.weight', 'vocoder.hifi_gan.resblocks.6.convs1.0.bias', 'vocoder.hifi_gan.resblocks.6.convs1.0.weight', 'vocoder.hifi_gan.resblocks.6.convs1.1.bias', 'vocoder.hifi_gan.resblocks.6.convs1.1.weight', 'vocoder.hifi_gan.resblocks.6.convs1.2.bias', 'vocoder.hifi_gan.resblocks.6.convs1.2.weight', 'vocoder.hifi_gan.resblocks.6.convs2.0.bias', 'vocoder.hifi_gan.resblocks.6.convs2.0.weight', 'vocoder.hifi_gan.resblocks.6.convs2.1.bias', 'vocoder.hifi_gan.resblocks.6.convs2.1.weight', 'vocoder.hifi_gan.resblocks.6.convs2.2.bias', 'vocoder.hifi_gan.resblocks.6.convs2.2.weight', 'vocoder.hifi_gan.resblocks.7.convs1.0.bias', 'vocoder.hifi_gan.resblocks.7.convs1.0.weight', 'vocoder.hifi_gan.resblocks.7.convs1.1.bias', 'vocoder.hifi_gan.resblocks.7.convs1.1.weight', 'vocoder.hifi_gan.resblocks.7.convs1.2.bias', 'vocoder.hifi_gan.resblocks.7.convs1.2.weight', 'vocoder.hifi_gan.resblocks.7.convs2.0.bias', 'vocoder.hifi_gan.resblocks.7.convs2.0.weight', 'vocoder.hifi_gan.resblocks.7.convs2.1.bias', 'vocoder.hifi_gan.resblocks.7.convs2.1.weight', 'vocoder.hifi_gan.resblocks.7.convs2.2.bias', 'vocoder.hifi_gan.resblocks.7.convs2.2.weight', 'vocoder.hifi_gan.resblocks.8.convs1.0.bias', 'vocoder.hifi_gan.resblocks.8.convs1.0.weight', 'vocoder.hifi_gan.resblocks.8.convs1.1.bias', 'vocoder.hifi_gan.resblocks.8.convs1.1.weight', 'vocoder.hifi_gan.resblocks.8.convs1.2.bias', 'vocoder.hifi_gan.resblocks.8.convs1.2.weight', 'vocoder.hifi_gan.resblocks.8.convs2.0.bias', 'vocoder.hifi_gan.resblocks.8.convs2.0.weight', 'vocoder.hifi_gan.resblocks.8.convs2.1.bias', 'vocoder.hifi_gan.resblocks.8.convs2.1.weight', 'vocoder.hifi_gan.resblocks.8.convs2.2.bias', 'vocoder.hifi_gan.resblocks.8.convs2.2.weight', 'vocoder.hifi_gan.resblocks.9.convs1.0.bias', 'vocoder.hifi_gan.resblocks.9.convs1.0.weight', 'vocoder.hifi_gan.resblocks.9.convs1.1.bias', 'vocoder.hifi_gan.resblocks.9.convs1.1.weight', 'vocoder.hifi_gan.resblocks.9.convs1.2.bias', 'vocoder.hifi_gan.resblocks.9.convs1.2.weight', 'vocoder.hifi_gan.resblocks.9.convs2.0.bias', 'vocoder.hifi_gan.resblocks.9.convs2.0.weight', 'vocoder.hifi_gan.resblocks.9.convs2.1.bias', 'vocoder.hifi_gan.resblocks.9.convs2.1.weight', 'vocoder.hifi_gan.resblocks.9.convs2.2.bias', 'vocoder.hifi_gan.resblocks.9.convs2.2.weight', 'vocoder.hifi_gan.upsampler.0.bias', 'vocoder.hifi_gan.upsampler.0.weight', 'vocoder.hifi_gan.upsampler.1.bias', 'vocoder.hifi_gan.upsampler.1.weight', 'vocoder.hifi_gan.upsampler.2.bias', 'vocoder.hifi_gan.upsampler.2.weight', 'vocoder.hifi_gan.upsampler.3.bias', 'vocoder.hifi_gan.upsampler.3.weight', 'vocoder.hifi_gan.upsampler.4.bias', 'vocoder.hifi_gan.upsampler.4.weight', 'vocoder.language_embedding.weight', 'vocoder.speaker_embedding.weight', 'vocoder.unit_embedding.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #009933\">[04:14:46] SUCCESS: Model loaded successfully</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #0066cc\">[04:14:46] INFO: Loading Seamless processor...</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #cc0000\">[04:14:46] ERROR: Failed to load tokenizer/processor: expected str, bytes or os.PathLike object, not NoneType</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:14:46] DEBUG: Stack trace for tokenizer error: TypeError: expected str, bytes or os.PathLike object, not NoneType</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #cc0000\">[04:14:46] ERROR: Failed to load model: expected str, bytes or os.PathLike object, not NoneType</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"margin:0; padding:2px 0; color: #666666\">[04:14:46] DEBUG: Stack trace for model error: TypeError: expected str, bytes or os.PathLike object, not NoneType</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to load model: expected str, bytes or os.PathLike object, not NoneType\n"
          ]
        }
      ]
    }
  ]
}