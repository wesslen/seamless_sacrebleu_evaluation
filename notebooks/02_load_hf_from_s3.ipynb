{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfOcrRq3trstEnM5pthriX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wesslen/seamless_sacrebleu_evaluation/blob/main/notebooks/02_load_hf_from_s3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8t2osjYZJ6fO"
      },
      "outputs": [],
      "source": [
        "import boto3\n",
        "import json\n",
        "import os\n",
        "from contextlib import contextmanager\n",
        "from io import BytesIO\n",
        "from tempfile import NamedTemporaryFile, TemporaryDirectory\n",
        "from transformers import AutoModel, AutoTokenizer, PretrainedConfig\n",
        "from typing import Tuple, Optional, Union, List, Dict\n",
        "from pathlib import Path\n",
        "\n",
        "@contextmanager\n",
        "def s3_fileobj(bucket: str, key: str, endpoint_url: Optional[str] = None):\n",
        "    \"\"\"\n",
        "    Yields a file object from the filename at {bucket}/{key}\n",
        "\n",
        "    Args:\n",
        "        bucket (str): Name of the S3 bucket where your model is stored\n",
        "        key (str): Path to the file within the bucket\n",
        "        endpoint_url (str, optional): Custom endpoint URL for S3-compatible storage\n",
        "    \"\"\"\n",
        "    s3 = boto3.client(\n",
        "        \"s3\",\n",
        "        endpoint_url=endpoint_url,\n",
        "        aws_access_key_id=os.environ.get('AWS_ACCESS_KEY_ID'),\n",
        "        aws_secret_access_key=os.environ.get('AWS_SECRET_ACCESS_KEY')\n",
        "    )\n",
        "    try:\n",
        "        obj = s3.get_object(Bucket=bucket, Key=key)\n",
        "        yield BytesIO(obj[\"Body\"].read())\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"Failed to read {key} from bucket {bucket}: {str(e)}\")\n",
        "\n",
        "def list_s3_files(bucket: str, prefix: str, endpoint_url: Optional[str] = None) -> List[str]:\n",
        "    \"\"\"List all files under a prefix in an S3 bucket.\"\"\"\n",
        "    s3 = boto3.client(\n",
        "        \"s3\",\n",
        "        endpoint_url=endpoint_url,\n",
        "        aws_access_key_id=os.environ.get('AWS_ACCESS_KEY_ID'),\n",
        "        aws_secret_access_key=os.environ.get('AWS_SECRET_ACCESS_KEY')\n",
        "    )\n",
        "\n",
        "    files = []\n",
        "    paginator = s3.get_paginator('list_objects_v2')\n",
        "    for page in paginator.paginate(Bucket=bucket, Prefix=prefix):\n",
        "        if 'Contents' in page:\n",
        "            files.extend(obj['Key'] for obj in page['Contents'])\n",
        "    return files\n",
        "\n",
        "def load_model_from_s3(\n",
        "    bucket: str,\n",
        "    path_to_model: str,\n",
        "    endpoint_url: Optional[str] = None,\n",
        "    force_bin: bool = False,\n",
        ") -> Tuple[Union[AutoModel, None], Union[AutoTokenizer, None]]:\n",
        "    \"\"\"\n",
        "    Load a model and tokenizer from S3 storage, preferring .safetensors format.\n",
        "\n",
        "    Args:\n",
        "        bucket (str): S3 bucket name\n",
        "        path_to_model (str): Path to model directory in bucket\n",
        "        endpoint_url (str, optional): Custom S3 endpoint URL\n",
        "        force_bin (bool): Force using .bin format even if .safetensors is available\n",
        "\n",
        "    Returns:\n",
        "        tuple: (model, tokenizer)\n",
        "    \"\"\"\n",
        "    # List all files in the model directory\n",
        "    files = list_s3_files(bucket, path_to_model, endpoint_url)\n",
        "\n",
        "    # Check for single consolidated safetensors file\n",
        "    safetensors_files = [f for f in files if f.endswith('.safetensors')]\n",
        "    bin_files = [f for f in files if f.endswith('.bin')]\n",
        "\n",
        "    with TemporaryDirectory() as temp_dir:\n",
        "        temp_path = Path(temp_dir)\n",
        "        config_path = None\n",
        "\n",
        "        # Download config.json first as it's needed for both formats\n",
        "        config_file = next((f for f in files if f.endswith('config.json')), None)\n",
        "        if config_file:\n",
        "            config_path = temp_path / 'config.json'\n",
        "            with s3_fileobj(bucket, config_file, endpoint_url) as f:\n",
        "                with open(config_path, 'wb') as out:\n",
        "                    out.write(f.read())\n",
        "\n",
        "        # Determine if we have a single safetensors file or multiple files in subfolders\n",
        "        if safetensors_files and not force_bin:\n",
        "            print(\"Using safetensors format for model loading\")\n",
        "\n",
        "            # Download all safetensors files preserving directory structure\n",
        "            for file in safetensors_files:\n",
        "                relative_path = Path(file).relative_to(path_to_model)\n",
        "                target_path = temp_path / relative_path\n",
        "                target_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "                with s3_fileobj(bucket, file, endpoint_url) as f:\n",
        "                    with open(target_path, 'wb') as out:\n",
        "                        out.write(f.read())\n",
        "\n",
        "        # Fallback to .bin format if no safetensors or force_bin=True\n",
        "        elif bin_files:\n",
        "            print(\"Using .bin format for model loading\")\n",
        "            for file in bin_files:\n",
        "                relative_path = Path(file).relative_to(path_to_model)\n",
        "                target_path = temp_path / relative_path\n",
        "                target_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "                with s3_fileobj(bucket, file, endpoint_url) as f:\n",
        "                    with open(target_path, 'wb') as out:\n",
        "                        out.write(f.read())\n",
        "\n",
        "        # Download tokenizer files if they exist\n",
        "        tokenizer_files = [f for f in files if any(f.endswith(ext) for ext in\n",
        "                          ['.tokenizer.json', 'tokenizer_config.json', 'special_tokens_map.json', 'vocab.json', 'merges.txt'])]\n",
        "        for file in tokenizer_files:\n",
        "            relative_path = Path(file).relative_to(path_to_model)\n",
        "            target_path = temp_path / relative_path\n",
        "            target_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "            with s3_fileobj(bucket, file, endpoint_url) as f:\n",
        "                with open(target_path, 'wb') as out:\n",
        "                    out.write(f.read())\n",
        "\n",
        "        # Load the model and tokenizer\n",
        "        try:\n",
        "            model = AutoModel.from_pretrained(\n",
        "                temp_path,\n",
        "                local_files_only=True,\n",
        "                use_safetensors=not force_bin\n",
        "            )\n",
        "\n",
        "            tokenizer = AutoTokenizer.from_pretrained(\n",
        "                temp_path,\n",
        "                local_files_only=True\n",
        "            ) if tokenizer_files else None\n",
        "\n",
        "            return model, tokenizer\n",
        "\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Failed to load model: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a model preferring safetensors (default)\n",
        "model, tokenizer = load_model_from_s3(\n",
        "    bucket=\"my-bucket\",\n",
        "    path_to_model=\"models/stable-diffusion-v1-5\",\n",
        "    endpoint_url=\"https://your-storagegrid-endpoint\"\n",
        ")\n",
        "\n",
        "# Force using .bin format if needed\n",
        "model, tokenizer = load_model_from_s3(\n",
        "    bucket=\"my-bucket\",\n",
        "    path_to_model=\"models/stable-diffusion-v1-5\",\n",
        "    force_bin=True\n",
        ")"
      ],
      "metadata": {
        "id": "_ChlOgdWJ8ET"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}