{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/mUTofgfkUsjVVx806Up+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wesslen/seamless_sacrebleu_evaluation/blob/main/notebooks/02_load_hf_from_s3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8t2osjYZJ6fO"
      },
      "outputs": [],
      "source": [
        "import boto3\n",
        "from botocore.config import Config\n",
        "import json\n",
        "import os\n",
        "from contextlib import contextmanager\n",
        "from io import BytesIO\n",
        "from tempfile import TemporaryDirectory\n",
        "from transformers import AutoModel, AutoTokenizer, PretrainedConfig\n",
        "from typing import Tuple, Optional, Union, List, Dict\n",
        "from pathlib import Path\n",
        "import urllib3\n",
        "import warnings\n",
        "from IPython.display import display, HTML\n",
        "from datetime import datetime\n",
        "import sys\n",
        "\n",
        "class NotebookLogger:\n",
        "    \"\"\"Custom logger for Jupyter notebooks with colored output\"\"\"\n",
        "\n",
        "    COLORS = {\n",
        "        'INFO': '#0066cc',\n",
        "        'DEBUG': '#666666',\n",
        "        'WARNING': '#ff9900',\n",
        "        'ERROR': '#cc0000',\n",
        "        'SUCCESS': '#009933'\n",
        "    }\n",
        "\n",
        "    def __init__(self, debug=False):\n",
        "        self.debug = debug\n",
        "\n",
        "    def _log(self, level: str, message: str):\n",
        "        timestamp = datetime.now().strftime('%H:%M:%S')\n",
        "        color = self.COLORS.get(level, '#000000')\n",
        "        display(HTML(\n",
        "            f'<pre style=\"margin:0; padding:2px 0; color: {color}\">'\n",
        "            f'[{timestamp}] {level}: {message}'\n",
        "            '</pre>'\n",
        "        ))\n",
        "\n",
        "    def info(self, message: str):\n",
        "        self._log('INFO', message)\n",
        "\n",
        "    def debug(self, message: str):\n",
        "        if self.debug:\n",
        "            self._log('DEBUG', message)\n",
        "\n",
        "    def warning(self, message: str):\n",
        "        self._log('WARNING', message)\n",
        "\n",
        "    def error(self, message: str):\n",
        "        self._log('ERROR', message)\n",
        "\n",
        "    def success(self, message: str):\n",
        "        self._log('SUCCESS', message)\n",
        "\n",
        "def get_s3_client(endpoint_url: Optional[str] = None, verify_ssl: bool = True, logger: NotebookLogger = None):\n",
        "    \"\"\"Create an S3 client with configurable SSL verification.\"\"\"\n",
        "    if logger:\n",
        "        logger.debug(f\"Creating S3 client with endpoint: {endpoint_url}, verify_ssl: {verify_ssl}\")\n",
        "\n",
        "    if not verify_ssl:\n",
        "        warnings.filterwarnings('ignore', category=urllib3.exceptions.InsecureRequestWarning)\n",
        "\n",
        "    config = Config(retries=dict(max_attempts=3))\n",
        "\n",
        "    return boto3.client(\n",
        "        's3',\n",
        "        endpoint_url=endpoint_url,\n",
        "        aws_access_key_id=os.environ.get('AWS_ACCESS_KEY_ID'),\n",
        "        aws_secret_access_key=os.environ.get('AWS_SECRET_ACCESS_KEY'),\n",
        "        verify=verify_ssl,\n",
        "        config=config\n",
        "    )\n",
        "\n",
        "def list_s3_files(bucket: str, prefix: str, endpoint_url: Optional[str] = None,\n",
        "                  verify_ssl: bool = True, logger: NotebookLogger = None) -> List[str]:\n",
        "    \"\"\"List all files under a prefix in an S3 bucket.\"\"\"\n",
        "    s3_client = get_s3_client(endpoint_url, verify_ssl, logger)\n",
        "\n",
        "    if logger:\n",
        "        logger.debug(f\"Listing files in bucket: {bucket}, prefix: {prefix}\")\n",
        "\n",
        "    files = []\n",
        "    paginator = s3_client.get_paginator('list_objects_v2')\n",
        "    for page in paginator.paginate(Bucket=bucket, Prefix=prefix):\n",
        "        if 'Contents' in page:\n",
        "            files.extend(obj['Key'] for obj in page['Contents'])\n",
        "\n",
        "    if logger:\n",
        "        logger.debug(f\"Found {len(files)} files\")\n",
        "        for file in files:\n",
        "            logger.debug(f\"Found file: {file}\")\n",
        "\n",
        "    return files\n",
        "\n",
        "def load_model_from_s3(\n",
        "    bucket: str,\n",
        "    path_to_model: str,\n",
        "    endpoint_url: Optional[str] = None,\n",
        "    verify_ssl: bool = True,\n",
        "    force_bin: bool = False,\n",
        "    debug: bool = False\n",
        ") -> Tuple[Union[AutoModel, None], Union[AutoTokenizer, None]]:\n",
        "    \"\"\"\n",
        "    Load a model and tokenizer from S3 storage, preferring .safetensors format.\n",
        "    \"\"\"\n",
        "    logger = NotebookLogger(debug=debug)\n",
        "    logger.info(f\"Starting model load from bucket: {bucket}, path: {path_to_model}\")\n",
        "\n",
        "    # List all files in the model directory\n",
        "    files = list_s3_files(bucket, path_to_model, endpoint_url, verify_ssl, logger)\n",
        "\n",
        "    # Check for model files\n",
        "    safetensors_files = [f for f in files if f.endswith('.safetensors')]\n",
        "    bin_files = [f for f in files if f.endswith('.bin')]\n",
        "\n",
        "    logger.info(f\"Found {len(safetensors_files)} safetensor files and {len(bin_files)} bin files\")\n",
        "\n",
        "    with TemporaryDirectory() as temp_dir:\n",
        "        temp_path = Path(temp_dir)\n",
        "        logger.debug(f\"Created temporary directory: {temp_dir}\")\n",
        "\n",
        "        # Download config.json first\n",
        "        config_file = next((f for f in files if f.endswith('config.json')), None)\n",
        "        if config_file:\n",
        "            config_path = temp_path / 'config.json'\n",
        "            logger.info(f\"Downloading config file: {config_file}\")\n",
        "            s3_client = get_s3_client(endpoint_url, verify_ssl, logger)\n",
        "            with open(config_path, 'wb') as out:\n",
        "                obj = s3_client.get_object(Bucket=bucket, Key=config_file)\n",
        "                out.write(obj['Body'].read())\n",
        "            logger.success(\"Config file downloaded successfully\")\n",
        "        else:\n",
        "            logger.error(\"No config.json found!\")\n",
        "            raise Exception(\"No config.json found in model directory\")\n",
        "\n",
        "        # Handle model weights\n",
        "        if safetensors_files and not force_bin:\n",
        "            logger.info(\"Using safetensors format for model loading\")\n",
        "            for file in safetensors_files:\n",
        "                relative_path = Path(file).relative_to(path_to_model)\n",
        "                target_path = temp_path / relative_path\n",
        "                target_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "                logger.info(f\"Downloading safetensors file: {file}\")\n",
        "                with open(target_path, 'wb') as out:\n",
        "                    obj = s3_client.get_object(Bucket=bucket, Key=file)\n",
        "                    out.write(obj['Body'].read())\n",
        "                logger.success(f\"Downloaded: {relative_path}\")\n",
        "\n",
        "        elif bin_files:\n",
        "            logger.info(\"Using .bin format for model loading\")\n",
        "            for file in bin_files:\n",
        "                relative_path = Path(file).relative_to(path_to_model)\n",
        "                target_path = temp_path / relative_path\n",
        "                target_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "                logger.info(f\"Downloading bin file: {file}\")\n",
        "                with open(target_path, 'wb') as out:\n",
        "                    obj = s3_client.get_object(Bucket=bucket, Key=file)\n",
        "                    out.write(obj['Body'].read())\n",
        "                logger.success(f\"Downloaded: {relative_path}\")\n",
        "\n",
        "        # Download tokenizer files\n",
        "        tokenizer_files = [f for f in files if any(f.endswith(ext) for ext in\n",
        "                          ['.tokenizer.json', 'tokenizer_config.json', 'special_tokens_map.json', 'vocab.json', 'merges.txt'])]\n",
        "\n",
        "        for file in tokenizer_files:\n",
        "            relative_path = Path(file).relative_to(path_to_model)\n",
        "            target_path = temp_path / relative_path\n",
        "            target_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "            logger.info(f\"Downloading tokenizer file: {file}\")\n",
        "            with open(target_path, 'wb') as out:\n",
        "                obj = s3_client.get_object(Bucket=bucket, Key=file)\n",
        "                out.write(obj['Body'].read())\n",
        "            logger.success(f\"Downloaded: {relative_path}\")\n",
        "\n",
        "        # Debug: list all files in temp directory\n",
        "        logger.debug(\"Files in temporary directory:\")\n",
        "        for file in Path(temp_dir).rglob('*'):\n",
        "            if file.is_file():\n",
        "                logger.debug(f\"  {file.relative_to(temp_dir)}\")\n",
        "\n",
        "        # Load the model and tokenizer\n",
        "        try:\n",
        "            logger.info(\"Loading model from temporary directory\")\n",
        "            model = AutoModel.from_pretrained(\n",
        "                temp_path,\n",
        "                local_files_only=True,\n",
        "                use_safetensors=not force_bin\n",
        "            )\n",
        "            logger.success(\"Model loaded successfully\")\n",
        "\n",
        "            if tokenizer_files:\n",
        "                logger.info(\"Loading tokenizer\")\n",
        "                tokenizer = AutoTokenizer.from_pretrained(\n",
        "                    temp_path,\n",
        "                    local_files_only=True\n",
        "                )\n",
        "                logger.success(\"Tokenizer loaded successfully\")\n",
        "            else:\n",
        "                logger.warning(\"No tokenizer files found\")\n",
        "                tokenizer = None\n",
        "\n",
        "            return model, tokenizer\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to load model: {str(e)}\")\n",
        "            raise"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage with debugging enabled\n",
        "try:\n",
        "    model, tokenizer = load_model_from_s3(\n",
        "        bucket=\"my-bucket\",\n",
        "        path_to_model=\"models/my-model\",\n",
        "        endpoint_url=\"https://my-storage-endpoint\",\n",
        "        verify_ssl=False,\n",
        "        debug=True  # Enable detailed logging\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(f\"Failed to load model: {e}\")"
      ],
      "metadata": {
        "id": "_ChlOgdWJ8ET"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}