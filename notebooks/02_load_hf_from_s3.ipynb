{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbPx32FwoR2ZZUGIIIFzuC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wesslen/seamless_sacrebleu_evaluation/blob/main/notebooks/02_load_hf_from_s3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8t2osjYZJ6fO"
      },
      "outputs": [],
      "source": [
        "import boto3\n",
        "from botocore.config import Config\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "from contextlib import contextmanager\n",
        "from io import BytesIO\n",
        "from tempfile import TemporaryDirectory\n",
        "from transformers import AutoModel, AutoTokenizer, PretrainedConfig\n",
        "from typing import Tuple, Optional, Union, List, Dict\n",
        "from pathlib import Path\n",
        "import urllib3\n",
        "import warnings\n",
        "from IPython.display import display, HTML\n",
        "from datetime import datetime\n",
        "\n",
        "class NotebookLogger:\n",
        "    \"\"\"Custom logger for Jupyter notebooks with colored output\"\"\"\n",
        "\n",
        "    COLORS = {\n",
        "        'INFO': '#0066cc',\n",
        "        'DEBUG': '#666666',\n",
        "        'WARNING': '#ff9900',\n",
        "        'ERROR': '#cc0000',\n",
        "        'SUCCESS': '#009933'\n",
        "    }\n",
        "\n",
        "    def __init__(self, enable_debug=False):\n",
        "        self.enable_debug = enable_debug\n",
        "\n",
        "    def _log(self, level: str, message: str):\n",
        "        timestamp = datetime.now().strftime('%H:%M:%S')\n",
        "        color = self.COLORS.get(level, '#000000')\n",
        "        display(HTML(\n",
        "            f'<pre style=\"margin:0; padding:2px 0; color: {color}\">'\n",
        "            f'[{timestamp}] {level}: {message}'\n",
        "            '</pre>'\n",
        "        ))\n",
        "\n",
        "    def info(self, message: str):\n",
        "        self._log('INFO', message)\n",
        "\n",
        "    def debug_log(self, message: str):\n",
        "        if self.enable_debug:\n",
        "            self._log('DEBUG', message)\n",
        "\n",
        "    def warning(self, message: str):\n",
        "        self._log('WARNING', message)\n",
        "\n",
        "    def error(self, message: str):\n",
        "        self._log('ERROR', message)\n",
        "\n",
        "    def success(self, message: str):\n",
        "        self._log('SUCCESS', message)\n",
        "\n",
        "def get_s3_client(endpoint_url: Optional[str] = None, verify_ssl: bool = True):\n",
        "    \"\"\"Create an S3 client with configurable SSL verification.\"\"\"\n",
        "    if not verify_ssl:\n",
        "        warnings.filterwarnings('ignore', category=urllib3.exceptions.InsecureRequestWarning)\n",
        "\n",
        "    config = Config(retries=dict(max_attempts=3))\n",
        "\n",
        "    return boto3.client(\n",
        "        's3',\n",
        "        endpoint_url=endpoint_url,\n",
        "        aws_access_key_id=os.environ.get('AWS_ACCESS_KEY_ID'),\n",
        "        aws_secret_access_key=os.environ.get('AWS_SECRET_ACCESS_KEY'),\n",
        "        verify=verify_ssl,\n",
        "        config=config\n",
        "    )\n",
        "\n",
        "def find_model_files(files: List[str], logger: NotebookLogger) -> List[str]:\n",
        "    \"\"\"\n",
        "    Find model files following either pattern:\n",
        "    - model.safetensors\n",
        "    - model-00001-of-00002.safetensors (sharded)\n",
        "    \"\"\"\n",
        "    # First look for single safetensors file\n",
        "    single_file = [f for f in files if f.endswith('model.safetensors')]\n",
        "    if single_file:\n",
        "        logger.debug_log(\"Found single safetensors file\")\n",
        "        return single_file\n",
        "\n",
        "    # Look for sharded files\n",
        "    sharded_pattern = re.compile(r'model-\\d{5}-of-\\d{5}\\.safetensors$')\n",
        "    sharded_files = [f for f in files if sharded_pattern.search(os.path.basename(f))]\n",
        "\n",
        "    if sharded_files:\n",
        "        logger.debug_log(f\"Found {len(sharded_files)} sharded safetensors files\")\n",
        "        # Sort to ensure consistent ordering\n",
        "        return sorted(sharded_files)\n",
        "\n",
        "    logger.debug_log(\"No safetensors files found\")\n",
        "    return []\n",
        "\n",
        "def load_model_from_s3(\n",
        "    bucket: str,\n",
        "    path_to_model: str,\n",
        "    endpoint_url: Optional[str] = None,\n",
        "    verify_ssl: bool = True,\n",
        "    force_bin: bool = False,\n",
        "    enable_debug: bool = False\n",
        ") -> Tuple[Union[AutoModel, None], Union[AutoTokenizer, None]]:\n",
        "    \"\"\"\n",
        "    Load a model and tokenizer from S3 storage, supporting both single and sharded safetensors.\n",
        "\n",
        "    Args:\n",
        "        bucket (str): S3 bucket name\n",
        "        path_to_model (str): Path to model directory in bucket\n",
        "        endpoint_url (str, optional): Custom S3 endpoint URL\n",
        "        verify_ssl (bool): Whether to verify SSL certificates\n",
        "        force_bin (bool): Force using .bin format even if .safetensors is available\n",
        "        enable_debug (bool): Enable detailed debug logging\n",
        "    \"\"\"\n",
        "    logger = NotebookLogger(enable_debug=enable_debug)\n",
        "    logger.info(f\"Starting model load from bucket: {bucket}, path: {path_to_model}\")\n",
        "\n",
        "    s3_client = get_s3_client(endpoint_url, verify_ssl)\n",
        "\n",
        "    # List all files in the model directory\n",
        "    logger.info(\"Listing files in bucket...\")\n",
        "    files = []\n",
        "    paginator = s3_client.get_paginator('list_objects_v2')\n",
        "    for page in paginator.paginate(Bucket=bucket, Prefix=path_to_model):\n",
        "        if 'Contents' in page:\n",
        "            files.extend(obj['Key'] for obj in page['Contents'])\n",
        "\n",
        "    logger.debug_log(f\"Found {len(files)} total files\")\n",
        "    for file in files:\n",
        "        logger.debug_log(f\"Found file: {file}\")\n",
        "\n",
        "    # Find model files\n",
        "    safetensors_files = find_model_files(files, logger)\n",
        "    bin_files = [f for f in files if f.endswith('.bin')]\n",
        "\n",
        "    logger.info(f\"Found {len(safetensors_files)} safetensor files and {len(bin_files)} bin files\")\n",
        "\n",
        "    with TemporaryDirectory() as temp_dir:\n",
        "        temp_path = Path(temp_dir)\n",
        "        logger.debug_log(f\"Created temporary directory: {temp_dir}\")\n",
        "\n",
        "        # Download config.json first\n",
        "        config_file = next((f for f in files if f.endswith('config.json')), None)\n",
        "        if config_file:\n",
        "            config_path = temp_path / 'config.json'\n",
        "            logger.info(f\"Downloading config file: {config_file}\")\n",
        "            with open(config_path, 'wb') as out:\n",
        "                obj = s3_client.get_object(Bucket=bucket, Key=config_file)\n",
        "                out.write(obj['Body'].read())\n",
        "            logger.success(\"Config file downloaded successfully\")\n",
        "        else:\n",
        "            logger.error(\"No config.json found!\")\n",
        "            raise Exception(\"No config.json found in model directory\")\n",
        "\n",
        "        # Handle model weights\n",
        "        if safetensors_files and not force_bin:\n",
        "            logger.info(\"Using safetensors format for model loading\")\n",
        "            for file in safetensors_files:\n",
        "                relative_path = Path(file).relative_to(path_to_model)\n",
        "                target_path = temp_path / relative_path\n",
        "                target_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "                logger.info(f\"Downloading safetensors file: {file}\")\n",
        "                with open(target_path, 'wb') as out:\n",
        "                    obj = s3_client.get_object(Bucket=bucket, Key=file)\n",
        "                    out.write(obj['Body'].read())\n",
        "                logger.success(f\"Downloaded: {relative_path}\")\n",
        "\n",
        "        elif bin_files:\n",
        "            logger.info(\"Using .bin format for model loading\")\n",
        "            for file in bin_files:\n",
        "                relative_path = Path(file).relative_to(path_to_model)\n",
        "                target_path = temp_path / relative_path\n",
        "                target_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "                logger.info(f\"Downloading bin file: {file}\")\n",
        "                with open(target_path, 'wb') as out:\n",
        "                    obj = s3_client.get_object(Bucket=bucket, Key=file)\n",
        "                    out.write(obj['Body'].read())\n",
        "                logger.success(f\"Downloaded: {relative_path}\")\n",
        "        else:\n",
        "            logger.error(\"No model weights files found!\")\n",
        "            raise Exception(\"No model weights files (safetensors or bin) found\")\n",
        "\n",
        "        # Download tokenizer files\n",
        "        tokenizer_files = [f for f in files if any(f.endswith(ext) for ext in\n",
        "                          ['.tokenizer.json', 'tokenizer_config.json', 'special_tokens_map.json', 'vocab.json', 'merges.txt'])]\n",
        "\n",
        "        for file in tokenizer_files:\n",
        "            relative_path = Path(file).relative_to(path_to_model)\n",
        "            target_path = temp_path / relative_path\n",
        "            target_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "            logger.info(f\"Downloading tokenizer file: {file}\")\n",
        "            with open(target_path, 'wb') as out:\n",
        "                obj = s3_client.get_object(Bucket=bucket, Key=file)\n",
        "                out.write(obj['Body'].read())\n",
        "            logger.success(f\"Downloaded: {relative_path}\")\n",
        "\n",
        "        # Debug: list all files in temp directory\n",
        "        logger.debug_log(\"Files in temporary directory:\")\n",
        "        for file in Path(temp_dir).rglob('*'):\n",
        "            if file.is_file():\n",
        "                logger.debug_log(f\"  {file.relative_to(temp_dir)}\")\n",
        "\n",
        "        # Load the model and tokenizer\n",
        "        try:\n",
        "            logger.info(\"Loading model from temporary directory\")\n",
        "            model = AutoModel.from_pretrained(\n",
        "                temp_path,\n",
        "                local_files_only=True,\n",
        "                use_safetensors=not force_bin\n",
        "            )\n",
        "            logger.success(\"Model loaded successfully\")\n",
        "\n",
        "            if tokenizer_files:\n",
        "                logger.info(\"Loading tokenizer\")\n",
        "                tokenizer = AutoTokenizer.from_pretrained(\n",
        "                    temp_path,\n",
        "                    local_files_only=True\n",
        "                )\n",
        "                logger.success(\"Tokenizer loaded successfully\")\n",
        "            else:\n",
        "                logger.warning(\"No tokenizer files found\")\n",
        "                tokenizer = None\n",
        "\n",
        "            return model, tokenizer\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to load model: {str(e)}\")\n",
        "            raise"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage with debugging enabled\n",
        "try:\n",
        "    model, tokenizer = load_model_from_s3(\n",
        "        bucket=\"my-bucket\",\n",
        "        path_to_model=\"models/my-model\",\n",
        "        endpoint_url=\"https://my-storage-endpoint\",\n",
        "        verify_ssl=False,\n",
        "        enable_debug=True  # To see detailed file discovery logs\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(f\"Failed to load model: {e}\")"
      ],
      "metadata": {
        "id": "_ChlOgdWJ8ET"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}